{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TFM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CsgYxvzHCb2J"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOmXr/0cEQ8Sa2+VqKB7SpO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martavillagran/martavillagran.github.io/blob/main/TFM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbe7etjox_im"
      },
      "source": [
        "# Pruebas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3hpVQVUIB1n"
      },
      "source": [
        "### **Prueba para comprobar el truco de la matriz identidad**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgZItwfEDZx8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yDMU6kCDYpL",
        "outputId": "d3a89df3-a5a6-48a0-a7ed-4fe28149e7f1"
      },
      "source": [
        "# Datos del mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVs0tZMnDWHR"
      },
      "source": [
        "# Parameters\n",
        "max_layers = 7\n",
        "max_layers_2train = 3\n",
        "num_max_units = 54\n",
        "input_dim = 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_uxhqZktrlF"
      },
      "source": [
        "def build_model(max_layers):\n",
        "  # Comprobaciones de la identidad tipo resnet (fijo las tres primeras capas y el resto no las entreno)\n",
        "  inputs = keras.Input(shape=(input_dim, input_dim), name=\"digits\")\n",
        "\n",
        "  for layers in range(max_layers):\n",
        "    if layers == 0:\n",
        "      x = keras.layers.Flatten()(inputs)\n",
        "    else:\n",
        "      if layers > 3:  \n",
        "        x = keras.layers.Dense(num_max_units, trainable=False, kernel_initializer=tf.keras.initializers.Identity())(x)\n",
        "      else:\n",
        "        x = keras.layers.Dense(num_max_units, activation=\"sigmoid\")(x)\n",
        "\n",
        "  outputs = keras.layers.Dense(len(np.unique(train_labels)), activation=\"softmax\", name=\"classification\")(x)\n",
        "  return  keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "vs5o5_FRD1Ko",
        "outputId": "3c5ec3c0-fa9b-4de9-c12c-fabe44839347"
      },
      "source": [
        "model1 = build_model(7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-32d15d7b164a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-ecbdeee82ffc>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(max_layers)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_max_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;32mreturn\u001b[0m  \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRV9OJCpD46w"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXOQFVR5nghy"
      },
      "source": [
        "model2 = build_model(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u04kj0s5D_EE"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfgW8Qw22xOD"
      },
      "source": [
        "model1.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01), \n",
        "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNtG0Pfl2zLM"
      },
      "source": [
        "np.random.seed(19)\n",
        "tf.random.set_seed(41)\n",
        "history = model1.fit(train_images, train_labels, epochs=100, batch_size=512, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd6r5iHC3Bxf"
      },
      "source": [
        "model1.predict(test_images[0:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Yy9LT5H2sy"
      },
      "source": [
        "# Planteamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEOWCHLixfOt"
      },
      "source": [
        "#### Con Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uJlpon8H4gn"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68LLfOXYIAo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cef8de5-6039-4073-ae7c-5bdc6ae35817"
      },
      "source": [
        "# Datos del mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2xm5wveH8h5"
      },
      "source": [
        "# Parameters\n",
        "max_layers = 6\n",
        "max_layers_2train = 2\n",
        "num_max_units = 54\n",
        "input_dim = 28\n",
        "trigger_thr = 0.025"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDgkjORZISpC"
      },
      "source": [
        "def build_model(max_layers, max_layers2train):\n",
        "  # Comprobaciones de la identidad tipo resnet (fijo las tres primeras capas y el resto no las entreno)\n",
        "  inputs = keras.Input(shape=(input_dim**2,), name=\"digits\")\n",
        "\n",
        "  for layers in range(max_layers):\n",
        "    if layers == 0:\n",
        "      x = keras.layers.Dense(num_max_units, activation=\"relu\", name=\"layer%s\" %layers, kernel_constraint=FreezeSlice([1],np.s_[0]))(inputs)\n",
        "    else:\n",
        "      if layers > max_layers2train:  \n",
        "        x = keras.layers.Dense(num_max_units, trainable=False,  name=\"layer%s\" %layers, \n",
        "                               kernel_initializer=tf.keras.initializers.Identity())(x)\n",
        "      else:\n",
        "        x = keras.layers.Dense(num_max_units,  name=\"layer%s\" %layers, activation=\"relu\")(x)\n",
        "\n",
        "  outputs = keras.layers.Dense(len(np.unique(train_labels)), activation=\"softmax\", name=\"classification\")(x)\n",
        "  return  keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mVLYDeiIj3J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "8371401c-0002-4599-815e-0e15b3aeb6dc"
      },
      "source": [
        "model = build_model(max_layers, max_layers_2train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-6-05dd31fc2331>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_layers_2train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-5-182729a65b6c>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(max_layers, max_layers2train)\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_max_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"layer%s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFreezeSlice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_layers2train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'FreezeSlice' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx4G81owMk4Q",
        "outputId": "67bb1eac-d5c3-4fd0-e083-702c0f8cdbaa"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "digits (InputLayer)          [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "layer0 (Dense)               (None, 54)                42390     \n",
            "_________________________________________________________________\n",
            "layer1 (Dense)               (None, 54)                2970      \n",
            "_________________________________________________________________\n",
            "layer2 (Dense)               (None, 54)                2970      \n",
            "_________________________________________________________________\n",
            "layer3 (Dense)               (None, 54)                2970      \n",
            "_________________________________________________________________\n",
            "layer4 (Dense)               (None, 54)                2970      \n",
            "_________________________________________________________________\n",
            "layer5 (Dense)               (None, 54)                2970      \n",
            "_________________________________________________________________\n",
            "classification (Dense)       (None, 10)                550       \n",
            "=================================================================\n",
            "Total params: 57,790\n",
            "Trainable params: 48,880\n",
            "Non-trainable params: 8,910\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbd5yBCQIqHy"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5rM0sfLJ24m"
      },
      "source": [
        "# Prepare the training dataset\n",
        "batch_size = 512\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = np.reshape(x_train, (-1, 784))\n",
        "x_test = np.reshape(x_test, (-1, 784))\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAXmGg6xMDqy"
      },
      "source": [
        "# Prepare the metrics.\n",
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONcqygmHME64"
      },
      "source": [
        "# Instantiate an optimizer.\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "# Instantiate a loss function.\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjqe-lwlKnfV"
      },
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x, training=True)\n",
        "        loss_value = loss_fn(y, logits)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "    return loss_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1JQudrAQimG"
      },
      "source": [
        "trigger_thr = 0.25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo0DiUCJRYle"
      },
      "source": [
        "def get_non_trainable_layers(model, max_layers):\n",
        "  non_trainable = np.zeros(max_layers)\n",
        "  for i in range(max_layers):\n",
        "    if model.get_layer(\"layer%s\" %i).trainable == 0:\n",
        "      non_trainable[i] = 1\n",
        "  return non_trainable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv-7xrahvpz6"
      },
      "source": [
        "non_trainabale_layers = get_non_trainable_layers(model, max_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8wQaMWPwOIN",
        "outputId": "c71e1061-40df-407b-fc8b-fea9798b4741"
      },
      "source": [
        "# Trainable weigths para hacer la mascara y el dropout\n",
        "# No sirve lo anterior, el modelo no se compila, hacerlo con early stopping\n",
        "# https://github.com/keras-team/keras/issues/2880 - para darle freeze"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 1., 1.])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "jK-H0y0A1tf6",
        "outputId": "22b96861-1538-49e9-9b5f-0ff4621d30bd"
      },
      "source": [
        "w1 = model.get_layer('layer0').get_weigths()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-802a5550fc0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layer0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weigth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'get_weigth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztoxMQZNJnqo",
        "outputId": "a210c920-d7bf-43d2-d0c4-e92ff088251c"
      },
      "source": [
        "# Custom training loop\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # Iterate over the batches of the dataset.\n",
        "    loss_prev = loss_value\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "    \n",
        "    if epoch == 0:\n",
        "      loss_prev = loss_value\n",
        "    if np.abs((loss_prev - loss_value)/loss_prev) > trigger_thr:\n",
        "      # GA optimization ex\n",
        "      hidden_layers = 4\n",
        "      non_trainabale_layers = get_non_trainable_layers(model, max_layers)\n",
        "      while (max_layers - np.sum(non_trainabale_layers)) < hidden_layers:\n",
        "        print('Trigger')\n",
        "        idx = np.where(non_trainabale_layers>0)[0]\n",
        "        non_trainabale_layers[idx[0]] = 0\n",
        "        model.get_layer(\"layer%s\" %idx[0]).trainable = True\n",
        "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy') # ojo que sino no hace nada\n",
        "        \n",
        "   \n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "     # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training acc over epoch: 0.8779\n",
            "Training acc over epoch: 0.8813\n",
            "Training acc over epoch: 0.8869\n",
            "Training acc over epoch: 0.8920\n",
            "Training acc over epoch: 0.8947\n",
            "Training acc over epoch: 0.8969\n",
            "Training acc over epoch: 0.8993\n",
            "Training acc over epoch: 0.9020\n",
            "Training acc over epoch: 0.9039\n",
            "Training acc over epoch: 0.9062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u0iUp3yyPl8",
        "outputId": "f45114fa-5e0e-45b6-92c8-1cc52c1b6e94"
      },
      "source": [
        "non_trainabale_layers = get_non_trainable_layers(model, max_layers)\n",
        "non_trainabale_layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 1.])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvLIGknvzRFR"
      },
      "source": [
        "w3 = model.get_layer('layer0')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv_hXYu4_pHQ"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "Ckn16TWc_Zzu",
        "outputId": "3a9ddc72-5064-4922-b10d-d2a5ba8fc1fd"
      },
      "source": [
        "pd.DataFrame(w3.get_weights()[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.040816</td>\n",
              "      <td>0.034933</td>\n",
              "      <td>0.071282</td>\n",
              "      <td>-0.005608</td>\n",
              "      <td>0.012143</td>\n",
              "      <td>0.036048</td>\n",
              "      <td>0.077783</td>\n",
              "      <td>0.037841</td>\n",
              "      <td>0.014904</td>\n",
              "      <td>0.082379</td>\n",
              "      <td>-0.000381</td>\n",
              "      <td>0.069258</td>\n",
              "      <td>-0.020570</td>\n",
              "      <td>0.000968</td>\n",
              "      <td>0.015307</td>\n",
              "      <td>0.064013</td>\n",
              "      <td>-0.077571</td>\n",
              "      <td>-0.006489</td>\n",
              "      <td>-0.019111</td>\n",
              "      <td>0.037761</td>\n",
              "      <td>-0.032844</td>\n",
              "      <td>-0.041544</td>\n",
              "      <td>-0.055568</td>\n",
              "      <td>-0.074368</td>\n",
              "      <td>0.023561</td>\n",
              "      <td>-0.081544</td>\n",
              "      <td>0.018014</td>\n",
              "      <td>0.064763</td>\n",
              "      <td>0.045914</td>\n",
              "      <td>0.038636</td>\n",
              "      <td>-0.079743</td>\n",
              "      <td>0.036667</td>\n",
              "      <td>0.015317</td>\n",
              "      <td>-0.021623</td>\n",
              "      <td>0.083662</td>\n",
              "      <td>0.055733</td>\n",
              "      <td>0.048132</td>\n",
              "      <td>-0.025575</td>\n",
              "      <td>-0.014567</td>\n",
              "      <td>0.038181</td>\n",
              "      <td>-0.047241</td>\n",
              "      <td>0.014633</td>\n",
              "      <td>0.082796</td>\n",
              "      <td>-0.013425</td>\n",
              "      <td>-0.050871</td>\n",
              "      <td>0.001069</td>\n",
              "      <td>-0.042327</td>\n",
              "      <td>-0.073835</td>\n",
              "      <td>0.035631</td>\n",
              "      <td>0.064500</td>\n",
              "      <td>0.065276</td>\n",
              "      <td>0.068856</td>\n",
              "      <td>-0.064112</td>\n",
              "      <td>0.065959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.050813</td>\n",
              "      <td>0.004208</td>\n",
              "      <td>-0.083369</td>\n",
              "      <td>-0.072771</td>\n",
              "      <td>0.040086</td>\n",
              "      <td>0.053143</td>\n",
              "      <td>0.023650</td>\n",
              "      <td>-0.017038</td>\n",
              "      <td>0.021519</td>\n",
              "      <td>-0.023179</td>\n",
              "      <td>-0.054561</td>\n",
              "      <td>0.043894</td>\n",
              "      <td>-0.082774</td>\n",
              "      <td>-0.002985</td>\n",
              "      <td>-0.027646</td>\n",
              "      <td>-0.010465</td>\n",
              "      <td>-0.024704</td>\n",
              "      <td>0.077425</td>\n",
              "      <td>0.069002</td>\n",
              "      <td>0.033896</td>\n",
              "      <td>0.068864</td>\n",
              "      <td>-0.002189</td>\n",
              "      <td>0.008090</td>\n",
              "      <td>0.043587</td>\n",
              "      <td>0.069004</td>\n",
              "      <td>-0.058721</td>\n",
              "      <td>-0.058498</td>\n",
              "      <td>0.056573</td>\n",
              "      <td>-0.022667</td>\n",
              "      <td>0.040349</td>\n",
              "      <td>-0.034662</td>\n",
              "      <td>-0.027642</td>\n",
              "      <td>-0.050791</td>\n",
              "      <td>-0.013329</td>\n",
              "      <td>-0.019086</td>\n",
              "      <td>-0.051741</td>\n",
              "      <td>0.036200</td>\n",
              "      <td>-0.003845</td>\n",
              "      <td>0.077286</td>\n",
              "      <td>0.038562</td>\n",
              "      <td>-0.074627</td>\n",
              "      <td>-0.074661</td>\n",
              "      <td>0.018292</td>\n",
              "      <td>-0.049099</td>\n",
              "      <td>-0.049046</td>\n",
              "      <td>-0.011546</td>\n",
              "      <td>-0.023001</td>\n",
              "      <td>-0.014542</td>\n",
              "      <td>0.014810</td>\n",
              "      <td>0.071854</td>\n",
              "      <td>0.028379</td>\n",
              "      <td>-0.014995</td>\n",
              "      <td>-0.033035</td>\n",
              "      <td>0.010024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.066511</td>\n",
              "      <td>-0.063230</td>\n",
              "      <td>0.060301</td>\n",
              "      <td>-0.022914</td>\n",
              "      <td>0.019500</td>\n",
              "      <td>-0.018194</td>\n",
              "      <td>-0.049797</td>\n",
              "      <td>-0.007767</td>\n",
              "      <td>0.052476</td>\n",
              "      <td>0.075698</td>\n",
              "      <td>0.052329</td>\n",
              "      <td>-0.028242</td>\n",
              "      <td>-0.084026</td>\n",
              "      <td>-0.026509</td>\n",
              "      <td>-0.030610</td>\n",
              "      <td>0.048289</td>\n",
              "      <td>0.025827</td>\n",
              "      <td>0.059023</td>\n",
              "      <td>0.062186</td>\n",
              "      <td>-0.055522</td>\n",
              "      <td>0.015328</td>\n",
              "      <td>0.023914</td>\n",
              "      <td>0.014982</td>\n",
              "      <td>0.060698</td>\n",
              "      <td>-0.036607</td>\n",
              "      <td>0.060766</td>\n",
              "      <td>0.068325</td>\n",
              "      <td>-0.036000</td>\n",
              "      <td>0.044746</td>\n",
              "      <td>-0.045154</td>\n",
              "      <td>0.051430</td>\n",
              "      <td>-0.055435</td>\n",
              "      <td>0.035434</td>\n",
              "      <td>0.073502</td>\n",
              "      <td>-0.079585</td>\n",
              "      <td>0.082807</td>\n",
              "      <td>0.022626</td>\n",
              "      <td>0.030297</td>\n",
              "      <td>0.021089</td>\n",
              "      <td>-0.081252</td>\n",
              "      <td>-0.030687</td>\n",
              "      <td>0.038162</td>\n",
              "      <td>0.018953</td>\n",
              "      <td>-0.056651</td>\n",
              "      <td>0.039238</td>\n",
              "      <td>-0.013250</td>\n",
              "      <td>0.053461</td>\n",
              "      <td>-0.057019</td>\n",
              "      <td>0.067539</td>\n",
              "      <td>-0.036395</td>\n",
              "      <td>0.029410</td>\n",
              "      <td>-0.082958</td>\n",
              "      <td>-0.016458</td>\n",
              "      <td>0.010619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.022178</td>\n",
              "      <td>-0.021026</td>\n",
              "      <td>-0.082399</td>\n",
              "      <td>-0.070535</td>\n",
              "      <td>0.019096</td>\n",
              "      <td>-0.005691</td>\n",
              "      <td>-0.053594</td>\n",
              "      <td>0.027403</td>\n",
              "      <td>0.039142</td>\n",
              "      <td>0.038024</td>\n",
              "      <td>-0.078203</td>\n",
              "      <td>0.079007</td>\n",
              "      <td>-0.074097</td>\n",
              "      <td>0.032382</td>\n",
              "      <td>-0.043261</td>\n",
              "      <td>-0.020954</td>\n",
              "      <td>-0.071257</td>\n",
              "      <td>-0.067479</td>\n",
              "      <td>0.023143</td>\n",
              "      <td>0.050282</td>\n",
              "      <td>-0.004035</td>\n",
              "      <td>0.065023</td>\n",
              "      <td>0.035802</td>\n",
              "      <td>0.066714</td>\n",
              "      <td>-0.018054</td>\n",
              "      <td>-0.006602</td>\n",
              "      <td>0.046304</td>\n",
              "      <td>0.020962</td>\n",
              "      <td>-0.020979</td>\n",
              "      <td>0.037289</td>\n",
              "      <td>-0.042101</td>\n",
              "      <td>-0.058693</td>\n",
              "      <td>-0.045718</td>\n",
              "      <td>-0.022028</td>\n",
              "      <td>-0.068745</td>\n",
              "      <td>-0.008206</td>\n",
              "      <td>-0.030656</td>\n",
              "      <td>-0.049251</td>\n",
              "      <td>-0.083461</td>\n",
              "      <td>0.029621</td>\n",
              "      <td>-0.008434</td>\n",
              "      <td>0.069664</td>\n",
              "      <td>-0.081643</td>\n",
              "      <td>-0.011234</td>\n",
              "      <td>-0.061039</td>\n",
              "      <td>-0.081420</td>\n",
              "      <td>-0.044808</td>\n",
              "      <td>-0.031347</td>\n",
              "      <td>-0.037301</td>\n",
              "      <td>-0.071862</td>\n",
              "      <td>-0.062580</td>\n",
              "      <td>0.053458</td>\n",
              "      <td>-0.049285</td>\n",
              "      <td>0.007102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.056877</td>\n",
              "      <td>-0.083174</td>\n",
              "      <td>-0.018631</td>\n",
              "      <td>0.037361</td>\n",
              "      <td>-0.028160</td>\n",
              "      <td>0.072845</td>\n",
              "      <td>0.069202</td>\n",
              "      <td>-0.026534</td>\n",
              "      <td>-0.017204</td>\n",
              "      <td>0.046108</td>\n",
              "      <td>0.002416</td>\n",
              "      <td>0.019517</td>\n",
              "      <td>-0.082398</td>\n",
              "      <td>-0.012950</td>\n",
              "      <td>0.024216</td>\n",
              "      <td>-0.051724</td>\n",
              "      <td>0.076221</td>\n",
              "      <td>-0.070663</td>\n",
              "      <td>-0.068563</td>\n",
              "      <td>0.067489</td>\n",
              "      <td>0.045596</td>\n",
              "      <td>-0.024708</td>\n",
              "      <td>0.044227</td>\n",
              "      <td>0.040457</td>\n",
              "      <td>-0.030351</td>\n",
              "      <td>0.072548</td>\n",
              "      <td>-0.011113</td>\n",
              "      <td>0.042733</td>\n",
              "      <td>0.047204</td>\n",
              "      <td>-0.004216</td>\n",
              "      <td>-0.005111</td>\n",
              "      <td>-0.055785</td>\n",
              "      <td>-0.044020</td>\n",
              "      <td>-0.040617</td>\n",
              "      <td>-0.072027</td>\n",
              "      <td>-0.007951</td>\n",
              "      <td>0.064382</td>\n",
              "      <td>-0.075824</td>\n",
              "      <td>-0.019558</td>\n",
              "      <td>-0.056610</td>\n",
              "      <td>0.002980</td>\n",
              "      <td>0.078838</td>\n",
              "      <td>0.082166</td>\n",
              "      <td>0.010410</td>\n",
              "      <td>-0.037415</td>\n",
              "      <td>-0.040607</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>-0.067893</td>\n",
              "      <td>-0.074733</td>\n",
              "      <td>0.046354</td>\n",
              "      <td>-0.084028</td>\n",
              "      <td>0.052057</td>\n",
              "      <td>-0.039099</td>\n",
              "      <td>-0.079448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>0.032553</td>\n",
              "      <td>0.073165</td>\n",
              "      <td>-0.074960</td>\n",
              "      <td>0.035447</td>\n",
              "      <td>0.072694</td>\n",
              "      <td>-0.015046</td>\n",
              "      <td>0.050601</td>\n",
              "      <td>-0.050443</td>\n",
              "      <td>-0.058342</td>\n",
              "      <td>-0.025527</td>\n",
              "      <td>0.012865</td>\n",
              "      <td>-0.063225</td>\n",
              "      <td>0.042553</td>\n",
              "      <td>-0.006569</td>\n",
              "      <td>0.069413</td>\n",
              "      <td>0.065219</td>\n",
              "      <td>0.003376</td>\n",
              "      <td>-0.076669</td>\n",
              "      <td>-0.055099</td>\n",
              "      <td>-0.009938</td>\n",
              "      <td>-0.075990</td>\n",
              "      <td>-0.022195</td>\n",
              "      <td>-0.029973</td>\n",
              "      <td>0.053166</td>\n",
              "      <td>-0.073553</td>\n",
              "      <td>-0.019086</td>\n",
              "      <td>0.035778</td>\n",
              "      <td>-0.002784</td>\n",
              "      <td>0.068967</td>\n",
              "      <td>0.080992</td>\n",
              "      <td>-0.076994</td>\n",
              "      <td>0.000833</td>\n",
              "      <td>0.079333</td>\n",
              "      <td>0.004919</td>\n",
              "      <td>-0.076813</td>\n",
              "      <td>0.075796</td>\n",
              "      <td>-0.048707</td>\n",
              "      <td>0.016452</td>\n",
              "      <td>-0.018926</td>\n",
              "      <td>-0.068866</td>\n",
              "      <td>0.005920</td>\n",
              "      <td>-0.046256</td>\n",
              "      <td>0.021791</td>\n",
              "      <td>0.054079</td>\n",
              "      <td>0.019203</td>\n",
              "      <td>-0.028588</td>\n",
              "      <td>0.061442</td>\n",
              "      <td>-0.008230</td>\n",
              "      <td>-0.001006</td>\n",
              "      <td>-0.037633</td>\n",
              "      <td>-0.000933</td>\n",
              "      <td>0.059720</td>\n",
              "      <td>0.013516</td>\n",
              "      <td>-0.067722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>0.031789</td>\n",
              "      <td>0.061051</td>\n",
              "      <td>0.024838</td>\n",
              "      <td>-0.054059</td>\n",
              "      <td>0.083717</td>\n",
              "      <td>-0.020930</td>\n",
              "      <td>0.020352</td>\n",
              "      <td>0.000282</td>\n",
              "      <td>-0.052710</td>\n",
              "      <td>0.030490</td>\n",
              "      <td>-0.025399</td>\n",
              "      <td>-0.013316</td>\n",
              "      <td>-0.051764</td>\n",
              "      <td>0.056875</td>\n",
              "      <td>0.049697</td>\n",
              "      <td>-0.083116</td>\n",
              "      <td>-0.025027</td>\n",
              "      <td>-0.059617</td>\n",
              "      <td>-0.030312</td>\n",
              "      <td>-0.071241</td>\n",
              "      <td>0.075783</td>\n",
              "      <td>0.005492</td>\n",
              "      <td>0.027992</td>\n",
              "      <td>-0.053718</td>\n",
              "      <td>-0.052705</td>\n",
              "      <td>-0.080325</td>\n",
              "      <td>0.003682</td>\n",
              "      <td>0.016135</td>\n",
              "      <td>-0.038168</td>\n",
              "      <td>0.040071</td>\n",
              "      <td>0.082938</td>\n",
              "      <td>-0.057800</td>\n",
              "      <td>-0.009995</td>\n",
              "      <td>0.002813</td>\n",
              "      <td>0.079940</td>\n",
              "      <td>0.052179</td>\n",
              "      <td>0.007601</td>\n",
              "      <td>0.076367</td>\n",
              "      <td>0.012326</td>\n",
              "      <td>0.070553</td>\n",
              "      <td>0.047625</td>\n",
              "      <td>-0.077731</td>\n",
              "      <td>0.062256</td>\n",
              "      <td>0.001734</td>\n",
              "      <td>0.059669</td>\n",
              "      <td>0.055450</td>\n",
              "      <td>0.010006</td>\n",
              "      <td>-0.012430</td>\n",
              "      <td>0.063227</td>\n",
              "      <td>-0.067751</td>\n",
              "      <td>0.053841</td>\n",
              "      <td>0.035348</td>\n",
              "      <td>-0.045475</td>\n",
              "      <td>-0.078142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>-0.015362</td>\n",
              "      <td>-0.062178</td>\n",
              "      <td>-0.064879</td>\n",
              "      <td>0.013043</td>\n",
              "      <td>0.082827</td>\n",
              "      <td>0.026861</td>\n",
              "      <td>-0.020804</td>\n",
              "      <td>0.015974</td>\n",
              "      <td>-0.005130</td>\n",
              "      <td>0.020539</td>\n",
              "      <td>0.083357</td>\n",
              "      <td>-0.058618</td>\n",
              "      <td>-0.052433</td>\n",
              "      <td>-0.027116</td>\n",
              "      <td>-0.074733</td>\n",
              "      <td>-0.040232</td>\n",
              "      <td>0.016490</td>\n",
              "      <td>0.007047</td>\n",
              "      <td>0.052962</td>\n",
              "      <td>-0.064858</td>\n",
              "      <td>0.063549</td>\n",
              "      <td>0.080273</td>\n",
              "      <td>-0.009069</td>\n",
              "      <td>0.032298</td>\n",
              "      <td>-0.023046</td>\n",
              "      <td>-0.075692</td>\n",
              "      <td>-0.015669</td>\n",
              "      <td>0.047195</td>\n",
              "      <td>0.038616</td>\n",
              "      <td>-0.080842</td>\n",
              "      <td>0.047979</td>\n",
              "      <td>-0.035570</td>\n",
              "      <td>0.003754</td>\n",
              "      <td>-0.034984</td>\n",
              "      <td>0.013576</td>\n",
              "      <td>-0.032136</td>\n",
              "      <td>0.025569</td>\n",
              "      <td>0.040749</td>\n",
              "      <td>-0.006006</td>\n",
              "      <td>0.049025</td>\n",
              "      <td>-0.035446</td>\n",
              "      <td>0.048632</td>\n",
              "      <td>-0.006849</td>\n",
              "      <td>-0.007876</td>\n",
              "      <td>-0.071042</td>\n",
              "      <td>-0.018907</td>\n",
              "      <td>0.071958</td>\n",
              "      <td>-0.039329</td>\n",
              "      <td>-0.017456</td>\n",
              "      <td>0.029641</td>\n",
              "      <td>-0.071429</td>\n",
              "      <td>-0.040518</td>\n",
              "      <td>0.020316</td>\n",
              "      <td>0.027230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>-0.069466</td>\n",
              "      <td>-0.022379</td>\n",
              "      <td>-0.016960</td>\n",
              "      <td>0.041653</td>\n",
              "      <td>0.009581</td>\n",
              "      <td>-0.007190</td>\n",
              "      <td>-0.033757</td>\n",
              "      <td>0.051400</td>\n",
              "      <td>0.033781</td>\n",
              "      <td>-0.060344</td>\n",
              "      <td>-0.055742</td>\n",
              "      <td>-0.068006</td>\n",
              "      <td>0.049393</td>\n",
              "      <td>-0.075221</td>\n",
              "      <td>0.032562</td>\n",
              "      <td>0.013639</td>\n",
              "      <td>-0.054440</td>\n",
              "      <td>0.016070</td>\n",
              "      <td>-0.052705</td>\n",
              "      <td>-0.007346</td>\n",
              "      <td>-0.032531</td>\n",
              "      <td>-0.001831</td>\n",
              "      <td>0.025769</td>\n",
              "      <td>0.030416</td>\n",
              "      <td>0.007193</td>\n",
              "      <td>-0.023706</td>\n",
              "      <td>0.010714</td>\n",
              "      <td>0.053001</td>\n",
              "      <td>-0.060701</td>\n",
              "      <td>0.020528</td>\n",
              "      <td>-0.024327</td>\n",
              "      <td>0.049881</td>\n",
              "      <td>0.015018</td>\n",
              "      <td>-0.068961</td>\n",
              "      <td>0.078054</td>\n",
              "      <td>0.031498</td>\n",
              "      <td>0.004624</td>\n",
              "      <td>-0.027589</td>\n",
              "      <td>-0.047333</td>\n",
              "      <td>-0.066362</td>\n",
              "      <td>-0.046674</td>\n",
              "      <td>0.035396</td>\n",
              "      <td>-0.064848</td>\n",
              "      <td>0.044697</td>\n",
              "      <td>0.037344</td>\n",
              "      <td>0.001197</td>\n",
              "      <td>-0.054121</td>\n",
              "      <td>0.023626</td>\n",
              "      <td>0.040397</td>\n",
              "      <td>-0.015908</td>\n",
              "      <td>0.036753</td>\n",
              "      <td>0.012100</td>\n",
              "      <td>-0.008558</td>\n",
              "      <td>0.020920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>-0.013121</td>\n",
              "      <td>-0.040022</td>\n",
              "      <td>-0.011737</td>\n",
              "      <td>0.014154</td>\n",
              "      <td>0.059860</td>\n",
              "      <td>-0.012816</td>\n",
              "      <td>0.065015</td>\n",
              "      <td>0.063662</td>\n",
              "      <td>0.040852</td>\n",
              "      <td>-0.042863</td>\n",
              "      <td>0.014336</td>\n",
              "      <td>0.033264</td>\n",
              "      <td>0.071868</td>\n",
              "      <td>-0.061755</td>\n",
              "      <td>0.056502</td>\n",
              "      <td>0.072831</td>\n",
              "      <td>0.002276</td>\n",
              "      <td>-0.067977</td>\n",
              "      <td>-0.062773</td>\n",
              "      <td>0.066153</td>\n",
              "      <td>-0.082736</td>\n",
              "      <td>-0.031542</td>\n",
              "      <td>0.039183</td>\n",
              "      <td>-0.044154</td>\n",
              "      <td>0.084103</td>\n",
              "      <td>0.025029</td>\n",
              "      <td>0.019501</td>\n",
              "      <td>-0.024696</td>\n",
              "      <td>0.007616</td>\n",
              "      <td>-0.061201</td>\n",
              "      <td>-0.021905</td>\n",
              "      <td>-0.078541</td>\n",
              "      <td>-0.024903</td>\n",
              "      <td>0.044914</td>\n",
              "      <td>-0.031520</td>\n",
              "      <td>0.063232</td>\n",
              "      <td>-0.067512</td>\n",
              "      <td>-0.002836</td>\n",
              "      <td>-0.033181</td>\n",
              "      <td>0.030234</td>\n",
              "      <td>0.017389</td>\n",
              "      <td>-0.038101</td>\n",
              "      <td>0.053879</td>\n",
              "      <td>0.061957</td>\n",
              "      <td>-0.055167</td>\n",
              "      <td>0.051720</td>\n",
              "      <td>-0.015853</td>\n",
              "      <td>-0.069993</td>\n",
              "      <td>-0.034819</td>\n",
              "      <td>0.004436</td>\n",
              "      <td>-0.031047</td>\n",
              "      <td>-0.046359</td>\n",
              "      <td>0.002474</td>\n",
              "      <td>-0.077197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>784 rows  54 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2   ...        51        52        53\n",
              "0   -0.040816  0.034933  0.071282  ...  0.068856 -0.064112  0.065959\n",
              "1    0.050813  0.004208 -0.083369  ... -0.014995 -0.033035  0.010024\n",
              "2    0.066511 -0.063230  0.060301  ... -0.082958 -0.016458  0.010619\n",
              "3    0.022178 -0.021026 -0.082399  ...  0.053458 -0.049285  0.007102\n",
              "4    0.056877 -0.083174 -0.018631  ...  0.052057 -0.039099 -0.079448\n",
              "..        ...       ...       ...  ...       ...       ...       ...\n",
              "779  0.032553  0.073165 -0.074960  ...  0.059720  0.013516 -0.067722\n",
              "780  0.031789  0.061051  0.024838  ...  0.035348 -0.045475 -0.078142\n",
              "781 -0.015362 -0.062178 -0.064879  ... -0.040518  0.020316  0.027230\n",
              "782 -0.069466 -0.022379 -0.016960  ...  0.012100 -0.008558  0.020920\n",
              "783 -0.013121 -0.040022 -0.011737  ... -0.046359  0.002474 -0.077197\n",
              "\n",
              "[784 rows x 54 columns]"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ4o02sXzYWg"
      },
      "source": [
        "from keras.initializers import Initializer\n",
        "\n",
        "class FixSlice(Initializer):\n",
        "    \"\"\"\n",
        "    Initializer which forces a certain slice to be chosen values\n",
        "\n",
        "    INPUTS:\n",
        "\n",
        "    values - An object which can be converted into a numpy ndarray. These are\n",
        "             the pre-chosen values. When using this initializer, the user should\n",
        "             ensure that the dtype of values can be converted to the desired\n",
        "             dtype of the weight tensor.\n",
        "\n",
        "    slice - A slice or tuple of slices (it is recommended to use numpy.s_ to\n",
        "            specify this parameter). This specifies which entries should be\n",
        "            filled with the pre-chosen values. When using this initializer,\n",
        "            the user should ensure that the slice object \"fits inside\" the shape\n",
        "            of the tensor to be initialized, and that the resulting slice of the\n",
        "            tensor has the same shape as the values ndarray.\n",
        "\n",
        "    backup - An initializer instance. The remaining values are filled using this\n",
        "             initializer.\n",
        "    \"\"\"\n",
        "    def __init__(self, values, slice, backup=\"glorot_uniform\"):\n",
        "        if hasattr(values, \"numpy\"):\n",
        "            self.values = values.numpy()\n",
        "        elif isinstance(values, np.ndarray):\n",
        "            self.values = values\n",
        "        else:\n",
        "            try:\n",
        "                self.values = values.to_numpy()\n",
        "            except:\n",
        "                self.values = np.array(values)\n",
        "\n",
        "        self.values = values\n",
        "        self.slice = slice\n",
        "        self.backup = initializers.get(backup)\n",
        "\n",
        "    def __call__(self, shape, dtype=None):\n",
        "        result = self.backup(shape, dtype=dtype).numpy()\n",
        "        result[self.slice] = self.values\n",
        "        return tf.Variable(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6wpBIE_9exn"
      },
      "source": [
        "from keras.constraints import Constraint\n",
        "\n",
        "class FreezeSlice(Constraint):\n",
        "    \"\"\"\n",
        "    Constraint which keeps a certain slice frozen at chosen values\n",
        "\n",
        "    INPUTS:\n",
        "\n",
        "    values - An object which can be converted into a numpy ndarray. These are\n",
        "             the pre-chosen values. When using this constraint, the user should\n",
        "             ensure that the dtype of values can be converted to the desired\n",
        "             dtype of the weight tensor.\n",
        "\n",
        "    slice - A slice or tuple of slices (it is recommended to use numpy.s_ to\n",
        "            specify this parameter). This specifies which entries should be\n",
        "            filled with the pre-chosen values. When using this initializer,\n",
        "            the user should ensure that the slice object \"fits inside\" the shape\n",
        "            of the tensor to be initialized, and that the resulting slice of the\n",
        "            tensor has the same shape as the values ndarray.\n",
        "    \"\"\"\n",
        "    def __init__(self, values, slice):\n",
        "        if hasattr(values, \"numpy\"):\n",
        "            self.values = values.numpy()\n",
        "        elif isinstance(values, np.ndarray):\n",
        "            self.values = values\n",
        "        else:\n",
        "            try:\n",
        "                self.values = values.to_numpy()\n",
        "            except:\n",
        "                self.values = np.array(values)\n",
        "\n",
        "        self.values = values\n",
        "        self.slice = slice\n",
        "\n",
        "    def __call__(self, w):\n",
        "        zs = np.zeros(w.shape)\n",
        "        zs[self.slice] = self.values\n",
        "        os = np.ones(w.shape)\n",
        "        os[self.slice] = 0\n",
        "        return w * os + zs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdRE_B5m-Gh_"
      },
      "source": [
        "model.add(Dense(1,input_dim =2,kernel_constraint=FreezeSlice([1],np.s_[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-fNC2S8xkyo"
      },
      "source": [
        "#### Con TensorFlow 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQXwypiTxm_r"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_q9SEJ6xwbk"
      },
      "source": [
        "# Datos del mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4dLknl9HoOE"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ymwxMRf-HjNW",
        "outputId": "d3e5b0d7-6d2d-460e-d1c2-264afa9ce041"
      },
      "source": [
        "plt.imshow(train_images[0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f58380f7c50>"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYE3q22cx0Vj"
      },
      "source": [
        "# Parameters\n",
        "max_layers = 2\n",
        "num_max_units = 54\n",
        "input_dim = 28\n",
        "output_dim = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvz8DCj20z49"
      },
      "source": [
        "# Mask to freeze layers or neurons in each layer\n",
        "# Each neuron is trainable if 1, otherwise is weight = 0\n",
        "hidden_mask = tf.Variable(tf.cast(tf.random.normal((num_max_units, max_layers))>(0.5), dtype=tf.dtypes.float64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEgaDi2i3QIg"
      },
      "source": [
        "def get_trainable_layers(hidden_mask):\n",
        "  # if one column is all filled by zeros, the layer is not trainable and its weitghs have to be equal to I(54)\n",
        "  return np.all(hidden_mask.numpy() == 0, axis=0) == False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fllA46cw-SgB"
      },
      "source": [
        "# Creacin de las variables para el modelo con un diccionario\n",
        "b = {}\n",
        "w = {}\n",
        "\n",
        "for layer in range(max_layers):\n",
        "  trainable_layers = get_trainable_layers(hidden_mask)\n",
        "  if layer == 0:\n",
        "    b['b%s' % (layer+1)] = tf.Variable(tf.random.normal(shape=[num_max_units, 1], dtype=tf.dtypes.float64))\n",
        "    w['w%s' % (layer+1)] =  tf.Variable(tf.random.normal(shape=[num_max_units, input_dim**2], dtype=tf.dtypes.float64))\n",
        "  else:\n",
        "    if trainable_layers[layer] == True:\n",
        "      b['b%s' % (layer+1)]  =  tf.Variable(tf.random.normal(shape=[num_max_units, 1], dtype=tf.dtypes.float64))\n",
        "      w['w%s' % (layer+1)]  =  tf.Variable(tf.random.normal(shape=[num_max_units, num_max_units], dtype=tf.dtypes.float64))\n",
        "    else:\n",
        "      b['b%s' % (layer+1)]  =  tf.Variable(tf.zeros(shape=[num_max_units, num_max_units], dtype=tf.dtypes.float64))\n",
        "      w['w%s' % (layer+1)]  =  tf.Variable(tf.eye(num_max_units))\n",
        "\n",
        "b['b%s' % (max_layers+1)]  =  tf.Variable(tf.random.normal(shape=[output_dim, 1], dtype=tf.dtypes.float64))\n",
        "w['w%s' % (max_layers+1)]  =  tf.Variable(tf.random.normal(shape=[output_dim, num_max_units], dtype=tf.dtypes.float64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4owqgs-qAo27"
      },
      "source": [
        "# Parametros de la red neuronal\n",
        "hidden_activation = tf.nn.relu\n",
        "output_activation = tf.nn.softmax\n",
        "loss_fcn = tf.nn.sparse_softmax_cross_entropy_with_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWUQ2G5_58Ai"
      },
      "source": [
        "# Creacin de la red neuronal\n",
        "\n",
        "def get_loss(x, t, max_layers, hidden_mask):\n",
        "  a_prev = 0\n",
        "  trainable_layers = get_trainable_layers(hidden_mask)\n",
        "  for layer in range(max_layers):\n",
        "    w_aux = tf.transpose(tf.transpose(w['w%s' % (layer+1)])*hidden_mask[:,layer])\n",
        "    b_aux = tf.transpose(tf.transpose(b['b%s' % (layer+1)])*hidden_mask[:,layer])\n",
        "    if layer == 0: # For the input layer\n",
        "      a = hidden_activation(tf.matmul(w_aux, x.T) + b_aux)\n",
        "    else: # For the hidden layers\n",
        "      if trainable_layers[layer] == 0:\n",
        "        w_aux = w['w%s' % (layer+1)]\n",
        "        b_aux = b['b%s' % (layer+1)]\n",
        "      a = hidden_activation(tf.matmul(w_aux, a_prev) + b_aux)\n",
        "    a_prev = a\n",
        "  # For the ouput layer\n",
        "  a = tf.matmul(w['w%s' % (max_layers+1)], a_prev) + b['b%s' % (max_layers+1)]\n",
        "  y = output_activation(a, axis=0)\n",
        "\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVonw8Zp62VC"
      },
      "source": [
        "# Variables \n",
        "\n",
        "x_train = np.reshape(train_images, (train_images.shape[0], input_dim**2))\n",
        "x_test = np.reshape(test_images, (test_images.shape[0], input_dim**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESC-cO-YIr_t"
      },
      "source": [
        "# Custom training loop from scratch (Parameters)\n",
        "lr = 1e-1\n",
        "trigger_thr = 0.025\n",
        "nepochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YLZy-SFKPiJ"
      },
      "source": [
        "def train(lr, trigger_thr, nepochs, x, t, max_layers):\n",
        "  training_loss = []\n",
        "  for epoch in range(nepochs):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # Compute the forward pass\n",
        "      y = get_loss(x, t, max_layers, hidden_mask)\n",
        "      xentropy = loss_fcn(tf.cast(tf.reshape(t, [-1]), dtype='int32'), tf.transpose(y))\n",
        "      loss = tf.reduce_mean(xentropy)\n",
        "      \n",
        "\n",
        "    training_loss.append(loss.numpy())\n",
        "\n",
        "    trainable_layers = get_trainable_layers(hidden_mask)\n",
        "\n",
        "    for layer in range(max_layers):\n",
        "      if trainable_layers[layer] == 1:\n",
        "        w_aux = tf.transpose(tf.transpose(w['w%s' % (layer+1)])*hidden_mask[:,layer])\n",
        "        b_aux = tf.transpose(tf.transpose(b['b%s' % (layer+1)])*hidden_mask[:,layer])\n",
        "        # Compute gradients \n",
        "        db = tape.gradient(loss, b_aux)\n",
        "        dw = tape.gradient(loss, w_aux)\n",
        "        # Update parameters\n",
        "        # w['w%s' % (layer+1)] = w['w%s' % (layer+1)] - lr*dw\n",
        "        # b['b%s' % (layer+1)] = b['b%s' % (layer+1)] - lr*db\n",
        "        w['w%s' % (layer+1)].assign(w['w%s' % (layer+1)] - lr*dw)\n",
        "        b['b%s' % (layer+1)].assign(b['b%s' % (layer+1)] - lr*db)\n",
        "  return training_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHvFAw-Yl3KK"
      },
      "source": [
        "training_loss = []\n",
        "for epoch in range(nepochs):\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "    # Compute the forward pass\n",
        "    y = get_loss(x_train, train_labels, max_layers, hidden_mask)\n",
        "    xentropy = loss_fcn(tf.cast(tf.reshape(train_labels, [-1]), dtype='int32'), tf.transpose(y))\n",
        "    loss = tf.reduce_mean(xentropy)\n",
        "    layer = 0\n",
        "    w_aux = tf.Variable(tf.transpose(tf.transpose(w['w%s' % (layer+1)])*hidden_mask[:,layer]))\n",
        "    b_aux = tf.Variable(tf.transpose(tf.transpose(b['b%s' % (layer+1)])*hidden_mask[:,layer]))\n",
        "  # Compute gradients \n",
        "  db = tape.gradient(loss, b_aux)\n",
        "  dw = tape.gradient(loss, w_aux)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93fIpoWOpHny"
      },
      "source": [
        "db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "AUxrCgrqXwmx",
        "outputId": "63a4f42c-43c6-4095-f44c-27befd66476b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizacin \n",
        "plt.plot(training_loss)\n",
        "plt.grid(True)\n",
        "plt.xlabel(\"poca\")\n",
        "plt.ylabel(\"coste\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpCWCS7HMEMr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl9uJGaLUlOW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM5a0vGjUlgS"
      },
      "source": [
        "#### Con TensorFlow 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZE603UQUlgT"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "___CSrNaUlgT"
      },
      "source": [
        "# Datos del mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B58C7IWJUlgU"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "FRdY6NiFUlgV",
        "outputId": "d3e5b0d7-6d2d-460e-d1c2-264afa9ce041"
      },
      "source": [
        "plt.imshow(train_images[0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f58380f7c50>"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1L-UU1oUlgV"
      },
      "source": [
        "# Parameters\n",
        "max_layers = 2\n",
        "num_max_units = 54\n",
        "input_dim = 28\n",
        "output_dim = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzEZPHUoUlgW"
      },
      "source": [
        "# Mask to freeze layers or neurons in each layer\n",
        "# Each neuron is trainable if 1, otherwise is weight = 0\n",
        "hidden_mask = np.random.rand(num_max_units, max_layers)>(0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hr2PM0mUlgW"
      },
      "source": [
        "def get_trainable_layers(hidden_mask):\n",
        "  # if one column is all filled by zeros, the layer is not trainable and its weitghs have to be equal to I(54)\n",
        "  return np.all(hidden_mask == 0, axis=0) == False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-DepMIyUlgX"
      },
      "source": [
        "# Creacin de las variables para el modelo con un diccionario\n",
        "b = {}\n",
        "w = {}\n",
        "\n",
        "for layer in range(max_layers):\n",
        "  # trainable_layers = get_trainable_layers(hidden_mask)\n",
        "  if layer == 0:\n",
        "    b['b%s' % (layer+1)] = tf.Variable(tf.random.normal(shape=[1, num_max_units], dtype=tf.dtypes.float64))\n",
        "    w['w%s' % (layer+1)] =  tf.Variable(tf.random.normal(shape=[input_dim**2, num_max_units], dtype=tf.dtypes.float64))\n",
        "  else:\n",
        "    # if trainable_layers[layer] == True:\n",
        "    b['b%s' % (layer+1)]  =  tf.Variable(tf.random.normal(shape=[1, num_max_units], dtype=tf.dtypes.float64))\n",
        "    w['w%s' % (layer+1)]  =  tf.Variable(tf.random.normal(shape=[num_max_units, num_max_units], dtype=tf.dtypes.float64))\n",
        "    # else:\n",
        "    #  b['b%s' % (layer+1)]  =  tf.Variable(tf.zeros(shape=[num_max_units, num_max_units], dtype=tf.dtypes.float64))\n",
        "    #  w['w%s' % (layer+1)]  =  tf.Variable(tf.eye(num_max_units))\n",
        "\n",
        "b['b%s' % (max_layers+1)]  =  tf.Variable(tf.random.normal(shape=[1, output_dim], dtype=tf.dtypes.float64))\n",
        "w['w%s' % (max_layers+1)]  =  tf.Variable(tf.random.normal(shape=[num_max_units, output_dim], dtype=tf.dtypes.float64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oKnGaGsUlgX"
      },
      "source": [
        "# Parametros de la red neuronal\n",
        "hidden_activation = tf.nn.relu\n",
        "output_activation = tf.nn.softmax\n",
        "loss_fcn = tf.nn.sparse_softmax_cross_entropy_with_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qryz-fdJHTz",
        "outputId": "4a39d558-ec54-47e3-d135-e05679f5fa28"
      },
      "source": [
        "w['w%s' % (1)].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([784, 54])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykkjAUqJayn"
      },
      "source": [
        "b_aux = b['b%s' % (1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGljey0RJMcs",
        "outputId": "bbe56161-c03d-4b82-8da2-f34d5dd2c9ed"
      },
      "source": [
        "b_aux.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([1, 54])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgCbAmXuUlgX"
      },
      "source": [
        "# Creacin de la red neuronal\n",
        "\n",
        "def get_loss(x, t, max_layers):\n",
        "  a_prev = 0\n",
        "  # trainable_layers = get_trainable_layers(hidden_mask)\n",
        "  for layer in range(max_layers):\n",
        "    w_aux = w['w%s' % (layer+1)]\n",
        "    b_aux = b['b%s' % (layer+1)]\n",
        "    if layer == 0: # For the input layer\n",
        "      a = hidden_activation(tf.matmul(x, w_aux) + b_aux)\n",
        "    else: # For the hidden layers\n",
        "      # if trainable_layers[layer] == 0:\n",
        "      a = hidden_activation(tf.matmul(a_prev, w_aux) + b_aux)\n",
        "    a_prev = a\n",
        "  # For the ouput layer\n",
        "  a = tf.matmul(a_prev, w['w%s' % (max_layers+1)]) + b['b%s' % (max_layers+1)]\n",
        "  y = output_activation(a, axis=0)\n",
        "\n",
        "  return y, a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOg6MFceGW8P"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6pKxndXUlgY"
      },
      "source": [
        "# Variables \n",
        "\n",
        "x_train = tf.cast(np.reshape(train_images, (train_images.shape[0], input_dim**2)), dtype=tf.float64)\n",
        "x_test = np.reshape(test_images, (test_images.shape[0], input_dim**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzUzTo43UlgY"
      },
      "source": [
        "# Custom training loop from scratch (Parameters)\n",
        "lr = 1e-3\n",
        "trigger_thr = 0.025\n",
        "nepochs = 2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXQsa4QPUlgZ"
      },
      "source": [
        "def train(lr, trigger_thr, nepochs, x, t, max_layers):\n",
        "  training_loss = []\n",
        "  for epoch in range(nepochs):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # Compute the forward pass\n",
        "      y, a = get_loss(x, t, max_layers)\n",
        "      xentropy = loss_fcn(tf.cast(t, dtype='int32'), tf.transpose(y))\n",
        "      loss = tf.reduce_mean(xentropy)\n",
        "      \n",
        "\n",
        "    training_loss.append(loss.numpy())\n",
        "\n",
        "    # trainable_layers = get_trainable_layers(hidden_mask)\n",
        "\n",
        "    for layer in range(max_layers):\n",
        "      # if trainable_layers[layer] == 1:\n",
        "      w_aux = w['w%s' % (layer+1)]\n",
        "      b_aux = b['b%s' % (layer+1)]\n",
        "      # Compute gradients \n",
        "      db = tape.gradient(loss, b_aux)\n",
        "      dw = tape.gradient(loss, w_aux)\n",
        "      # Update parameters\n",
        "      w['w%s' % (layer+1)].assign(w['w%s' % (layer+1)] - lr*dw)\n",
        "      b['b%s' % (layer+1)].assign(b['b%s' % (layer+1)] - lr*db)\n",
        "  return training_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "rLxK3nONUlga",
        "outputId": "d64c3034-0800-4e92-a248-d25267ca5929"
      },
      "source": [
        "training_loss =  train(lr, trigger_thr, 20, x_train, train_labels, max_layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-380644f17e50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrigger_thr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-0bdd5a1dd377>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(lr, trigger_thr, nepochs, x, t, max_layers)\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;31m# Compute the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mxentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxentropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m   4350\u001b[0m   \"\"\"\n\u001b[1;32m   4351\u001b[0m   return sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 4352\u001b[0;31m       labels=labels, logits=logits, name=name)\n\u001b[0m\u001b[1;32m   4353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   4257\u001b[0m                        \u001b[0;34m\"should equal the shape of logits except for the last \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4258\u001b[0m                        \"dimension (received %s).\" % (labels_static_shape,\n\u001b[0;32m-> 4259\u001b[0;31m                                                      logits.get_shape()))\n\u001b[0m\u001b[1;32m   4260\u001b[0m     \u001b[0;31m# Check if no reshapes are required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shape mismatch: The shape of labels (received (60000,)) should equal the shape of logits except for the last dimension (received (10, 60000))."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "P8WDopXKUlgb",
        "outputId": "323cfd68-97b6-46f2-a4ee-f74385eece37"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizacin \n",
        "plt.plot(training_loss)\n",
        "plt.grid(True)\n",
        "plt.xlabel(\"poca\")\n",
        "plt.ylabel(\"coste\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bVFSPfyUlgb",
        "outputId": "0e2358e9-c26f-42ef-b852-e1f287ac2e77"
      },
      "source": [
        "len(training_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvUw4w-iXzDa",
        "outputId": "c369c856-aa75-44e9-ca4e-a238a445e699"
      },
      "source": [
        "training_loss[20-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.3678305804598163"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWPe2oXODec6"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEpMfA79EIXF"
      },
      "source": [
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKBVKCI7YHHR"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(Dense(input_shape=(784, ), units=54, activation='relu'))\n",
        "model.add(Dense(units=54, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGHrdR3cCo8G",
        "outputId": "b9fb296a-bd70-4dad-cf8b-428148900190"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 54)                42390     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 54)                2970      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                550       \n",
            "=================================================================\n",
            "Total params: 45,910\n",
            "Trainable params: 45,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRfTzJljF8on"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-55S03UYFrA0"
      },
      "source": [
        "opt = tf.keras.optimizers.RMSprop(learning_rate=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRDyYAzDCo5k"
      },
      "source": [
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbxMve0zGHof",
        "outputId": "6ec817ed-9074-44cb-c48d-b64a87ba719b"
      },
      "source": [
        "model.fit(x_train, train_labels, epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3764\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4330\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3615\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3421\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3215\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3062\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3042\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2966\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2880\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2721\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2881\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2671\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2660\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2713\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2576\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2598\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2521\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2358\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2398\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x7f2b35dff7a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 546, in __del__\n",
            "    handle=self._handle, deleter=self._deleter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1264, in delete_iterator\n",
            "    _ctx, \"DeleteIterator\", name, handle, deleter)\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b2008b350>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2Qww2yAOigk"
      },
      "source": [
        "### Opcin con Kernels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuY0B7AhGOfG"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtH0A8U-OtBB"
      },
      "source": [
        "def load_data():\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], 784))/255.\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], 784))/255.\n",
        "    y_train = tf.keras.utils.to_categorical(y_train)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8Isic7NOwsK"
      },
      "source": [
        "def plot_results(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    epochs = len(history['val_loss'])\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(epochs), history['val_loss'], label='Val Loss')\n",
        "    plt.plot(range(epochs), history['train_loss'], label='Train Loss')\n",
        "    plt.xticks(list(range(epochs)))\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(epochs), history['val_acc'], label='Val Acc')\n",
        "    plt.xticks(list(range(epochs)))\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    return plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UniLY_CDUyVV"
      },
      "source": [
        "# Parameters\n",
        "max_layers = 2\n",
        "num_max_units = 128\n",
        "\n",
        "layers = np.zeros(max_layers, dtype='uint32')\n",
        "for i in range(max_layers): layers[i] = num_max_units"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA4KXWHtUbev"
      },
      "source": [
        "# Mask to freeze layers or neurons in each layer\n",
        "# Each neuron is trainable if 1, otherwise its weight = 0\n",
        "hidden_mask = tf.Variable(tf.cast(tf.random.normal((num_max_units, max_layers))>(-1), dtype=tf.dtypes.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPS6Gg0c1NJf"
      },
      "source": [
        "hidden_mask = tf.Variable(tf.cast(tf.ones((num_max_units, max_layers)), dtype=tf.dtypes.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1GTsd_JO7NB"
      },
      "source": [
        "class FluidNetwork:\n",
        "#------------------------------------------------------------------------------- \n",
        "    def __init__(self, layers, hidden_mask, input_dim, output_dim):\n",
        "        self.layers = layers\n",
        "        self.L = len(layers)\n",
        "        self.num_features = input_dim\n",
        "        self.num_classes = output_dim\n",
        "        self.hidden_mask = hidden_mask\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        self.W = {}\n",
        "        self.b = {}\n",
        "        \n",
        "        self.dW = {}\n",
        "        self.db = {}\n",
        "        \n",
        "        self.build_net()\n",
        "#-------------------------------------------------------------------------------     \n",
        "    def build_net(self):\n",
        "      trainable_layers = self.get_trainable_layers()\n",
        "      for i in range(self.L):\n",
        "        if i == 0:\n",
        "          self.W[i] = tf.Variable(tf.random.normal(shape=(self.layers[i], input_dim)))\n",
        "          self.b[i] = tf.Variable(tf.random.normal(shape=(self.layers[i], 1)))\n",
        "        else:\n",
        "          if trainable_layers[i] == 1:\n",
        "            self.W[i] = tf.Variable(tf.random.normal(shape=(self.layers[i], self.layers[i-1])))\n",
        "            self.b[i] = tf.Variable(tf.random.normal(shape=(self.layers[i], 1))) \n",
        "          else: \n",
        "            self.W[i] = tf.Variable(tf.eye(self.layers[i], self.layers[i-1]))\n",
        "            self.b[i] = tf.Variable(tf.zeros(shape=(self.layers[i], 1)))\n",
        "      self.W[i+1] = tf.Variable(tf.random.normal(shape=(output_dim, self.layers[i])))\n",
        "      self.b[i+1] = tf.Variable(tf.random.normal(shape=(output_dim, 1))) \n",
        "#-------------------------------------------------------------------------------             \n",
        "    def get_trainable_layers(self):\n",
        "    # if one column is all filled by zeros, the layer is not trainable and its weitghs have to be equal to I(units)\n",
        "      aux = np.all(self.hidden_mask.numpy() == 0, axis=0) == False\n",
        "      # aux[self.L-1] = 1 # output is always trainable\n",
        "      return aux\n",
        "#-------------------------------------------------------------------------------\n",
        "    def forward_pass(self, X):\n",
        "        A = tf.convert_to_tensor(X, dtype=tf.float32)\n",
        "\n",
        "        for i in range(self.L+1):\n",
        "            Z = tf.matmul(A, tf.transpose(self.W[i])) + tf.transpose(self.b[i])\n",
        "            if i <= self.L:\n",
        "                A = tf.nn.relu(Z)\n",
        "            else:\n",
        "                A = Z # do not call tf.nn.softmax with the output of a softmax as it internally does it\n",
        "        return A\n",
        "#-------------------------------------------------------------------------------\n",
        "    def compute_loss(self, A, Y):\n",
        "      loss = tf.nn.softmax_cross_entropy_with_logits(Y, A)\n",
        "      return tf.reduce_mean(loss)\n",
        "#-------------------------------------------------------------------------------    \n",
        "    def update_params(self, lr):\n",
        "        for i in range(self.L+1):\n",
        "          # if i == 0:\n",
        "          self.W[i].assign_sub(lr * self.dW[i])\n",
        "          self.b[i].assign_sub(lr * self.db[i])\n",
        "          # else:\n",
        "            # self.W[i].assign_sub(lr * self.hidden_mask[:, i-1:i] * self.dW[i])\n",
        "            # self.b[i].assign_sub(lr * self.db[i] * self.hidden_mask[:, i-1:i])\n",
        "#-------------------------------------------------------------------------------\n",
        "    def predict(self, X):\n",
        "      A = self.forward_pass(X)\n",
        "      return tf.argmax(tf.nn.softmax(A), axis=1)\n",
        "#-------------------------------------------------------------------------------    \n",
        "    def freeze_weights(self):\n",
        "      for i in range(1, self.L): # the first element in hidden layer is never used\n",
        "        self.W[i].assign = self.hidden_mask[:, i][None] * self.W[i]\n",
        "        self.b[i].assign = self.hidden_mask[:, i][None] * self.b[i]    \n",
        "#-------------------------------------------------------------------------------\n",
        "    def summary(self): # Actualizar\n",
        "        num_params = 0\n",
        "        for i in range(0, self.L+1):\n",
        "            num_params += self.W[i].shape[0] * self.W[i].shape[1]\n",
        "            num_params += self.b[i].shape[0]\n",
        "        print('Input Features:', self.num_features)\n",
        "        print('Number of Classes:', self.num_classes)\n",
        "        print('Hidden Layers:')\n",
        "        print('--------------')\n",
        "        for i in range(self.L):\n",
        "            print('Layer {}, Units {}'.format(i, self.layers[i]))\n",
        "        print('--------------')\n",
        "        print('Number of parameters:', num_params)\n",
        "#-------------------------------------------------------------------------------\n",
        "    def train_on_batch(self, X, Y, lr):\n",
        "      X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
        "      Y = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
        "        \n",
        "      with tf.GradientTape(persistent=True) as tape:\n",
        "          self.freeze_weights()\n",
        "          A = self.forward_pass(X)\n",
        "          loss = self.compute_loss(A, Y)\n",
        "\n",
        "      for i in range(self.L):\n",
        "          self.dW[i] = tape.gradient(loss, self.W[i])\n",
        "          self.db[i] = tape.gradient(loss, self.b[i])\n",
        "\n",
        "      self.dW[i+1] = tape.gradient(loss, self.W[i+1])\n",
        "      self.db[i+1] = tape.gradient(loss, self.b[i+1])\n",
        "\n",
        "      del tape\n",
        "      self.update_params(lr)\n",
        "      return loss.numpy()\n",
        "#-------------------------------------------------------------------------------\n",
        "    def train(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size, lr):\n",
        "      history = {\n",
        "          'val_loss':[],\n",
        "          'train_loss':[],\n",
        "          'val_acc':[]\n",
        "      }\n",
        "      \n",
        "      for e in range(0, epochs):\n",
        "          epoch_train_loss = 0.\n",
        "          print('Epoch{}'.format(e), end='-')\n",
        "          for i in range(0, steps_per_epoch):\n",
        "              x_batch = x_train[i*batch_size:(i+1)*batch_size]\n",
        "              y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
        "              \n",
        "              batch_loss = self.train_on_batch(x_batch, y_batch,lr)\n",
        "              epoch_train_loss += batch_loss\n",
        "              \n",
        "              if i%int(steps_per_epoch/10) == 0:\n",
        "                  print(end='.')\n",
        "                  \n",
        "          history['train_loss'].append(epoch_train_loss/steps_per_epoch)\n",
        "          val_A = self.forward_pass(x_test)\n",
        "          val_loss = self.compute_loss(val_A, y_test).numpy()\n",
        "          history['val_loss'].append(val_loss)\n",
        "          val_preds = self.predict(x_test)\n",
        "          val_acc =  np.mean(np.argmax(y_test, axis=1) == val_preds.numpy())\n",
        "          history['val_acc'].append(val_acc)\n",
        "          print('Val acc:',val_acc)\n",
        "      return history\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoyO9A3pPnt7"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5TBTBu0P55f",
        "outputId": "ea90215b-1a4c-4f8f-818c-9465d277412a"
      },
      "source": [
        "input_dim = 28*28\n",
        "output_dim = 10\n",
        "net = FluidNetwork(layers, hidden_mask, input_dim, output_dim)\n",
        "net.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Features: 784\n",
            "Number of Classes: 10\n",
            "Hidden Layers:\n",
            "--------------\n",
            "Layer 0, Units 128\n",
            "Layer 1, Units 128\n",
            "--------------\n",
            "Number of parameters: 118282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMi1oIu9P-fC"
      },
      "source": [
        "# Parameters\n",
        "batch_size = 104\n",
        "epochs = 100\n",
        "steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
        "lr = 3e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm9e5Iu3zXSm"
      },
      "source": [
        "A = net.forward_pass(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0pLPCWB0ZF2"
      },
      "source": [
        "net.compute_loss(A, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUnMtzrKYSEZ"
      },
      "source": [
        "net.db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a28UavwQA6C"
      },
      "source": [
        "history = net.train(\n",
        "    x_train,y_train,\n",
        "    x_test, y_test,\n",
        "    epochs, steps_per_epoch,\n",
        "    batch_size, lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzNmZ4kuaKNj"
      },
      "source": [
        "hidden_mask = tf.Variable(tf.cast(tf.ones((num_max_units, max_layers)), dtype=tf.dtypes.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT1aINzjdi_w"
      },
      "source": [
        "net.b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FtZhQVznHPt",
        "outputId": "89f6a700-cd53-44d3-fbfb-ea350b3585fe"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEOjqhLmqbgL"
      },
      "source": [
        "### Opcion con padding en los pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3s9dC2UqjJj"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from operator import itemgetter\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import ShuffleSplit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwYjOiIX6JeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dddd919-a3ab-47bd-d42b-981f06e883ce"
      },
      "source": [
        "X , (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfjajvDwqjJk"
      },
      "source": [
        "def load_data():\n",
        "  \"Loads data and each time the function is called a new partition of xtrain is used\"\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "  # Shuffle data\n",
        "  # rs = ShuffleSplit(n_splits=5, test_size=.1)\n",
        "  # x_train, y_train  = rs.get_n_splits(X) pensar \n",
        "  # Normalize and transform to categorical\n",
        "  x_train = np.reshape(x_train, (x_train.shape[0], 784))/255.\n",
        "  x_test = np.reshape(x_test, (x_test.shape[0], 784))/255.\n",
        "  y_train = tf.keras.utils.to_categorical(y_train)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "  return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUOFYl7p3WME"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKH0VhUcqjJk"
      },
      "source": [
        "def plot_results(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    epochs = len(history['val_loss'])\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(epochs), history['val_loss'], label='Val Loss')\n",
        "    plt.plot(range(epochs), history['train_loss'], label='Train Loss')\n",
        "    plt.xticks(list(range(epochs)))\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(epochs), history['val_acc'], label='Val Acc')\n",
        "    plt.xticks(list(range(epochs)))\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    return plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3AKV6olYj-K"
      },
      "source": [
        "class FluidNetwork:\n",
        "#-------------------------------------------------------------------------------    \n",
        "  def __init__(self, layers):\n",
        "      self.layers = layers\n",
        "      self.L = len(layers) # input, hidden & output layer\n",
        "      self.num_features = layers[0]\n",
        "      self.num_classes = layers[-1]\n",
        "      \n",
        "      self.W = {}\n",
        "      self.b = {}\n",
        "      \n",
        "      self.dW = {}\n",
        "      self.db = {}\n",
        "      \n",
        "      self.setup()\n",
        "      self.new_topology = []\n",
        "#-------------------------------------------------------------------------------\n",
        "  def setup(self):\n",
        "      \n",
        "      for i in range(1, self.L):\n",
        "        self.W[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) # to enable future modifications\n",
        "        self.b[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) \n",
        "        self.W[i].assign(tf.Variable(tf.random.normal(shape=(self.layers[i],self.layers[i-1]))))\n",
        "        self.b[i].assign(tf.Variable(tf.random.normal(shape=(self.layers[i],1))))\n",
        "#-------------------------------------------------------------------------------\n",
        "  def forward_pass(self, X):\n",
        "\n",
        "      A = tf.convert_to_tensor(X, dtype=tf.float32)\n",
        "      for i in range(1, self.L):\n",
        "          Z = tf.matmul(A,tf.transpose(self.W[i])) + tf.transpose(self.b[i])\n",
        "          if i != self.L-1:\n",
        "              A = tf.nn.relu(Z)\n",
        "          else:\n",
        "              A = Z\n",
        "      return A\n",
        "#-------------------------------------------------------------------------------\n",
        "  def compute_loss(self, A, Y):\n",
        "      loss = tf.nn.softmax_cross_entropy_with_logits(Y,A)\n",
        "      return tf.reduce_mean(loss)\n",
        "#-------------------------------------------------------------------------------   \n",
        "  def update_params(self, lr):\n",
        "      for i in range(1,self.L):\n",
        "          self.W[i].assign_sub(lr * self.dW[i])\n",
        "          self.b[i].assign_sub(lr * self.db[i])\n",
        "#-------------------------------------------------------------------------------          \n",
        "  def predict(self, X):\n",
        "\n",
        "      A = self.forward_pass(X)\n",
        "      return tf.argmax(tf.nn.softmax(A), axis=1)\n",
        "#-------------------------------------------------------------------------------  \n",
        "  def info(self):\n",
        "      num_params = 0\n",
        "      for i in range(1, self.L):\n",
        "          num_params += self.W[i].shape[0] * self.W[i].shape[1]\n",
        "          num_params += self.b[i].shape[0]\n",
        "      print('Input Features:', self.num_features)\n",
        "      print('Number of Classes:', self.num_classes)\n",
        "      print('Hidden Layers:')\n",
        "      print('--------------')\n",
        "      for i in range(1, self.L-1):\n",
        "          print('Layer {}, Units {}'.format(i, self.layers[i]))\n",
        "      print('--------------')\n",
        "      print('Number of parameters:', num_params)\n",
        "#-------------------------------------------------------------------------------\n",
        "  def train_on_batch(self, X, Y, lr):\n",
        "        \n",
        "      X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
        "      Y = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
        "        \n",
        "      with tf.GradientTape(persistent=True) as tape:\n",
        "          A = self.forward_pass(X)\n",
        "          loss = self.compute_loss(A, Y)\n",
        "      for i in range(1, self.L):\n",
        "          self.dW[i] = tape.gradient(loss, self.W[i])\n",
        "          self.db[i] = tape.gradient(loss, self.b[i])\n",
        "      del tape\n",
        "      self.update_params(lr)\n",
        "      return loss.numpy()\n",
        "#-------------------------------------------------------------------------------    \n",
        "  def update_keys(self):\n",
        "    ini_list = {}\n",
        "    for i in range(1, net.L): ini_list[i] = i\n",
        "    self.b = dict(zip(ini_list, list(self.b.values())))    \n",
        "    self.W = dict(zip(ini_list, list(self.W.values())))   \n",
        "#-------------------------------------------------------------------------------\n",
        "  def activate_neurons(self, i):\n",
        "    \"Activate one neuron means adding a extra cols for W[i] and extra rows for W[i-1]\"\n",
        "    if self.layers[i-1] < self.new_topology[i-1]: # activate more neurons\n",
        "      neurons_to_act = self.new_topology[i-1] - self.layers[i-1]\n",
        "      if i != 2 :  # Only if is not the first layer of this case\n",
        "        # First add cols to W[i]\n",
        "        # W\n",
        "        aux = tf.Variable(tf.random.normal(shape=(self.new_topology[i], neurons_to_act)))\n",
        "        self.W[i].assign(tf.concat(axis=1, values=[self.W[i], aux]))\n",
        "      # Then add rows to W[i-1]\n",
        "      # W\n",
        "      aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, self.new_topology[i-2])))\n",
        "      self.W[i-1].assign(tf.concat(axis=0, values=[self.W[i-1], aux]))\n",
        "      # b\n",
        "      aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, 1)))\n",
        "      self.b[i-1].assign(tf.concat(axis=0, values=[self.b[i-1], aux]))\n",
        "    elif self.layers[i-1] > self.new_topology[i-1]: # deactivate some randomly neurons\n",
        "      neurons_to_act = self.new_topology[i-1]\n",
        "      random_index = np.random.choice(self.layers[i-1], neurons_to_act, replace=False)\n",
        "      if (i != self.L - 1 & self.L < len(self.new_topology)) | self.L >= len(self.new_topology): # Only if is not the last layer\n",
        "        # First remove extra cols from the current layer\n",
        "        # W\n",
        "        aux = pd.DataFrame(self.W[i].numpy())\n",
        "        aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "        self.W[i].assign(aux.to_numpy())\n",
        "      # Then remove extra rows from the previous layer\n",
        "      # W\n",
        "      aux = np.transpose(pd.DataFrame(self.W[i-1].numpy()))\n",
        "      aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "      self.W[i-1].assign(aux.T.to_numpy())\n",
        "      # b\n",
        "      aux = np.transpose(pd.DataFrame(self.b[i-1].numpy()))\n",
        "      aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "      self.b[i-1].assign(aux.T.to_numpy())\n",
        "#-------------------------------------------------------------------------------    \n",
        "  def AG_update(self): # weight padding\n",
        "    self.prev_W = self.W.copy()\n",
        "    self.prev_b = self.b.copy()\n",
        "    new_L = len(self.new_topology)\n",
        "\n",
        "    for i in range(2, new_L): # 2 as the input alwyas remain the same\n",
        "      if self.L < new_L : # The new topology contains more layers\n",
        "        if i <= self.L - 1 : # Only apply for hidden layers\n",
        "          self.activate_neurons(i, flag)\n",
        "        else: # add new layers,and reestructure output weights for the last layer\n",
        "          if i == new_L - 1: # copy the output weights from the previous structure\n",
        "            self.W[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) # to enable future modifications\n",
        "            self.b[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) \n",
        "            if (self.layers[-2] >= self.new_topology[-2]):\n",
        "              neurons_to_act = self.new_topology[i-1]\n",
        "              random_index = np.random.choice(self.layers[self.L-2], neurons_to_act, replace=False)\n",
        "              aux = pd.DataFrame(self.prev_W[self.L -1].numpy())\n",
        "              aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "              self.W[i].assign(aux.to_numpy())\n",
        "            else:\n",
        "              neurons_to_act = self.new_topology[-2] - self.layers[-2]\n",
        "              aux = tf.Variable(tf.random.normal(shape=(self.new_topology[i], neurons_to_act)))\n",
        "              self.W[i].assign(tf.concat(axis=1, values=[self.prev_W[self.L -1], aux]))\n",
        "\n",
        "            self.b[i].assign(self.prev_b[self.L -1])\n",
        "          # Add more layers\n",
        "          self.W[i-1] = tf.Variable(1.0, shape=tf.TensorShape(None)) # to enable future modifications\n",
        "          self.b[i-1] = tf.Variable(1.0, shape=tf.TensorShape(None)) \n",
        "          self.W[i-1].assign(tf.Variable(tf.random.normal(shape=(self.new_topology[i-1],self.new_topology[i-2]))))\n",
        "          self.b[i-1].assign(tf.Variable(tf.random.normal(shape=(self.new_topology[i-1],1))))\n",
        "\n",
        "      elif self.L > new_L: # The new topology contains less layers\n",
        "        # Only apply for hidden layers\n",
        "        self.activate_neurons(i, flag)\n",
        "        if i == new_L - 1 :\n",
        "          # First remove extra layers and then assign the ouput weights to the output layer\n",
        "          index_aux = np.arange(start=1, stop=new_L-1, step=1)\n",
        "          # index_aux[-1] = self.L - 1\n",
        "          mask = np.isin(list(self.W.keys()), index_aux) == False\n",
        "          keys_to_remove = np.array(list(self.W.keys()))[mask]\n",
        "          # W\n",
        "          d = self.W\n",
        "          l = keys_to_remove\n",
        "          list(map(d.__delitem__, filter(d.__contains__,l)))\n",
        "          # b\n",
        "          d = self.b\n",
        "          l = keys_to_remove\n",
        "          list(map(d.__delitem__, filter(d.__contains__,l)))\n",
        "          # Assign output weights to the ouput layer\n",
        "          self.W[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) # to enable future modifications\n",
        "          self.b[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) \n",
        "          if (self.layers[-2] >= self.new_topology[-2]):\n",
        "            neurons_to_act = self.new_topology[i-1]\n",
        "            random_index = np.random.choice(self.layers[self.L-2], neurons_to_act, replace=False)\n",
        "            aux = pd.DataFrame(self.prev_W[self.L -1].numpy())\n",
        "            aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "            self.W[i].assign(aux.to_numpy())\n",
        "          else:\n",
        "            neurons_to_act = self.new_topology[-2] - self.layers[-2]\n",
        "            aux = tf.Variable(tf.random.normal(shape=(self.new_topology[i], neurons_to_act)))\n",
        "            self.W[i].assign(tf.concat(axis=1, values=[self.prev_W[self.L -1], aux]))\n",
        "\n",
        "          self.b[i].assign(self.prev_b[self.L -1])           \n",
        "          break\n",
        "      else: # The new topology contains the same layers but might differ in the number of units per layer\n",
        "        self.activate_neurons(i)\n",
        "    \n",
        "    # Update layers attributes and keys\n",
        "    self.L = len(self.new_topology)\n",
        "    self.layers = self.new_topology\n",
        "    # self.update_keys()\n",
        "#-------------------------------------------------------------------------------\n",
        "  def train(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size, lr, trigger):\n",
        "\n",
        "      history = {\n",
        "          'val_loss':[],\n",
        "          'train_loss':[],\n",
        "          'val_acc':[]\n",
        "      }\n",
        "      \n",
        "      flag = 0\n",
        "      for e in range(0, epochs):\n",
        "          epoch_train_loss = 0.\n",
        "          print('Epoch{}'.format(e), end='.')\n",
        "          for i in range(0, steps_per_epoch):\n",
        "              x_batch = x_train[i*batch_size:(i+1)*batch_size]\n",
        "              y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
        "              \n",
        "              batch_loss = self.train_on_batch(x_batch, y_batch,lr)\n",
        "              epoch_train_loss += batch_loss\n",
        "              \n",
        "              if i%int(steps_per_epoch/10) == 0:\n",
        "                  print(end='.')\n",
        "                  \n",
        "          history['train_loss'].append(epoch_train_loss/steps_per_epoch)\n",
        "          val_A = self.forward_pass(x_test)\n",
        "          val_loss = self.compute_loss(val_A, y_test).numpy()\n",
        "          history['val_loss'].append(val_loss)\n",
        "          val_preds = self.predict(x_test)\n",
        "          val_acc =    np.mean(np.argmax(y_test, axis=1) == val_preds.numpy())\n",
        "          history['val_acc'].append(val_acc)\n",
        "          print('Val acc:',val_acc)\n",
        "          \n",
        "          if e>1 & flag == 0:\n",
        "            flag = 1\n",
        "            if (np.abs(history['train_loss'][-2]-history['train_loss'][-1]/history['train_loss'][-2])>=trigger):\n",
        "              print('AG trigger') \n",
        "              self.new_topology = [28*28, 128, 54, 128, 10]\n",
        "              self.AG_update()\n",
        "      return history"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS6EdO-Qbx8a"
      },
      "source": [
        "# Topological parameters\n",
        "max_layers = 3+2\n",
        "num_max_units = 128\n",
        "input_dim = 28*28\n",
        "output_dim = 10\n",
        "\n",
        "layers = np.zeros(max_layers, dtype='uint32')\n",
        "for i in range(max_layers): \n",
        "  if i == 0:\n",
        "    layers[i] = input_dim\n",
        "  elif i == max_layers-1:\n",
        "    layers[i] = output_dim\n",
        "  else:\n",
        "    layers[i] = num_max_units"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rHIwDLiY4Sg"
      },
      "source": [
        "net = FluidNetwork(layers)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRBAcbfIrbO-"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh1qxdL_Y6d3",
        "outputId": "c6c8fd6a-dd89-48c6-fff9-96c736fa5b57"
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 120\n",
        "epochs = 3\n",
        "steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
        "lr = 3e-3\n",
        "trigger = 0.1\n",
        "print('Steps per epoch', steps_per_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps per epoch 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GA7SLnCQY8g",
        "outputId": "f8d33ec1-1bd9-4692-f31c-afb04273412c"
      },
      "source": [
        "layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([784, 128, 128, 128,  10], dtype=uint32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffTuGq-mvhxG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "aa2b9fe0-1ded-4cdc-ab5a-314e10b156f0"
      },
      "source": [
        "# COMPROBACIONES:\n",
        "net.new_topology = [784, 3, 300, 20, 10]\n",
        "net.AG_update()\n",
        "for i in range(1, net.L):\n",
        " print(net.W[i].numpy().shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-a67519bb35ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# COMPROBACIONES:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_topology\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAG_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m  \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-36682206b278>\u001b[0m in \u001b[0;36mAG_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# The new topology contains the same layers but might differ in the number of units per layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate_neurons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# Update layers attributes and keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-36682206b278>\u001b[0m in \u001b[0;36mactivate_neurons\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_topology\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneurons_to_act\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m       \u001b[0;31m# Then add rows to W[i-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0;31m# W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1767\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1768\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1769\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1211\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [128,128] vs. shape[1] = [20,172] [Op:ConcatV2] name: concat"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "essBWHmy9VLb"
      },
      "source": [
        "self.prev_W = net.W.copy()\n",
        "self.prev_b = net.b.copy()\n",
        "new_L = len(net.new_topology)\n",
        "\n",
        "for i in range(2, new_L): # 2 as the input alwyas remain the same\n",
        "  if net.L < new_L : # The new topology contains more layers\n",
        "    if i <= net.L - 1 : # Only apply for hidden layers\n",
        "      net.activate_neurons(i)\n",
        "    else: # add new layers,and reestructure output weights for the last layer\n",
        "      if i == new_L - 1: # copy the output weights from the previous structure\n",
        "        net.W[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) # to enable future modifications\n",
        "        net.b[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) \n",
        "        if (net.layers[-2] >= net.new_topology[-2]):\n",
        "          neurons_to_act = net.new_topology[i-1]\n",
        "          random_index = np.random.choice(net.layers[net.L-2], neurons_to_act, replace=False)\n",
        "          aux = pd.DataFrame(self.prev_W[net.L -1].numpy())\n",
        "          aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "          net.W[i].assign(aux.to_numpy())\n",
        "        else:\n",
        "          neurons_to_act = net.new_topology[-2] - net.layers[-2]\n",
        "          aux = tf.Variable(tf.random.normal(shape=(net.new_topology[i], neurons_to_act)))\n",
        "          net.W[i].assign(tf.concat(axis=1, values=[self.prev_W[net.L -1], aux]))\n",
        "\n",
        "        net.b[i].assign(self.prev_b[net.L -1])\n",
        "      # Add more layers\n",
        "      net.W[i-1] = tf.Variable(1.0, shape=tf.TensorShape(None)) # to enable future modifications\n",
        "      net.b[i-1] = tf.Variable(1.0, shape=tf.TensorShape(None)) \n",
        "      net.W[i-1].assign(tf.Variable(tf.random.normal(shape=(net.new_topology[i-1],net.new_topology[i-2]))))\n",
        "      net.b[i-1].assign(tf.Variable(tf.random.normal(shape=(net.new_topology[i-1],1))))\n",
        "\n",
        "  elif net.L > new_L: # The new topology contains less layers\n",
        "    # Only apply for hidden layers\n",
        "    net.activate_neurons(i)\n",
        "    if i == new_L - 1 :\n",
        "      # First remove extra layers and then assign the ouput weights to the output layer\n",
        "      index_aux = np.arange(start=1, stop=new_L-1, step=1)\n",
        "      # index_aux[-1] = self.L - 1\n",
        "      mask = np.isin(list(net.W.keys()), index_aux) == False\n",
        "      keys_to_remove = np.array(list(net.W.keys()))[mask]\n",
        "      # W\n",
        "      d = net.W\n",
        "      l = keys_to_remove\n",
        "      list(map(d.__delitem__, filter(d.__contains__,l)))\n",
        "      # b\n",
        "      d = net.b\n",
        "      l = keys_to_remove\n",
        "      list(map(d.__delitem__, filter(d.__contains__,l)))\n",
        "      # Assign output weights to the ouput layer\n",
        "      net.W[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) # to enable future modifications\n",
        "      net.b[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) \n",
        "      if (net.layers[-2] >= net.new_topology[-2]):\n",
        "        neurons_to_act = net.new_topology[i-1]\n",
        "        random_index = np.random.choice(net.layers[net.L-2], neurons_to_act, replace=False)\n",
        "        aux = pd.DataFrame(self.prev_W[net.L -1].numpy())\n",
        "        aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "        net.W[i].assign(aux.to_numpy())\n",
        "      else:\n",
        "        neurons_to_act = net.new_topology[-2] - net.layers[-2]\n",
        "        aux = tf.Variable(tf.random.normal(shape=(net.new_topology[i], neurons_to_act)))\n",
        "        net.W[i].assign(tf.concat(axis=1, values=[self.prev_W[net.L -1], aux]))\n",
        "\n",
        "      net.b[i].assign(self.prev_b[net.L -1])           \n",
        "      break\n",
        "  else: # The new topology contains the same layers but might differ in the number of units per layer\n",
        "    net.activate_neurons(i)\n",
        "\n",
        "# Update layers attributes and keys\n",
        "net.L = len(net.new_topology)\n",
        "net.layers = net.new_topology"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "88yJk2u8-SAs",
        "outputId": "0b73210a-d497-42e0-f7d3-015b56c62eb0"
      },
      "source": [
        "\n",
        "if net.layers[i-1] < net.new_topology[i-1]: # activate more neurons\n",
        "  neurons_to_act = net.new_topology[i-1] - net.layers[i-1]\n",
        "  if (i != 2  & net.L < len(net.new_topology)) | net.L >= len(net.new_topology): # Only if is not the first layer of this case\n",
        "    # First add cols to W[i]\n",
        "    # W\n",
        "    aux = tf.Variable(tf.random.normal(shape=(net.new_topology[i], neurons_to_act)))\n",
        "    net.W[i].assign(tf.concat(axis=1, values=[net.W[i], aux]))\n",
        "  # Then add rows to W[i-1]\n",
        "  # W\n",
        "  aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, net.new_topology[i-2])))\n",
        "  net.W[i-1].assign(tf.concat(axis=0, values=[net.W[i-1], aux]))\n",
        "  # b\n",
        "  aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, 1)))\n",
        "  net.b[i-1].assign(tf.concat(axis=0, values=[net.b[i-1], aux]))\n",
        "elif net.layers[i-1] > net.new_topology[i-1]: # deactivate some randomly neurons\n",
        "  neurons_to_act = net.new_topology[i-1]\n",
        "  random_index = np.random.choice(net.layers[i-1], neurons_to_act, replace=False)\n",
        "  if (i != net.L - 1 & net.L < len(net.new_topology)) | net.L >= len(net.new_topology): # Only if is not the last layer\n",
        "    # First remove extra cols from the current layer\n",
        "    # W\n",
        "    aux = pd.DataFrame(net.W[i].numpy())\n",
        "    aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "    net.W[i].assign(aux.to_numpy())\n",
        "  # Then remove extra rows from the previous layer\n",
        "  # W\n",
        "  aux = np.transpose(pd.DataFrame(net.W[i-1].numpy()))\n",
        "  aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "  net.W[i-1].assign(aux.T.to_numpy())\n",
        "  # b\n",
        "  aux = np.transpose(pd.DataFrame(net.b[i-1].numpy()))\n",
        "  aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "  net.b[i-1].assign(aux.T.to_numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-7ba34b660dd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_topology\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneurons_to_act\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;31m# Then add rows to W[i-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1767\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1768\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1769\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1211\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [30,10] vs. shape[1] = [129,190] [Op:ConcatV2] name: concat"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h57_VepeY7JV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898b0250-243b-46ec-8a74-0a5e96fd99a4"
      },
      "source": [
        "history = net.train(\n",
        "    x_train,y_train,\n",
        "    x_test, y_test,\n",
        "    epochs, steps_per_epoch,\n",
        "    batch_size, lr, trigger)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch0...........Val acc: 0.2528\n",
            "Epoch1...........Val acc: 0.2592\n",
            "AG trigger\n",
            "Epoch2...........Val acc: 0.2083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "DSJDNuPHWjuV",
        "outputId": "473e0f29-9276-4151-d2be-405edc0cb235"
      },
      "source": [
        "plot_results(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWMWho2YzTL2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cdA-Z8pzTxO"
      },
      "source": [
        "### Opcion con padding en los pesos (SOL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2etl9xFtzTxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80dba679-1e3d-4823-c0d6-323cdf028e40"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from operator import itemgetter\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "!pip install fitter\n",
        "import seaborn as sns\n",
        "from fitter import Fitter, get_common_distributions, get_distributions\n",
        "import tensorflow_probability as tfp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fitter\n",
            "  Downloading fitter-1.4.0.tar.gz (27 kB)\n",
            "Collecting easydev\n",
            "  Downloading easydev-0.12.0.tar.gz (47 kB)\n",
            "\u001b[K     || 47 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fitter) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fitter) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.7/dist-packages (from fitter) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fitter) (1.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from fitter) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from fitter) (1.0.1)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from easydev->fitter) (4.8.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.5.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fitter) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fitter) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fitter) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fitter) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->fitter) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fitter) (2018.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->easydev->fitter) (0.7.0)\n",
            "Building wheels for collected packages: fitter, easydev\n",
            "  Building wheel for fitter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fitter: filename=fitter-1.4.0-py3-none-any.whl size=25025 sha256=9e2eced39df2e4bce815962d305f2722e5b8a98c9d0e819f00369640a9adbf2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/98/16/e5263962f94fbfaad79902aa94652516caccc1f1d51509e853\n",
            "  Building wheel for easydev (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easydev: filename=easydev-0.12.0-py3-none-any.whl size=64232 sha256=1bb1ae8ce71a05993f7ab2835df1fba8bea673d74f44a69ce96d84887d7f683a\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/83/fdfc4017ea44a585b6754752cc5f63f2d0d63fcc1317e7174b\n",
            "Successfully built fitter easydev\n",
            "Installing collected packages: colorlog, colorama, easydev, fitter\n",
            "Successfully installed colorama-0.4.4 colorlog-6.5.0 easydev-0.12.0 fitter-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpvjmGxpzTxP"
      },
      "source": [
        "def load_data():\n",
        "  \"Loads data and each time the function is called a new partition of xtrain is used\"\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "  # Shuffle data\n",
        "  # rs = ShuffleSplit(n_splits=5, test_size=.1)\n",
        "  # x_train, y_train  = rs.get_n_splits(X) pensar \n",
        "  # Normalize and transform to categorical\n",
        "  x_train = np.reshape(x_train, (x_train.shape[0], 784))/255.\n",
        "  x_test = np.reshape(x_test, (x_test.shape[0], 784))/255.\n",
        "  y_train = tf.keras.utils.to_categorical(y_train)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "  return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRg6Gax1zTxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "907ae460-23bf-48ef-9303-3063cf1a050a"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npkv3zdIzTxP"
      },
      "source": [
        "def plot_results(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    epochs = len(history['val_loss'])\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(epochs), history['val_loss'], label='Val Loss')\n",
        "    plt.plot(range(epochs), history['train_loss'], label='Train Loss')\n",
        "    plt.xticks(list(range(epochs)))\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(epochs), history['val_acc'], label='Val Acc')\n",
        "    plt.xticks(list(range(epochs)))\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    return plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3HUyWzFzTxP"
      },
      "source": [
        "class FluidNetwork:\n",
        "#-------------------------------------------------------------------------------    \n",
        "  def __init__(self, layers):\n",
        "      self.layers = layers\n",
        "      self.L = len(layers) # input, hidden & output layer\n",
        "      self.num_features = layers[0]\n",
        "      self.num_classes = layers[-1]\n",
        "      \n",
        "      self.W = {}\n",
        "      self.b = {}\n",
        "      \n",
        "      self.prev_W = {}\n",
        "      self.prev_b = {}\n",
        "\n",
        "      self.dW = {}\n",
        "      self.db = {}\n",
        "      \n",
        "      self.setup()\n",
        "      self.new_topology = []\n",
        "#-------------------------------------------------------------------------------\n",
        "  def setup(self):\n",
        "      \n",
        "      for i in range(1, self.L):\n",
        "        self.W[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) # to enable future modifications\n",
        "        self.b[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) \n",
        "        self.W[i].assign(tf.Variable(tf.random.normal(shape=(self.layers[i],self.layers[i-1]))))\n",
        "        self.b[i].assign(tf.Variable(tf.random.normal(shape=(self.layers[i],1))))\n",
        "#-------------------------------------------------------------------------------\n",
        "  def forward_pass(self, X):\n",
        "\n",
        "      A = tf.convert_to_tensor(X, dtype=tf.float32)\n",
        "      for i in range(1, self.L):\n",
        "          Z = tf.matmul(A,tf.transpose(self.W[i])) + tf.transpose(self.b[i])\n",
        "          if i != self.L-1:\n",
        "              A = tf.nn.relu(Z)\n",
        "          else:\n",
        "              A = Z\n",
        "      return A\n",
        "#-------------------------------------------------------------------------------\n",
        "  def compute_loss(self, A, Y):\n",
        "      loss = tf.nn.softmax_cross_entropy_with_logits(Y,A)\n",
        "      return tf.reduce_mean(loss)\n",
        "#-------------------------------------------------------------------------------   \n",
        "  def update_params(self, lr):\n",
        "      for i in range(1,self.L):\n",
        "          self.W[i].assign_sub(lr * self.dW[i])\n",
        "          self.b[i].assign_sub(lr * self.db[i])\n",
        "#-------------------------------------------------------------------------------          \n",
        "  def predict(self, X):\n",
        "\n",
        "      A = self.forward_pass(X)\n",
        "      return tf.argmax(tf.nn.softmax(A), axis=1)\n",
        "#-------------------------------------------------------------------------------  \n",
        "  def info(self):\n",
        "      num_params = 0\n",
        "      for i in range(1, self.L):\n",
        "          num_params += self.W[i].shape[0] * self.W[i].shape[1]\n",
        "          num_params += self.b[i].shape[0]\n",
        "      print('Input Features:', self.num_features)\n",
        "      print('Number of Classes:', self.num_classes)\n",
        "      print('Hidden Layers:')\n",
        "      print('--------------')\n",
        "      for i in range(1, self.L-1):\n",
        "          print('Layer {}, Units {}'.format(i, self.layers[i]))\n",
        "      print('--------------')\n",
        "      print('Number of parameters:', num_params)\n",
        "#-------------------------------------------------------------------------------\n",
        "  def train_on_batch(self, X, Y, lr):\n",
        "        \n",
        "      X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
        "      Y = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
        "        \n",
        "      with tf.GradientTape(persistent=True) as tape:\n",
        "          A = self.forward_pass(X)\n",
        "          loss = self.compute_loss(A, Y)\n",
        "      for i in range(1, self.L):\n",
        "          self.dW[i] = tape.gradient(loss, self.W[i])\n",
        "          self.db[i] = tape.gradient(loss, self.b[i])\n",
        "      del tape\n",
        "      self.update_params(lr)\n",
        "      return loss.numpy()\n",
        "#-------------------------------------------------------------------------------    \n",
        "  def update_keys(self):\n",
        "    ini_list = {}\n",
        "    for i in range(1, net.L): ini_list[i] = i\n",
        "    self.b = dict(zip(ini_list, list(self.b.values())))    \n",
        "    self.W = dict(zip(ini_list, list(self.W.values())))  \n",
        "#-------------------------------------------------------------------------------  \n",
        "  def sample_distribution(self,param, layer, shape):\n",
        "    'Param: W (1) /b (0), layer: number of weight, size: tensor shape'\n",
        "    # Find best distribution to fit in dataset\n",
        "    if param == 1:\n",
        "      dataset = pd.DataFrame(self.prev_W[layer].numpy())\n",
        "    else:\n",
        "      dataset = pd.DataFrame(self.prev_b[layer].numpy())\n",
        "\n",
        "    f = Fitter(dataset,distributions= get_common_distributions()) # only common distribution out of the 80 are tested\n",
        "    f.fit()\n",
        "    summary = pd.DataFrame(f.summary(method='bic')) \n",
        "    dist_name = summary['bic'].keys()[0] # best dist according to bic values\n",
        "    # best_params = list(f.get_best(method='bic').values())[0] # best params \n",
        "    best_params = f.fitted_param[dist_name]\n",
        "    # Invoke distribution object\n",
        "    tfd = tfp.distributions\n",
        "    # Switch-case sentence\n",
        "    if dist_name == 'cauchy':\n",
        "      return tf.cast(tf.Variable(tfd.Cauchy(loc=best_params[0], scale=best_params[1]).sample(shape)), tf.float32)\n",
        "    elif dist_name == 'chi2':\n",
        "      return tf.cast(tf.Variable(tfd.Chi2(best_params[0]).sample(shape)), tf.float32)\n",
        "    elif dist_name == 'expon':\n",
        "      return tf.cast(tf.Variable(tfd.Exponential(np.abs(best_params[0])).sample(shape)), tf.float32)\n",
        "    elif dist_name == 'exponpow':\n",
        "      return tf.cast(tf.Variable(tfd.ExponentiallyModifiedGaussian(loc=best_params[0],\n",
        "                                              scale=best_params[1],\n",
        "                                              rate=best_params[2]).sample(shape)), tf.float32)\n",
        "    elif dist_name == 'gamma':\n",
        "      return tf.cast(tf.Variable(tfd.Gamma(best_params[0], best_params[1], best_params[2]).sample(shape)), tf.float32)\n",
        "    elif dist_name == 'lognorm':\n",
        "      return tf.cast(tf.Variable(tfd.LogNormal(loc=best_params[0], scale=best_params[1]).sample(shape)), tf.float32)\n",
        "    elif dist_name == 'norm':\n",
        "      return tf.cast(tf.Variable(tfd.Normal(loc=best_params[0], scale=best_params[1]).sample(shape)), tf.float32)\n",
        "    elif dist_name == 'powerlaw': # Its not defined\n",
        "      return tf.cast(tf.Variable(tfd.Normal(loc=best_params[0], scale=best_params[1]).sample(shape)), tf.float32)\n",
        "    elif dist_name == 'rayleigh':\n",
        "      return tf.cast(tf.Variable(tfp.random.rayleigh(scale=best_params[1]).sample(shape)), tf.float32)\n",
        "    else: # uniform\n",
        "      return tf.cast(tf.Variable(tfd.Uniform(low=best_params[0], high=best_params[1]).sample(shape)), tf.float32)\n",
        "#-------------------------------------------------------------------------------\n",
        "  def activate_neurons(self, i, flag):\n",
        "    \"Activate one neuron means adding a extra cols for W[i] and extra rows for W[i-1]\"\n",
        "    if self.layers[i-1] < self.new_topology[i-1]: # activate more neurons\n",
        "      neurons_to_act = self.new_topology[i-1] - self.layers[i-1]\n",
        "      # First add cols to W[i]\n",
        "      # W\n",
        "      if flag == 1:\n",
        "        try:\n",
        "          shape = (self.layers[i], neurons_to_act)\n",
        "          aux = self.sample_distribution(1, i, shape)\n",
        "        except:\n",
        "          print('Normal dist instead')\n",
        "        finally:\n",
        "          aux = tf.Variable(tf.random.normal(shape=(self.layers[i], neurons_to_act)))\n",
        "      else:\n",
        "        aux = tf.Variable(tf.random.normal(shape=(self.layers[i], neurons_to_act)))\n",
        "      self.W[i].assign(tf.concat(axis=1, values=[self.W[i], aux]))\n",
        "      # Then add rows to W[i-1]\n",
        "      # W\n",
        "      if flag == 1:\n",
        "        try:\n",
        "          shape = (neurons_to_act, self.new_topology[i-2])\n",
        "          aux = self.sample_distribution(1, i, shape)\n",
        "        except:\n",
        "          print('Normal dist instead')\n",
        "        finally:\n",
        "          aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, self.new_topology[i-2])))\n",
        "      else:\n",
        "        aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, self.new_topology[i-2])))\n",
        "      self.W[i-1].assign(tf.concat(axis=0, values=[self.W[i-1], aux]))\n",
        "      # b\n",
        "      if flag == 1:\n",
        "        try:\n",
        "          shape = (neurons_to_act, 1)\n",
        "          aux = self.sample_distribution(0, i, shape)\n",
        "        except:\n",
        "          print('Normal dist instead')\n",
        "        finally:\n",
        "          aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, 1)))\n",
        "      else:\n",
        "        aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, 1)))\n",
        "      self.b[i-1].assign(tf.concat(axis=0, values=[self.b[i-1], aux]))\n",
        "\n",
        "    elif self.layers[i-1] > self.new_topology[i-1]: # deactivate some randomly neurons\n",
        "      neurons_to_act = self.new_topology[i-1]\n",
        "      random_index = np.random.choice(self.layers[i-1], neurons_to_act, replace=False)\n",
        "      # First remove extra cols from the current layer\n",
        "      # W\n",
        "      aux = pd.DataFrame(self.W[i].numpy())\n",
        "      aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "      self.W[i].assign(aux.to_numpy())\n",
        "      # Then remove extra rows from the previous layer\n",
        "      # W\n",
        "      aux = np.transpose(pd.DataFrame(self.W[i-1].numpy()))\n",
        "      aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "      self.W[i-1].assign(aux.T.to_numpy())\n",
        "      # b\n",
        "      aux = np.transpose(pd.DataFrame(self.b[i-1].numpy()))\n",
        "      aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "      self.b[i-1].assign(aux.T.to_numpy())\n",
        "#-------------------------------------------------------------------------------    \n",
        "  def AG_update(self, flag): # weight padding # i is the index for weights not for the layers \n",
        "    self.prev_W = self.W.copy()\n",
        "    self.prev_b = self.b.copy()\n",
        "    new_L = len(self.new_topology)\n",
        "\n",
        "    for i in range(2, new_L): # 2 as the input alwyas remain the same\n",
        "      if self.L < new_L : # The new topology contains more layers\n",
        "        if i <= self.L - 2 : # Only apply for hidden layers\n",
        "          self.activate_neurons(i, flag)\n",
        "        else: \n",
        "          if i == new_L - 1: # copy the output weights from the previous structure\n",
        "            self.W[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) # to enable future modifications\n",
        "            self.b[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) \n",
        "            if (self.layers[-2] >= self.new_topology[-2]):\n",
        "              neurons_to_act = self.new_topology[i-1]\n",
        "              random_index = np.random.choice(self.layers[self.L-2], neurons_to_act, replace=False)\n",
        "              aux = pd.DataFrame(self.prev_W[self.L -1].numpy())\n",
        "              aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "              self.W[i].assign(aux.to_numpy())\n",
        "            else:\n",
        "              neurons_to_act = self.new_topology[-2] - self.layers[-2]\n",
        "              if flag == 1: # cambiarlo a 1\n",
        "                shape = (self.new_topology[i], neurons_to_act)\n",
        "                try:\n",
        "                  aux = self.sample_distribution(1, self.L-1, shape)\n",
        "                except:\n",
        "                  print('Normal dist instead')\n",
        "                finally:\n",
        "                   aux = tf.Variable(tf.random.normal(shape=(self.new_topology[i], neurons_to_act)))\n",
        "              else:\n",
        "                 aux = tf.Variable(tf.random.normal(shape=(self.new_topology[i], neurons_to_act)))\n",
        "              self.W[i].assign(tf.concat(axis=1, values=[self.prev_W[self.L -1], aux]))\n",
        "\n",
        "            self.b[i].assign(self.prev_b[self.L -1])\n",
        "\n",
        "          else: # add more layers and reestructure weights for the previous layer\n",
        "          # Reestructure weights for the last layer\n",
        "            if i == self.L -1 :\n",
        "              if self.layers[i-1] < self.new_topology[i-1]: # activate more neurons\n",
        "                neurons_to_act = self.new_topology[i-1] - self.layers[i-1]\n",
        "                # Then add rows to W[i-1]\n",
        "                # W\n",
        "                if flag == 1:\n",
        "                  try:\n",
        "                    shape = (neurons_to_act, self.new_topology[i-2])\n",
        "                    aux = self.sample_distribution(1, i, shape)\n",
        "                  except:\n",
        "                    print('Normal dist instead')\n",
        "                  finally:\n",
        "                    aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, self.new_topology[i-2])))\n",
        "                else:\n",
        "                  aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, self.new_topology[i-2])))\n",
        "                self.W[i-1].assign(tf.concat(axis=0, values=[self.W[i-1], aux]))\n",
        "                # b\n",
        "                if flag == 1:\n",
        "                  try:\n",
        "                    shape = (neurons_to_act, 1)\n",
        "                    aux = tf.cast(self.sample_distribution(0, i, shape), tf.float32)\n",
        "                  except:\n",
        "                    print('Normal distribution')\n",
        "                  finally:\n",
        "                    aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, 1)))\n",
        "                else:\n",
        "                  aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, 1)))\n",
        "                self.b[i-1].assign(tf.concat(axis=0, values=[self.b[i-1], aux]))\n",
        "\n",
        "              elif self.layers[i-1] > self.new_topology[i-1]: # deactivate some randomly neurons\n",
        "                neurons_to_act = self.new_topology[i-1]\n",
        "                random_index = np.random.choice(self.layers[i-1], neurons_to_act, replace=False)\n",
        "                # Then remove extra rows from the previous layer\n",
        "                # W\n",
        "                aux = np.transpose(pd.DataFrame(self.W[i-1].numpy()))\n",
        "                aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "                self.W[i-1].assign(aux.T.to_numpy())\n",
        "                # b\n",
        "                aux = np.transpose(pd.DataFrame(self.b[i-1].numpy()))\n",
        "                aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "                self.b[i-1].assign(aux.T.to_numpy())\n",
        "\n",
        "          # Add more layers\n",
        "          self.W[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) # to enable future modifications\n",
        "          self.b[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) \n",
        "          if flag == 1: # cambiarlo a 1\n",
        "            try:\n",
        "              self.W[i].assign(self.sample_distribution(1, self.L-1, shape=(self.new_topology[i],self.new_topology[i-1])))\n",
        "              self.b[i].assign(tf.cast(self.sample_distribution(0, self.L-1, shape=(self.new_topology[i],1)), tf.float32))\n",
        "            except:\n",
        "              print('Normal dist instead')\n",
        "            finally:\n",
        "              self.W[i].assign(tf.Variable(tf.random.normal(shape=(self.new_topology[i],self.new_topology[i-1]))))\n",
        "              self.b[i].assign(tf.Variable(tf.random.normal(shape=(self.new_topology[i],1)))) \n",
        "          else:\n",
        "            self.W[i].assign(tf.Variable(tf.random.normal(shape=(self.new_topology[i],self.new_topology[i-1]))))\n",
        "            self.b[i].assign(tf.Variable(tf.random.normal(shape=(self.new_topology[i],1))))\n",
        "\n",
        "      elif self.L > new_L: # The new topology contains less layers\n",
        "        if i == new_L - 1 :\n",
        "        # Firstly, add/remove weights from the previous layer\n",
        "          if self.layers[i-1] < self.new_topology[i-1]: # activate more neurons\n",
        "            neurons_to_act = self.new_topology[i-1] - self.layers[i-1]\n",
        "            # Then add rows to W[i-1]\n",
        "            # W\n",
        "            if flag == 1:\n",
        "              try:\n",
        "                shape = (neurons_to_act, self.new_topology[i-2])\n",
        "                aux = self.sample_distribution(1, i, shape)\n",
        "              except:\n",
        "                print('Normal dist instead')\n",
        "              finally:\n",
        "                aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, self.new_topology[i-2])))\n",
        "            else:\n",
        "              aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, self.new_topology[i-2])))\n",
        "            self.W[i-1].assign(tf.concat(axis=0, values=[self.W[i-1], aux]))\n",
        "            # b\n",
        "            if flag == 1:\n",
        "              try:\n",
        "                shape = (neurons_to_act, 1)\n",
        "                aux = tf.cast(self.sample_distribution(0, i, shape), tf.float32)\n",
        "              except:\n",
        "                print('Normal dist instead')\n",
        "              finally:\n",
        "                aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, 1)))\n",
        "            else:\n",
        "              aux = tf.Variable(tf.random.normal(shape=(neurons_to_act, 1)))\n",
        "            self.b[i-1].assign(tf.concat(axis=0, values=[self.b[i-1], aux]))\n",
        "\n",
        "          elif self.layers[i-1] > self.new_topology[i-1]: # deactivate some randomly neurons\n",
        "            neurons_to_act = self.new_topology[i-1]\n",
        "            random_index = np.random.choice(self.layers[i-1], neurons_to_act, replace=False)\n",
        "            # Then remove extra rows from the previous layer\n",
        "            # W\n",
        "            aux = np.transpose(pd.DataFrame(self.W[i-1].numpy()))\n",
        "            aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "            self.W[i-1].assign(aux.T.to_numpy())\n",
        "            # b\n",
        "            aux = np.transpose(pd.DataFrame(self.b[i-1].numpy()))\n",
        "            aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "            self.b[i-1].assign(aux.T.to_numpy())\n",
        "\n",
        "          # Secondly, remove extra layers and then assign the ouput weights to the output layer\n",
        "          index_aux = np.arange(start=1, stop=new_L-1, step=1)\n",
        "          # index_aux[-1] = self.L - 1\n",
        "          mask = np.isin(list(self.W.keys()), index_aux) == False\n",
        "          keys_to_remove = np.array(list(self.W.keys()))[mask]\n",
        "          # W\n",
        "          d = self.W\n",
        "          l = keys_to_remove\n",
        "          list(map(d.__delitem__, filter(d.__contains__,l)))\n",
        "          # b\n",
        "          d = self.b\n",
        "          l = keys_to_remove\n",
        "          list(map(d.__delitem__, filter(d.__contains__,l)))\n",
        "          # Assign output weights to the ouput layer\n",
        "          self.W[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) # to enable future modifications\n",
        "          self.b[i] = tf.Variable(1.0, shape=tf.TensorShape(None)) \n",
        "          if (self.layers[-2] >= self.new_topology[-2]):\n",
        "            neurons_to_act = self.new_topology[i-1]\n",
        "            random_index = np.random.choice(self.layers[self.L-2], neurons_to_act, replace=False)\n",
        "            aux = pd.DataFrame(self.prev_W[self.L -1].numpy())\n",
        "            aux = aux.reindex(columns=random_index).dropna(axis=1)\n",
        "            self.W[i].assign(aux.to_numpy())\n",
        "          else:\n",
        "            neurons_to_act = self.new_topology[-2] - self.layers[-2]\n",
        "            if flag == 1:\n",
        "              try:\n",
        "                shape = (self.new_topology[i], neurons_to_act)\n",
        "                aux = self.sample_distribution(1, i, shape)\n",
        "              except:\n",
        "                print('Normal dist instead')\n",
        "              finally:\n",
        "                aux = tf.Variable(tf.random.normal(shape=(self.new_topology[i], neurons_to_act)))\n",
        "            else:\n",
        "              aux = tf.Variable(tf.random.normal(shape=(self.new_topology[i], neurons_to_act)))\n",
        "            self.W[i].assign(tf.concat(axis=1, values=[self.prev_W[self.L -1], aux]))\n",
        "\n",
        "          self.b[i].assign(self.prev_b[self.L -1])           \n",
        "          break\n",
        "        else:\n",
        "        # Only apply for hidden layers\n",
        "          self.activate_neurons(i, flag)\n",
        "      else: # The new topology contains the same layers but might differ in the number of units per layer\n",
        "        self.activate_neurons(i, flag)\n",
        "\n",
        "    # Update layers attributes and keys\n",
        "    self.L = len(self.new_topology)\n",
        "    self.layers = self.new_topology\n",
        "#-------------------------------------------------------------------------------\n",
        "  def train(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size, lr, trigger):\n",
        "\n",
        "      history = {\n",
        "          'val_loss':[],\n",
        "          'train_loss':[],\n",
        "          'val_acc':[]\n",
        "      }\n",
        "      \n",
        "      flag = 0\n",
        "      for e in range(0, epochs):\n",
        "          epoch_train_loss = 0.\n",
        "          print('Epoch{}'.format(e), end='.')\n",
        "          for i in range(0, steps_per_epoch):\n",
        "              x_batch = x_train[i*batch_size:(i+1)*batch_size]\n",
        "              y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
        "              \n",
        "              batch_loss = self.train_on_batch(x_batch, y_batch,lr)\n",
        "              epoch_train_loss += batch_loss\n",
        "              \n",
        "              if i%int(steps_per_epoch/10) == 0:\n",
        "                  print(end='.')\n",
        "                  \n",
        "          history['train_loss'].append(epoch_train_loss/steps_per_epoch)\n",
        "          val_A = self.forward_pass(x_test)\n",
        "          val_loss = self.compute_loss(val_A, y_test).numpy()\n",
        "          history['val_loss'].append(val_loss)\n",
        "          val_preds = self.predict(x_test)\n",
        "          val_acc =    np.mean(np.argmax(y_test, axis=1) == val_preds.numpy())\n",
        "          history['val_acc'].append(val_acc)\n",
        "          print('Val acc:',val_acc)\n",
        "          \n",
        "          if e>1 & flag == 0:\n",
        "            flag = 1\n",
        "            if (np.abs(history['train_loss'][-2]-history['train_loss'][-1]/history['train_loss'][-2])>=trigger):\n",
        "              print('AG trigger') \n",
        "              # GA Parameters\n",
        "              num_max_units = 128\n",
        "              num_min_units = 10\n",
        "              num_max_layers = 5\n",
        "              num_min_layers = 2\n",
        "              input_dim = 28*28\n",
        "              output_dim = 10\n",
        "              n_stall_generations = 30\n",
        "              n_iters = 30\n",
        "              sample_update = 0.1\n",
        "              # Invoke GA class \n",
        "              net_algo = self.copy_actual_instance()\n",
        "              algo = GA(net_algo, sample_update, num_max_units, num_min_units, num_max_layers, num_min_layers, input_dim, output_dim)\n",
        "              # Run GA optimization\n",
        "              algo.run_algo(n_stall_generations, n_iters)\n",
        "              # Save best NN & update params\n",
        "              best_NN = algo.best_NN\n",
        "              self.layers = best_NN.layers\n",
        "              self.L = len(self.layers) # input, hidden & output layer\n",
        "              for i in range(1, self.L):\n",
        "                self.W[i].assign(best_NN.W[i])\n",
        "                self.b[i].assign(best_NN.b[i])\n",
        "\n",
        "      return history\n",
        "#-------------------------------------------------------------------------------\n",
        "  def copy_actual_instance(self):\n",
        "    copynet = FluidNetwork(self.layers)\n",
        "    for i in range(1, copynet.L):\n",
        "      copynet.W[i].assign(self.W[i])\n",
        "      copynet.b[i].assign(self.b[i])\n",
        "    return copynet\n",
        "#-------------------------------------------------------------------------------    "
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhUkHzLEk69p"
      },
      "source": [
        "class GA():\n",
        "  \"Each cromosome represents a possible structure of a new NN\"\n",
        "#-------------------------------------------------------------------------------\n",
        "  def __init__(self, main_fluid_net, sample_params, num_max_units, num_min_units, num_max_layers, num_min_layers,input_dim, output_dim):\n",
        "    self.num_max_units = num_max_units\n",
        "    self.num_min_units = num_min_units\n",
        "    self.num_max_layers = num_max_layers\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.pop_layers = []\n",
        "    self.n_pop = []\n",
        "    self.best_fitness = []\n",
        "    self.best_NN = []\n",
        "    self.best_layers = []\n",
        "    self.pop_net = [] # the diff among pop_layers and pop_net is that the last one also incluse opt weights\n",
        "    self.pop_fitness = []\n",
        "    self.num_min_layers = num_min_layers\n",
        "    self.pop_initial()\n",
        "    self.main_fluid_net = main_fluid_net\n",
        "    self.sample_params = sample_params # % of params to be sample out of a predetermined distribution\n",
        "#-------------------------------------------------------------------------------    \n",
        "  def pop_initial(self):\n",
        "    # n_pop = int(np.ceil((self.input_dim * 50) / (5 + self.input_dim)))\n",
        "    n_pop = 3\n",
        "    n_layers =  np.random.randint(low=self.num_min_layers, high=self.num_max_layers, size=n_pop)\n",
        "    \n",
        "    pop_layers = [] # Pop of differents NN\n",
        "    for i in range(n_pop):\n",
        "      num_units_layer = np.random.randint(low=self.num_min_units, high=self.num_max_units, size=n_layers[i])\n",
        "      pop_layers.append(num_units_layer)\n",
        "\n",
        "    self.pop_initial = pop_layers\n",
        "    self.n_pop = len(self.pop_initial)\n",
        "    self.pop_layers = pop_layers\n",
        "\n",
        "    # return pop_layers\n",
        "#-------------------------------------------------------------------------------\n",
        "  def fitness(self, epochs):\n",
        "    pop_fitness = []\n",
        "    pop_net = []\n",
        "    pop_layers = []\n",
        "    sample_update = np.round(self.sample_params*self.n_pop, 0)\n",
        "    j = 0 # to control sample udpate\n",
        "    for i in range(self.n_pop):\n",
        "      layers = self.pop_layers[i]\n",
        "      if layers[0] != self.input_dim:\n",
        "        layers = np.insert(layers, 0, self.input_dim)\n",
        "      if layers[-1] != self.output_dim:\n",
        "        layers = np.insert(layers, len(layers), self.output_dim)\n",
        "      # Create de NN, starting from the previous step\n",
        "      net = self.main_fluid_net\n",
        "      net.new_topology = layers\n",
        "      # Padding\n",
        "      if j == sample_update:\n",
        "        net.AG_update(1)\n",
        "        j = 0 # start again\n",
        "      else:\n",
        "        net.AG_update(0) # 1: Sample distribution, 0: Normal initialization\n",
        "      # Load data\n",
        "      (x_train, y_train), (x_test, y_test) = load_data()\n",
        "      # Training parameters\n",
        "      batch_size = 120\n",
        "      steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
        "      lr = 3e-3\n",
        "      trigger = np.inf # to avoid an AG's trigger action\n",
        "      # Training loop\n",
        "      print(f'NN structure {i}/{self.n_pop}')\n",
        "      history = net.train(x_train, y_train, x_test, y_test, epochs, steps_per_epoch,\n",
        "        batch_size, lr, trigger)\n",
        "      pop_fitness.append(history['val_acc'][-1])\n",
        "      pop_net.append(net)\n",
        "      pop_layers.append(layers)\n",
        "      j +=1\n",
        "\n",
        "    self.pop_layers = pop_layers\n",
        "    self.pop_fitness = pop_fitness\n",
        "    self.pop_net = pop_net \n",
        "    return pop_fitness\n",
        "#-------------------------------------------------------------------------------\n",
        "  def selection(self):\n",
        "    pop_fitness =  self.pop_fitness\n",
        "    # Although the fitness values (accuracy) are normalised, as they are compared \n",
        "    # to a random threshold between 0-1 we rather apply a min-max scaler.\n",
        "    fitness_pu = np.asarray(pop_fitness)\n",
        "    fitness_pu = (fitness_pu - fitness_pu.min()) / (fitness_pu.max() - fitness_pu.min()) \n",
        "    index = random.sample(range(len(fitness_pu)), len(fitness_pu))\n",
        "\n",
        "    fathers_to_select = []\n",
        "    j = 0\n",
        "    while (len(fathers_to_select) < 2 and j < len(index)):\n",
        "      i = index[j]\n",
        "      threshold = np.random.random()\n",
        "      if fitness_pu[i] > threshold:\n",
        "        fathers_to_select.append(i)\n",
        "      j +=1\n",
        "    return fathers_to_select\n",
        "#-------------------------------------------------------------------------------\n",
        "  def crossover(self, crossover_rate, nchild): # Two children by each recombination\n",
        "    threshold = np.random.random()\n",
        "    if crossover_rate > threshold: # Then crossover operator is computed\n",
        "      # Select crossover point that is not on the end of the string\n",
        "      c = self.permutation(2) # number of children\n",
        "      # Wrap up all children\n",
        "      # c1, c2 = list(c.values())\n",
        "      return c\n",
        "    else:\n",
        "      return []\n",
        "#-------------------------------------------------------------------------------\n",
        "  def permutation(self, nchild):\n",
        "    c = {}\n",
        "    fathers_to_select = self.selection()\n",
        "    if len(fathers_to_select) < 2:\n",
        "      return []\n",
        "    else:\n",
        "      p1 = self.pop_layers[fathers_to_select[0]]\n",
        "      p2 = self.pop_layers[fathers_to_select[1]]\n",
        "      w_dW1 = np.abs(self.compute_db_weight(fathers_to_select[0]))\n",
        "      w_dW2 = np.abs(self.compute_db_weight(fathers_to_select[1]))\n",
        "      for j in range(2):\n",
        "        c[j] = []\n",
        "        n = np.random.randint(self.num_min_layers, (np.max([len(p1), len(p2)]))) # child's length\n",
        "        for i in range(n):\n",
        "          if i < min([len(p1)-1, len(p2)-1]):\n",
        "            idx = np.random.randint(1, np.min([len(p1)-1, len(p2)-1])) # -1 OJO\n",
        "            aux = np.argmin([w_dW1[idx], w_dW2[idx]])\n",
        "            if aux == 0:\n",
        "              c[j].append(p1[idx])\n",
        "            else:\n",
        "              c[j].append(p2[idx])\n",
        "          else:\n",
        "            if len(p1) > len(p2):\n",
        "              idx = np.random.randint(1, len(p1))\n",
        "              c[j].append(p1[idx])\n",
        "            else:\n",
        "              idx = np.random.randint(1, len(p2))\n",
        "              c[j].append(p2[idx])\n",
        "      return c\n",
        "#-------------------------------------------------------------------------------\n",
        "  def mutation(self, mutation_rate):\n",
        "    threshold = np.random.random()\n",
        "    if threshold < mutation_rate:\n",
        "       n_mut_pop = np.int(self.n_pop*mutation_rate)\n",
        "       return np.random.randint(low=self.num_min_layers, high=self.num_max_layers, size=n_mut_pop)\n",
        "    else:\n",
        "       return []\n",
        "#-------------------------------------------------------------------------------\n",
        "  def generational_replacement(self): \n",
        "    next_pop = []\n",
        "    i = 0\n",
        "    next_pop.append(self.best_layers)\n",
        "    while len(next_pop) < self.n_pop :\n",
        "      aux1 = self.crossover(0.8, 2)\n",
        "      aux2 = self.mutation(0.2)\n",
        "      if len(aux1) != 0:\n",
        "        aux1_0 = list(aux1.values())[0]\n",
        "        aux1_1 = list(aux1.values())[1]\n",
        "        next_pop.append(aux1_0)\n",
        "        next_pop.append(aux1_1)\n",
        "      if len(aux2) != 0:\n",
        "        next_pop.append(list(aux2))\n",
        "      i +=1\n",
        "    self.pop_layers = next_pop\n",
        "#-------------------------------------------------------------------------------\n",
        "  def compute_db_weight(self, j):\n",
        "    mean_dW = []\n",
        "    net = self.pop_net[j]\n",
        "    fitness = self.pop_fitness[j]\n",
        "    for i in range(1, net.L):\n",
        "      mean_dW.append(np.mean(net.dW[i]))\n",
        "    return mean_dW/fitness\n",
        "#-------------------------------------------------------------------------------\n",
        "  def run_algo(self, n_stall_generations, max_iters):\n",
        "     # Parameters' initialization\n",
        "     self.best_fitness = 0\n",
        "     stall_generations = 0\n",
        "     iters = 0\n",
        "     # While-loop to find the optimal parameters\n",
        "     while stall_generations < n_stall_generations or iters < max_iters:\n",
        "       iters += 1\n",
        "       pop_fitness = self.fitness(3)\n",
        "       if self.best_fitness < max(pop_fitness):\n",
        "         self.best_fitness = max(pop_fitness)\n",
        "         max_index = pop_fitness.index(self.best_fitness)\n",
        "         self.best_NN = self.pop_net[max_index]\n",
        "         self.best_layers = self.pop_layers[max_index]\n",
        "         stall_generations = 0\n",
        "         print(f'Iter {iters}.The best NN has an accuracy of {self.best_fitness }')\n",
        "       else:\n",
        "         stall_generations += 1\n",
        "         print(f'Iter {iters}.No improvement')\n",
        "\n",
        "       self.generational_replacement()\n",
        "     return self.best_NN\n",
        "    "
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_6h6OOFzTxP"
      },
      "source": [
        "# Topological parameters\n",
        "max_layers = 3+2\n",
        "num_max_units = 128\n",
        "input_dim = 28*28\n",
        "output_dim = 10\n",
        "\n",
        "layers = np.zeros(max_layers, dtype='uint32')\n",
        "for i in range(max_layers): \n",
        "  if i == 0:\n",
        "    layers[i] = input_dim\n",
        "  elif i == max_layers-1:\n",
        "    layers[i] = output_dim\n",
        "  else:\n",
        "    layers[i] = num_max_units"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA5zF12ZzTxQ"
      },
      "source": [
        "net = FluidNetwork(layers)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK4QGC6_zTxQ",
        "outputId": "63b18061-3193-4f6e-850f-ac5c5d567681"
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 120\n",
        "epochs = 3\n",
        "steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
        "lr = 3e-3\n",
        "trigger = 0.1\n",
        "print('Steps per epoch', steps_per_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps per epoch 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx1BGE4EzTxQ"
      },
      "source": [
        "# COMPROBACIONES:\n",
        "# net = FluidNetwork(layers) \n",
        "# net.new_topology = [784,  200, 1, 300, 30, 40 , 50 , 70, 10]\n",
        "# net.AG_update()\n",
        "# for i in range(1, net.L):\n",
        "# print(net.W[i].numpy().shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "262CZiIlzTxR"
      },
      "source": [
        "history = net.train(\n",
        "    x_train,y_train,\n",
        "    x_test, y_test,\n",
        "    epochs, steps_per_epoch,\n",
        "    batch_size, lr, trigger)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_H2IWHv3mZ9i",
        "outputId": "b56f52bc-976d-48fd-deb8-cdc78e9c95bb"
      },
      "source": [
        "net.new_topology = [784, 800, 100, 10]\n",
        "net.AG_update(1)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "Fn2bZ6WUzTxR",
        "outputId": "0890d0a5-a246-4081-b564-147b2893577b"
      },
      "source": [
        "plot_results(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 223
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsgYxvzHCb2J"
      },
      "source": [
        "### GA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GG3KBCtCafP"
      },
      "source": [
        "class GA():\n",
        "  \"Each cromosome represents a possible structure of a new NN\"\n",
        "#-------------------------------------------------------------------------------\n",
        "  def __init__(self, main_fluid_net, sample_params, num_max_units, num_min_units, num_max_layers, num_min_layers,input_dim, output_dim):\n",
        "    self.num_max_units = num_max_units\n",
        "    self.num_min_units = num_min_units\n",
        "    self.num_max_layers = num_max_layers\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.pop_layers = []\n",
        "    self.n_pop = []\n",
        "    self.best_fitness = []\n",
        "    self.best_NN = []\n",
        "    self.pop_net = [] # the diff among pop_layers and pop_net is that the last one also incluse opt weights\n",
        "    self.pop_fitness = []\n",
        "    self.num_min_layers = num_min_layers\n",
        "    self.pop_initial()\n",
        "    self.main_fluid_net = main_fluid_net\n",
        "    self.sample_params = sample_params # % of params to be sample out of a predetermined distribution\n",
        "#-------------------------------------------------------------------------------    \n",
        "  def pop_initial(self):\n",
        "    # n_pop = int(np.ceil((self.input_dim * 50) / (5 + self.input_dim)))\n",
        "    n_pop = 3\n",
        "    n_layers =  np.random.randint(low=self.num_min_layers, high=self.num_max_layers, size=n_pop)\n",
        "    \n",
        "    pop_layers = [] # Pop of differents NN\n",
        "    for i in range(n_pop):\n",
        "      num_units_layer = np.random.randint(low=self.num_min_units, high=self.num_max_units, size=n_layers[i])\n",
        "      pop_layers.append(num_units_layer)\n",
        "\n",
        "    self.pop_initial = pop_layers\n",
        "    self.n_pop = len(self.pop_initial)\n",
        "    self.pop_layers = pop_layers\n",
        "\n",
        "    # return pop_layers\n",
        "#-------------------------------------------------------------------------------\n",
        "  def fitness(self, epochs):\n",
        "    pop_fitness = []\n",
        "    pop_net = []\n",
        "    pop_layers = []\n",
        "    sample_update = np.round(self.sample_params*self.n_pop, 0)\n",
        "    j = 0 # to control sample udpate\n",
        "    for i in range(self.n_pop):\n",
        "      layers = self.pop_layers[i]\n",
        "      if layers[0] != self.input_dim:\n",
        "        layers = np.insert(layers, 0, self.input_dim)\n",
        "      if layers[-1] != self.output_dim:\n",
        "        layers = np.insert(layers, len(layers), self.output_dim)\n",
        "      # Create de NN, starting from the previous step\n",
        "      net = self.main_fluid_net\n",
        "      net.new_topology = layers\n",
        "      # Padding\n",
        "      if j == sample_update:\n",
        "        net.AG_update(1)\n",
        "        j = 0 # start again\n",
        "      else:\n",
        "        net.AG_update(0) # 1: Sample distribution, 0: Normal initialization\n",
        "      # Load data\n",
        "      (x_train, y_train), (x_test, y_test) = load_data()\n",
        "      # Training parameters\n",
        "      batch_size = 120\n",
        "      steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
        "      lr = 3e-3\n",
        "      trigger = np.inf # to avoid an AG's trigger action\n",
        "      # Training loop\n",
        "      print(f'NN structure {i}/{self.n_pop}')\n",
        "      history = net.train(x_train, y_train, x_test, y_test, epochs, steps_per_epoch,\n",
        "        batch_size, lr, trigger)\n",
        "      pop_fitness.append(history['val_acc'][-1])\n",
        "      pop_net.append(net)\n",
        "      pop_layers.append(layers)\n",
        "      j +=1\n",
        "\n",
        "    self.pop_layers = pop_layers\n",
        "    self.pop_fitness = pop_fitness\n",
        "    self.pop_net = pop_net \n",
        "    return pop_fitness\n",
        "#-------------------------------------------------------------------------------\n",
        "  def selection(self):\n",
        "    pop_fitness =  self.pop_fitness\n",
        "    # Although the fitness values (accuracy) are normalised, as they are compared \n",
        "    # with a random threshold between 0-1 we rather apply a min-max scaler.\n",
        "    fitness_pu = np.asarray(pop_fitness)\n",
        "    fitness_pu = (fitness_pu - fitness_pu.min()) / (fitness_pu.max() - fitness_pu.min()) \n",
        "    index = random.sample(range(len(fitness_pu)), len(fitness_pu))\n",
        "\n",
        "    fathers_to_select = []\n",
        "    j = 0\n",
        "    while (len(fathers_to_select) < 2 and j < len(index)):\n",
        "      i = index[j]\n",
        "      threshold = np.random.random()\n",
        "      if fitness_pu[i] > threshold:\n",
        "        fathers_to_select.append(i)\n",
        "      j +=1\n",
        "    return fathers_to_select\n",
        "#-------------------------------------------------------------------------------\n",
        "  def crossover(self, crossover_rate, nchild): # Two children by each recombination\n",
        "    threshold = np.random.random()\n",
        "    if crossover_rate > threshold: # Then crossover operator is computed\n",
        "      # Select crossover point that is not on the end of the string\n",
        "      c = self.permutation(2) # number of children\n",
        "      # Wrap up all children\n",
        "      # c1, c2 = list(c.values())\n",
        "      return c\n",
        "    else:\n",
        "      return []\n",
        "#-------------------------------------------------------------------------------\n",
        "  def permutation(self, nchild):\n",
        "    c = {}\n",
        "    fathers_to_select = self.selection()\n",
        "    if len(fathers_to_select) < 2:\n",
        "      return []\n",
        "    else:\n",
        "      p1 = self.pop_layers[fathers_to_select[0]]\n",
        "      p2 = self.pop_layers[fathers_to_select[1]]\n",
        "      w_dW1 = np.abs(self.compute_db_weight(fathers_to_select[0]))\n",
        "      w_dW2 = np.abs(self.compute_db_weight(fathers_to_select[1]))\n",
        "      for j in range(2):\n",
        "        c[j] = []\n",
        "        n = np.random.randint(self.num_min_layers, (np.max([len(p1), len(p2)]))) # child's length\n",
        "        for i in range(n):\n",
        "          if i < min([len(p1)-1, len(p2)-1]):\n",
        "            idx = np.random.randint(1, np.min([len(p1)-1, len(p2)-1])) # -1 OJO\n",
        "            aux = np.argmin([w_dW1[idx], w_dW2[idx]])\n",
        "            if aux == 0:\n",
        "              c[j].append(p1[idx])\n",
        "            else:\n",
        "              c[j].append(p2[idx])\n",
        "          else:\n",
        "            if len(p1) > len(p2):\n",
        "              idx = np.random.randint(1, len(p1))\n",
        "              c[j].append(p1[idx])\n",
        "            else:\n",
        "              idx = np.random.randint(1, len(p2))\n",
        "              c[j].append(p2[idx])\n",
        "      return c\n",
        "#-------------------------------------------------------------------------------\n",
        "  def mutation(self, mutation_rate):\n",
        "    threshold = np.random.random()\n",
        "    if threshold < mutation_rate:\n",
        "       n_mut_pop = np.int(self.n_pop*mutation_rate)\n",
        "       return np.random.randint(low=self.num_min_layers, high=self.num_max_layers, size=n_mut_pop)\n",
        "    else:\n",
        "       return []\n",
        "#-------------------------------------------------------------------------------\n",
        "  def generational_replacement(self): \n",
        "    next_pop = []\n",
        "    i = 0\n",
        "    next_pop.append(self.best_NN)\n",
        "    while len(next_pop) < self.n_pop :\n",
        "      aux1 = self.crossover(0.8, 2)\n",
        "      aux2 = self.mutation(0.2)\n",
        "      if len(aux1) != 0:\n",
        "        aux1_0 = list(aux1.values())[0]\n",
        "        aux1_1 = list(aux1.values())[1]\n",
        "        next_pop.append(aux1_0)\n",
        "        next_pop.append(aux1_1)\n",
        "      if len(aux2) != 0:\n",
        "        next_pop.append(list(aux2))\n",
        "      i +=1\n",
        "    self.pop_layers = next_pop\n",
        "#-------------------------------------------------------------------------------\n",
        "  def compute_db_weight(self, j):\n",
        "    mean_dW = []\n",
        "    net = self.pop_net[j]\n",
        "    fitness = self.pop_fitness[j]\n",
        "    for i in range(1, net.L):\n",
        "      mean_dW.append(np.mean(net.dW[i]))\n",
        "    return mean_dW/fitness\n",
        "#-------------------------------------------------------------------------------\n",
        "  def run_algo(self, n_stall_generations, max_iters):\n",
        "     # Parameters' initialization\n",
        "     self.best_fitness = 0\n",
        "     stall_generations = 0\n",
        "     iters = 0\n",
        "     # While-loop to find the optimal parameters\n",
        "     while stall_generations < n_stall_generations or iters < max_iters:\n",
        "       iters += 1\n",
        "       pop_fitness = self.fitness(3)\n",
        "       if self.best_fitness < max(pop_fitness):\n",
        "         self.best_fitness = max(pop_fitness)\n",
        "         max_index = pop_fitness.index(self.best_fitness)\n",
        "         self.best_NN = self.pop_net[max_index]\n",
        "         stall_generations = 0\n",
        "         print(f'Iter {iters}.The best NN has an accuracy of {self.best_fitness }')\n",
        "       else:\n",
        "         stall_generations += 1\n",
        "         print(f'Iter {iters}.No improvement')\n",
        "\n",
        "       self.generational_replacement()\n",
        "     return self.best_NN\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEKYJcR6X-Jh"
      },
      "source": [
        "num_max_units = 128\n",
        "num_min_units = 10\n",
        "num_max_layers = 5\n",
        "num_min_layers = 2\n",
        "input_dim = 28*28\n",
        "output_dim = 10\n",
        "sample_update = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXR3njMZUc9L"
      },
      "source": [
        "algo = GA(net, sample_update, num_max_units, num_min_units, num_max_layers, num_min_layers, input_dim, output_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh-sJMv_YOqN",
        "outputId": "0f1ba476-a6bf-45f6-c78f-f0e368949cd3"
      },
      "source": [
        "algo.run_algo(1, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN structure 0/3\n",
            "Epoch0...........Val acc: 0.1021\n",
            "Epoch1...........Val acc: 0.1015\n",
            "Epoch2...........Val acc: 0.1014\n",
            "NN structure 1/3\n",
            "Epoch0...........Val acc: 0.1012\n",
            "Epoch1...........Val acc: 0.1009\n",
            "Epoch2...........Val acc: 0.101\n",
            "NN structure 2/3\n",
            "Epoch0...........Val acc: 0.1103\n",
            "Epoch1...........Val acc: 0.1161\n",
            "Epoch2...........Val acc: 0.1202\n",
            "Iter 1.The best NN has an accuracy of 0.1202\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.FluidNetwork at 0x7f151b87c5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bffq_iOOqshZ"
      },
      "source": [
        "## Samplear distribucion de pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x07fVKfS1D1N"
      },
      "source": [
        "def sample_distribution(param, layer, shape):\n",
        "  'Param: W (1) /b (0), layer: number of weight, size: tensor shape'\n",
        "  # Find best distribution to fit in dataset\n",
        "  if param == 1:\n",
        "    dataset = pd.DataFrame(net.W[layer].numpy())\n",
        "  else:\n",
        "    dataset = pd.DataFrame(net.b[layer].numpy())\n",
        "\n",
        "  f = Fitter(dataset,distributions= get_common_distributions()) # only common distribution out of the 80 are tested\n",
        "  f.fit()\n",
        "  summary = pd.DataFrame(f.summary(method='bic')) \n",
        "  dist_name = summary['bic'].keys()[0] # best dist according to bic values\n",
        "  # best_params = list(f.get_best(method='bic').values())[0] # best params \n",
        "  best_params = f.fitted_param[dist_name]\n",
        "  # Invoke distribution object\n",
        "  tfd = tfp.distributions\n",
        "  # Switch-case sentence\n",
        "  if dist_name == 'cauchy':\n",
        "    return tfd.Cauchy(loc=best_params[0], scale=best_params[1]).sample(shape)\n",
        "  elif dist_name == 'chi2':\n",
        "    return tfd.Chi2(best_params[0]).sample(shape)\n",
        "  elif dist_name == 'expon':\n",
        "    return tfd.Exponential(np.abs(best_params[0])).sample(shape)\n",
        "  elif dist_name == 'exponpow':\n",
        "    return tfd.ExponentiallyModifiedGaussian(loc=best_params[0],\n",
        "                                             scale=best_params[1],\n",
        "                                             rate=best_params[2]).sample(shape)\n",
        "  elif dist_name == 'gamma':\n",
        "    return tfd.Gamma(concentration==best_params[0], rate=best_params[1],\n",
        "                                          log_rate=best_params[2]).sample(shape)\n",
        "  elif dist_name == 'lognorm':\n",
        "    return tfd.LogNormal(loc=best_params[0], scale=best_params[1]).sample(shape)\n",
        "  elif dist_name == 'norm':\n",
        "    return tfd.Normal(loc=best_params[0], scale=best_params[1]).sample(shape)\n",
        "  elif dist_name == 'powerlaw': # Its not defined\n",
        "    return tfd.Normal(loc=best_params[0], scale=best_params[1]).sample(shape)\n",
        "  elif dist_name == 'rayleigh':\n",
        "    return tfp.random.rayleigh(loc=best_params[0], scale=best_params[1]).sample(shape)\n",
        "  else: # uniform\n",
        "    return tfd.Uniform(low=best_params[0], high=best_params[1]).sample(shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Gmp-mv1L5Px7",
        "outputId": "4bdeb39e-73be-434a-dc7e-554c06675f1a"
      },
      "source": [
        "sample_distriibution(1, 3, (3,1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXjU1b348feZPckkIQsJWYCEHUJYkrDLKu7KIri1Vbi2rtfe2/Za6/3ptba0tlVba3vbWpdbsFZAQCkoakUI+w5hS4BACCQs2ZdJMvuc3x+TiQSyTEJ2zut5eB4y3+8538+E4ZOTswopJYqiKEr3p+nsABRFUZS2oRK6oihKD6ESuqIoSg+hErqiKEoPoRK6oihKD6HrrAdHRkbKhISEznp8PdXV1QQFBXV2GM1ScbYtFWfbUnG2naZiPHDgQLGUsneDF6WUnfInNTVVdhWbN2/u7BD8ouJsWyrOtqXibDtNxQjsl43kVdXloiiK0kOohK4oitJDqISuKIrSQ3TaoKiiKD2D0+kkPz+f0NBQsrKyOjucZnWHOENDQzl79izx8fHo9Xq/y6mErijKdcnPzyc4OJiIiAhCQkI6O5xmWSwWgoODOzuMJlVWVuJwOMjPzycxMdHvcqrLRVGU62Kz2YiIiEAI0dmh9BhCCCIiIrDZbC0qpxK6oijXTSXzttea76nqclFuOKUX83HabHiczs4ORVHalEroyg2lMDeHf/y/H+FxuwDIWbeCsbfPIfWuuZ0cmaJcP9XlotwwpJRsXvo2HreLwNBeoNFQUVhA+vvvUHw+t7PDUzqJy+Xq7BDajEroyg3j1O4d5GcdwxQcwr/97i1SvvefjLr5dgB2f7yyk6NTrkdubi7Dhw/nscceIykpiVtvvRWr1UpGRgYTJ05k1KhRzJ8/n7KyMgBmzJjBD37wA9LS0njzzTeZMWMGP/zhD0lLS2P48OHs27ePe++9l8GDB/Piiy928rvzn+pyUW4ITruNLR+8B8BNDzyMyWxGaLVMXPAgx7ds5OTu7UzKf4iI+H6dHGk393JoO9Vb0ewt2dnZLF++nHfeeYf777+fNWvW8Oqrr/LHP/6R6dOn89JLL/Gzn/2MJUuWAOBwONi/fz8A69evx2AwsH//ft58803mzp3LgQMHCA8PZ+DAgfzwhz8kIiKifd5bG1ItdOWGsG/dx1iKi+idMIDkm2+tez04IpKRM28BKVUrvZtLTExkzJgxAKSmpnLmzBnKy8uZPn06AIsWLWLr1q119z/wwAP1ys+ZMweA5ORkkpKSiImJwWg0MmDAAPLy8jroXVwf1UJXeryainL2rVsDwKxFj6PRaOtdHz/vPo5u+oqTO7cxaeFDhMfGd0aYPYMfLen2YjQa6/6u1WopLy9v8v6rt6f1lddoNPXq0mg03aaf3a8WuhDidiHESSHEaSHE8w1cXyyEKBJCZNT++V7bh6oorXN6/x5cDjsJo1OIHzHymushkVEkzbgZKT2qld6DhIaGEhYWxrZt2wD4+9//Xtda76maTehCCC3wJ+AOYATwkBBiRAO3rpRSjqn9824bx6korZZzcC8Ag8ZNavSeCfPuRwgNJ3duw2Gt6ajQlHa2bNkyfvzjHzNq1CgyMjJ46aWXOjukduVPl8t44LSUMgdACLECmAtktmdgitIWnA47545kADAgdVyj94VGRdNn8BAunTrB+eNHGZQ2oaNCVNpAQkICx44dq/v62Wefrfv77t27691rsVhIT0+v99qVX8+YMYMZM2Y0eK2r8yehxwFXjgjkAw192hcIIaYBp4AfSimvGUUQQjwOPA4QHR3dZb5RVVVVXSaWpqg4W67iXA4uh53AyGgOHDlW79o1cYaGA7Bzwzryq6wdGGXTutL3syGhoaFYLBbcbjcWi6Wzw2lWd4jTF6PNZmvRv31bDYquB5ZLKe1CiCeAZcCsq2+SUr4NvA2QlpYmr/wp2JnS09PpKrE0RcXZchvfPQ7AqOmzmHJVTFfHeSkuhg/37cRRdJnp06d3mf1JutL3syFZWVkEBwd3i10MoXvstuiL0WQyMXbsWL/L+TMoegHoe8XX8bWv1ZFSlkgp7bVfvguk+h2BorQTKSVnDu4DYGDq+Gbvjx44CJM5mIrCAsovX2zv8BSlzfmT0PcBg4UQiUIIA/AgsO7KG4QQMVd8OQfo2rvHKzeEwtwcqkqKCQoLJzpxYLP3azRa+o/ytobOZhxs7/AUpc01m9CllC7gGeBLvIn6IynlcSHEz4UQc2pv+w8hxHEhxGHgP4DF7RWwovjLN7tlQMo4hMa/NXSJY7y/XOYePtBucSlKe/GrD11KuQHYcNVrL13x9/8G/rttQ1OU65NzwJfQm+9u8fG10PMyj+JyONAZDO0Sm6K0B7X0X+mRqsvLuHwmG53eQP/k0X6XM4eF07t/Ii67nQsn1MxcpXtRCV3pkfIyjwIQP2IkeqOpRWUTartdzqpuF6WbUQld6ZEunToBQOyQ4S0umzg6BYDcDJXQu5MlS5YwdOhQbrrpJh566CFef/113nnnHcaNG8fo0aNZsGABNTXeVcCLFy/mqaeeYuLEiQwYMID09HQeffRRhg8fzuLFi+vqNJvN/PjHPyYpKYnZs2ezd+9eZsyYwYABA1i3zjs3JDc3l6lTp5KSkkJKSgo7d+7sjLcPqM25lB7qYrY3occMGdbisrFDh6MzGinJP09NZQWBIe20JWwPlLwsuV3qPbroaJPX9+3bx5o1azh8+DBOp5OUlBRSU1O59957eeyxxwB48cUXee+99+oSdllZGbt27WLdunXMmTOHHTt28O677zJu3DgyMjIYM2YM1dXVzJo1i9dee4358+fz4osv8tVXX5GZmcmiRYuYM2cOUVFRfPXVV5hMJrKzs3nooYfqtuXtaCqhKz2Oy+Gg8GwOCEHMoKEtLq/V6YlOHMSFE8e5fPoUA1Ia3zJA6Rp27NjB3LlzMZlMmEwm7rnnHgCOHTvGiy++SHl5OVVVVdx22211Ze655x6EECQnJxMdHU1ysveHUVJSErm5uYwZMwaDwcDtt3sPQUlOTsZoNKLX60lOTiY3NxcAp9PJM888Q0ZGBlqtllOnTnXsm7+CSuhKj1OQcxqP20VkvwSMgYGtqiNm8FAunDjOpdMnVUJvgeZa0h1t8eLFrF27ltGjR7N06dJ6y+j92S5Xr9fXrRi+8r4r73njjTeIjo7m8OHDeDweTKaWjdm0JdWHrvQ4vu6W2MEt727xiRnsbdlfyj7ZJjEp7WvKlCmsX78em81GVVUVn376KeBdQh8TE4PT6eQf//hHuzy7oqKCmJgYNBoNf//733G73e3yHH+ohK70OL4B0db0n/v4Evrl06eQHk+bxKW0n3HjxjFnzhxGjRrFHXfcQXJyMqGhoSxZsoQJEyYwZcoUhg1r/eehKU8//TTLli1j9OjRnDhx4pqDMzqS6nJRehQpJRdPeXeeiL2OhB4cHok5PIKq0hJKL10gIq5v84WUTvXss8/y8ssvU1NTw7Rp00hNTSUlJYWnnnqq3n0Wi4WlS5fWfX311rtXXquqqqr7+8svv1yvHt+1wYMHc+TIkbrXf/Ob37TBu2kd1UJXepTKokKqy8swmYMJi4m7rrp8A6qXT3feIJfiv8cff5wxY8aQkpLCggULSElJ6eyQOpxqoSs9St10xcFDr3v725jBQ8neu5NL2SdImn5zW4SntKMPP/yws0PodKqFrvQodQuKrmNA1MfXQr+UrVroSvegErrSo1xsgwFRn+gBgxAaDUXnz+K02667PkVpbyqhKz2G02Gn6FwOQmiIGTTkuuvTm0xE9ktAejwU5JxugwgVpX2phK70GN4FRW4i+/XHENC6BUVX8/1guKQGRpVuQCV0pccorG1F9xk4uM3qjKnti79UO9iqdE1ms7mzQ+gSVEJXeoyCs2cAiEoc1GZ11g2Mqha60gDf8v+uQk1bVHqMwtqEHj2g+fND/RUeG4chIJCqkmKqykoxh4W3Wd1K25NS8txzz/H5558jhODFF1/kgQcewOPx8Mwzz7Bp0yZiY2MxmUw8+uijLFy4kISEBBYtWsT69etxOp2sWrWKYcOGUVpayqOPPkpOTg6BgYG8/fbbjBo1ipdffpkzZ86Qk5NDv379GDp0KGfPniUnJ4fz58/zxhtvsHv3bj7//HPi4uJYv349er2+Q96/SuhKj+C02yjJz0NoNET2S2izeoVGQ1TiAPIzj1GYe0Yl9GZkDWv5/vP+GH7Cv3PnP/74YzIyMjh8+DDFxcWMGzeOadOmsWPHDnJzc8nMzCQnJ4dx48bx6KOP1pWLjIzk4MGD/PnPf+b111/n3Xff5ac//Sljx45l7dq1bNq0iUceeYSMjAwAMjMz2b59OwEBAXUJfvPmzWRmZjJp0iTWrFnDq6++yvz58/nss8+YN29eu3xfrqa6XJQeoehcLlJ6iIjvh95gbL5AC0Qnelv8hWdz2rRepe1t376dhx56CK1WS3R0NNOnT2ffvn1s376d++67D41GQ3R0NDNnzqxX7t577wUgNTW1blvc7du38/DDDwMwa9YsSkpKqKysBGDOnDkEBATUlb/jjjvqttV1u931ttz11dcRVAtd6RHqulsS2667xScqwZfQz7R53T2Nvy3prsa3La5Wq/WrX/zqDbiu3Fb36i13O7KfXbXQlR6hPQZEfaJ8LfRcldC7uqlTp7Jy5UrcbjdFRUVs3bqV8ePHM2XKFNasWYPH46GwsLDevuhN1eXbcjc9PZ3IyEhCQkLa+R1cH9VCV3oEf1voCc9/Vvf3pbf7t81peGw8Or2BisICbFVVmNQUuS5r/vz57Nq1i9GjRyOE4NVXX6VPnz4sWLCAr7/+mhEjRhAbG0tKSgqhoU0fLfjyyy/z6KOPMmrUKAIDA1m2bFkHvYvWUwld6fZcTifFeedACHonJLZ5/Rqtlt79E7l0+iSFuWfoN3J0mz9DuT6+rWyFELz22mu89tpr9a5rNBpef/11zGYzubm53HzzzXVHzl3Zx52WllbXeg8PD2ft2rXXPOvqbXQb21a3oWvtTSV0pdsryTuHx+0iPDYegymg+QKtEJU40JvQz6qE3l3dfffdlJeXY7PZ+J//+R/69OnT2SG1OZXQlW6v4Kx3hWhUOwyI+kQlDqh9lupH7658LW+LxUJwcHDnBtNO1KCo0u19s6Co7QdEfaJrB1sLc9XURaXrUgld6fYK2nHKok9E3/5otFpKL+bjtKmtdJWuSSV0pVtzu1wUnTsLQO+EAe32HJ1eT0R8P5CSwtrnKUpXoxK60q2VXsjD7XTSKzoGU1D7TiesW2Ck5qMrXZRK6Eq35uvTbs8BUZ+6BUZqYFTpovxK6EKI24UQJ4UQp4UQzzdx3wIhhBRCpLVdiIrSOF9yjWrH7hYfXx+9mumidFXNJnQhhBb4E3AHMAJ4SAgxooH7goH/BPa0dZCK0pi6FnoHJPTeCYkgBCV553E5ne3+PKVlPvjgA8aPH8+YMWN44okn2LNnD6NGjcJms1FdXU1SUhLHjh1j27ZtTJs2jbvuuouhQ4fy5JNP4vF4AFi+fDnJycmMHDmSn/zkJ3V1m81mXnjhBUaPHs3EiRMpKCgAYPHixTz55JOkpaUxZMgQPv30UwBsNhv/9m//RnJyMmPHjmXz5s0A3HXXXRw5cgSAsWPH8vOf/xyAl156iXfeeee6vwf+zEMfD5yWUuYACCFWAHOBzKvuWwL8BvjxdUelKH6QUvrV5TL4x2uZfXEfU8uPstJygaCqahASzU7JKbOG0H5hRNx1B7rUe6DPaNA03M4xmAII6xNL2aULlOSfb9dZNd3Vn57c1C71/vtbs5q8npWVxcqVK9mxYwd6vZ6nn36akydPMmfOHF588UWsVivf+c53GDlyJOfPn2fv3r1kZmbSv39/br/9dj7++GMmT57MT37yEw4cOEBYWBi33nora9euZd68eVRXVzNx4kR++ctf8txzz/HOO+/w4osvAt6Vpnv37uXMmTPMnDmT06dP86c//QkhBEePHuXEiRPceuutnDp1iqlTp7Jt2zb69++PTqdjx44dAGzbto233nrrur9P/iT0OCDviq/zgQlX3iCESAH6Sik/E0I0mtCFEI8DjwNER0f7tUFOR6iqquoysTRFxVmfvbIch7UGXWAQ+zIO17t29EIFhioL/fdtZe3+XWhsV+54J7x/qsFdCKU55RRt/ZCqvu8TPUJP9eRFFEdOgNod8+qpHXjd9sUGIocnt9+bu0JX/3cPDQ3FYrHgdrvb7RkWi6XJ65999hn79+8nNTUVAKvVSmhoKM8++ywzZszAaDTyy1/+EovFgsfjITU1ld69e1NTU8P8+fPZtGkTLpeLKVOmYDKZsFqtLFiwgI0bN3LzzTdjMBiYPn06FouFESNGsHnzZiwWC06nkzlz5lBdXU2fPn3o378/Bw4cID09nSeeeAKLxUJcXBzx8fEcOnSI1NRU3nrrLaKjo5k9ezabN2+moKCAnJwcYmNj696n2+3GYrFgs9la9G9/3StFhRAa4HfA4ubulVK+DbwNkJaWJmfMmHG9j28T6enpdJVYmqLirC97z06OAfFDhtV7npSS1Q++wBPH/onO7f1VOicadg/TkNcbLoUG4nGbGexxElHlYfDRclJOQ+g5PbZzUHTmXcbdthHz/Ncgdmy9ZwZWFLPt9EnCjPoO+7fo6v/uWVlZBAcHY7FYmm1Jtxej0cjixYv51a9+Ve/1S5cuUVNTg9vtRq/XExQUhEajQafT1a0WNZlMGI1GAgIC0Ov19V43GAwEBwej1+vrdlo0m80IIepeDwgIqCuj1Woxm83odDoCAwPrvR4UFERqaipPPvkkQ4YM4ZZbbsFisbBixQrS0tLqrV71rWY1mUyMHVv/M9gUfwZFLwB9r/g6vvY1n2BgJJAuhMgFJgLr1MCo0t580wev7D93lZSQ//hj/PvhT9C5PewfJPjpt7W89FAUKxIXskU8x8mSn5Jd/iz3T/4FS17ZyZ0fbeXMsufZdWd/HDroc0rP8fcusOWVebD/b/WeGdXfu/lX0Tm1YrQrufnmm1m9ejWFhYUAlJaWcu7cOZ544gmWLFnCt7/97Xp94nv37uXs2bN4PB5WrlzJTTfdxPjx49myZQvFxcW43W6WL1/O9OnTm332qlWr8Hg8dcfSDR06tN7Wu6dOneL8+fMMHToUg8FA3759WbVqFZMmTWLq1Km8/vrrTJs2rU2+D/600PcBg4UQiXgT+YPAt3wXpZQVQKTvayFEOvCslHJ/m0SoKI24ekD05if/yiu73ibEXkO1Ed6+Q8OhAb0oK7oHV+5IvF0t14oMiGTu+EUwfhEH9n/KxZd+SkJODSEbA1ld/QvmLTiC7o5XQau/Ym/0s0iPB9FIf7vSsUaMGMEvfvELbr31VjweD3q9nrlz56LX6/nWt76F2+1m8uTJbNrk7eMfN24czzzzDKdPn2bmzJnMnz8fjUbDr3/9a2bOnImUkrvuuou5c+c2++x+/foxfvx4KisreeuttzCZTDz99NM89dRTJCcno9PpWLp0ad0hGFOnTuXrr78mICCAqVOnkp+fz9SpU9vk+9BsQpdSuoQQzwBfAlrg/6SUx4UQPwf2SynXtUkkiuIn357m/3Y+EzPehG49fJjXdvyZAKeDzL7wxzlaLM5USnIW4P3Y+ic17W7c628n/bUfEbv0K5J2GVhp+4y7i08S+q3VBIb2whwWTlVZKeUFlwiLiWufN6m02AMPPMADDzzQ4DWtVsuePd4JeBs2bCAkJKRuRsqVHnroIR566KFrXr9yS9yFCxeycOHCuq9nz559zYCmyWTib3+r/9udz5IlS1iyZAkAsbGxSCmbeWf+86sPXUq5Adhw1WsvNXLvjOsPS1GaZnJbMbur0ZsCMFy4yLnHHyfA6WDPUMGf79FiKbgPqyXV7/quPPjC6zZmToIf7fmKlENaPrXlcJt4kElZ3+V2m5kESinMPasSutKlqN8XlW6pt70YgIjIKPK+9xiyxsb2EYK/3qOjNO/7LUrmjdkcfRs/vekhrHpBSpbgn1+e4hXjHyk2RABqC4DuaurUqQ22zltj6dKl9VrrnU0ldKVb6u3wJnTTiZNIm50tIwXv3qmlOO9pXPa2azUfDE/l5xMfxqWByQcFlwrOMzMwA1Bb6Spdj0roSrcUbffOZgguq+RYP8E/7tRRkf8ETnvfZkp+4+iFChKe/6yB7pb6MiJG8Uaqd3Ds5nQt5Xhb5kUqoStdjEroSvcjJYMrcwFw6ez8YZ6gPO872Gxtf56oz6a4qbw/cioa4JaNEjRuqsvLqC4va7dnKkpLqYSudDtzc7YitW6ElPzv3W6wTMNiTWr35y4fOIdNCUMwuSDQ6gCg8ERGuz9XUfylErrSrdhPn+bes1+DEFiNDtymePLK7uqYhwvBH0cu4kJIEFGVdgCyN/wWajd2UnqmxYsXs3r16s4Owy8qoSvdhnQ4uPjcc1iN3tm2JeEeTl56ksYWDLUHm87Ir1IeI8jmbaEfOG/Bsfev9e7x9cs31zevKG1NJXSl2yj685+xZWZREOpdcXfePQ6kvsPjONMrnq/ixwMQWmHk/9Jfh7LcDo9Dqe/9999n1KhRjB49mocffpj169czYcIExo4dy+zZs+u2vH3llVd4/fXX68qNHDmS3NzcBuvw2bp1K5MnT2bAgAF1rfVHHnmEtWvX1t3z7W9/m3/+858d8E4bd92bcylKR7BmZFDy9tt4gHO9jQTZ4IJuUKfF80nCLTxz7h2sBgPhO40ci3mCkY980fAOjTeQ3z5wd7vU+18rm543fvz4cX7xi1+wc+dOIiMjKS0tRQjB7t27EULw7rvv8uqrr/Lb3/62RXX4XLp0ie3bt3PixAnmzJnDwoUL+e53v8sbb7zBvHnzqKioYOfOnSxbtqzN3nNrqBa60uVJl4tLP30ZPJL14wUBdgMS6hb4dAaPRkeJLgyAIReMLD+ei2Pfu50Wz41u06ZN3HfffURGereVCg8PJz8/n9tuu43k5GRee+01jh8/3uI6fObNm4dGo2HEiBF1Lf3p06eTnZ1NUVERy5cvZ8GCBeh0ndtGVi10pcsr+/BD7CdPUhgKO0ebmL5XUKbvhVNj6NS4Lpn6EF5VRkWAkTs32Xg36jc8PayDBmi7qOZa0h3p+9//Pj/60Y+YM2cO6enpvPzyywDodLq6E4rAe7pQc3wbawH19l555JFH+OCDD1ixYkWje7d0JNVCV7o0Z2Ehhb//PQB/u0XDveabACg0RDZVrEMUGr0x5PUKJbwKXAcMnPzi2U6O6sY0a9YsVq1aRUlJCeDdPreiooK4OO+q4Su7Qvr168fBgwcBOHjwIGfPnm20juYsXryY39d+PkeMuOZkzg6nWuhKl1b4m1eRNVb2DRY4h5iJcwylhByKjL07O7S6GC6GhOPR5nHLIcnSIftIEakclMM6ObobS1JSEi+88ALTp09Hq9UyduxYXn75Ze677z7CwsKYNWtWXeKeO3cuq1atIikpiQkTJjBkyJBG61i6dGmTz42Ojmb48OHMmzevvd+iX1RCV7qs6t17qPzsM+w6eP9mwR+mvkLGu95NP4u6QAu9WB+BB4HZXUXgd76Fbdk/mLhNR8JtS8koewWP+gW4Qy1atIhFixbVe62h/cwDAgL417/+5XcdVyf1K7fSrampITs7u8EtdzuD+sQpXZL0eCj4za8B+HiyhnARzV1v1ZB35jQARYbOb6G7NTpKDeFokOjuuBNXmJkhFyGn0MUC3VedHZ7SzjZu3Mjw4cP5/ve/T2hoaGeHA6iErnRRlZ9+ij3rBMXBsCNNcLjge4Q5y9BJNxW6YOxaY/OVdIDC2h8s//7Xf/GHhDsAuHsr9O61gRCqmiqqdHOzZ8/m3Llz/OAHP+jsUOqohK50OR67ncLf/Q6AldM0hJSNxe4JJap2D/Su0Dr3KaodGO3tKGJjv3GcDutNpAXsJwx8K6B7LBdvC2156o7i1ZrvqUroSpdT9sEHuC4XkBsFZ4YIDpV5DxDo7SgCvkmiXYGvhR5lL0IKDW8l3QfAPbslVaZDUHmxM8PrECaTiZKSEpXU25CUkpKSEkwmU4vKqUFRpUtxlZVR9Je/APCPmRo0xbPwfUx9pxQVdqEWerHBOzAa7ixD63FxPHIA2+KGM/VCFlGHDBzf+P9IundpZ4fZruLj48nPz6e8vLzFCagz2Gy2Lh+nzWajV69exMfHt6icSuhKl1L63nvIqmqOJAiq++g5fu5W7wUp604p6kotdJdGT5m+FxHOMiIdJRSYolk27B4mX8xi1mHJ30bv4LWiU4jeQzo71Haj1+tJTEwkPT2dsWPHdnY4zeoOcbY2RtXlonQZruJiSj74AIAPZ2ioLJyDbyfFXq4KDNJJlTYIqzawE6O8VmHtfPSo2i6hC8FRfNUvBa2EYXv17Nz4XGeGp9xAVEJXuoySd98Dm539gwSD+kZwxjqh7lpvuzdZFnaBBUVX83UB+WJEwoohd+LQCKZkSZafycKTv78TI1RuFKrLRekSXEVFlC7/EIDVNwnevGkJa45a6q77zhDtCguKrhTiFpg10QAMtZYwuMJIkBRoiWHb1DcxOGtIyrHwwTvbGHdbHHFDehESGdDJUSs9lUroSpdQ8u67YHewd4ggqV80Cf2nAd8cEOFL6JeN0Z0U4TeCPJDk0JHk0BLp0SBlLHZA5y7B6PEghA4XEp3Q4jQEA8FYCmLZ9H4WAHFDe5E8PZ7E0ZFotOqXZKXtqISudDpnQSGlH3pb52umCEpP3FnvtB8hPXUDooXGqE6JESDKJZho1zPYqUFT27dvE5I8nZYIXRiBrjI+Nl7gXEAUbgFaCd85+TV3XMgiM3EgYlAyjuphXDhZzoWT5ZjDjEy6dyCD06IRN/g+6krbUM0DpdOVvPcuOF3sGSoIDQwh3zG83vUIRyl66aJcF4JN2/HTzXq7BfOqDCyqMjHUqUUC2Xo3HwfZ+VOIjbVmB+dM3h80ZlcB7trc7Bbw8YCJGKx5TDryNftNb/DwfwZz0/2D6RUdSFWZna/ey2TdmxmUF9R0+PtSeh7VQgDUeNsAACAASURBVFc6ha8FHmqvYsXmlQB8MllQUrTwmnt93S0FHdw6N3pgqk3PGIcWgcCJ5LDRzV6jk+qrmkIFxiiGV50k2lYIId+8bjEE8c8B03jw1GYm79GwacAL3P2dzxk1I56sXZfY+fFp8k+UsXzJHqY9MISkqXEd+h6VnkW10JVONefMdrA5ODhQMLpvDPmOa7ed7fCELiHJoeW7FhNjHTokcMDg4p0QG5sDrk3m8E3ffrS94JprnwycgU2nJeWM5LOzZ3FfzEBoBCOmxPLtn01k2KQ+eFyS9H+cZOuKU7jdnmvqUBR/qISudJpAp425Z7cBsHaS4LEpP23wvmiHL6G3/4BooAfmVRu4s8ZAkBTkad0sC7azKbDhRO5TYgjHJbSEuSowuuufgFNpDGJ9ovdgjsl7NHyx5aW6awFmAzcvGsGsR4ah0QmOpuez/g+HsVU72+X9KT2bSuhKp7kjdxdBTjuZfWFA/wj69p96zT06j5NwRykeRLtPWRzg1LDYYmKwS4sdyYYAByvMDoq1ze9R4hHauvnovt8orrRm0Aw8Rh1ppyWfnTmFpzi73vXhk2OZ98MUAkIMXDhZxvo/HsZhdbXNG1NuGH4ldCHE7UKIk0KI00KI5xu4/qQQ4qgQIkMIsV0I0flnMSldmt7tZMGZdAA+maThexN+3OB9UY4iNEiKDRG4Ne0z5CMkTLPqWFDtnUN+XufmbyF2jhvdvoWqfvF1CTWU0CuMwYQ/+C0A0vZr2LLl2t9GYgaGct/zaQRHmCjMreTT/z2Mw6aSuuK/ZhO6EEIL/Am4AxgBPNRAwv5QSpkspRwDvAr8rs0jVXqU2ef3E2arJicawgcEMXjIPQ3e197954EeuK/awAS7Hg+SLSYnK4McWDQt3znQF2OfBvrRAe6+3B+XRjDhhGTN6QPIykvX3BMcbmLeD8diDjNy6UwFG/5yBI9L7WKo+MefFvp44LSUMkdK6QBWAPXOdZJSVl7xZRCgPoFKo6TbzcIzmwH450QN3xv7743e264JvUrDwxYj/V1aqoVkpdnBXpOrRa3yKxXUDYwWQgNbyZYEhLKxbyoaYNhBLXu3/KzBekIiA5j7g7EEhhq8c9b3SrU1reIXfxJ6HJB3xdf5ta/VI4T4dyHEGbwt9P9om/CUnqhq82Ziq0op6AWWfhpGjXqk0Xuj2imhD3JqEIcDCZEaLmjdLAu2ka+7vtkllbpgrBoTAR4bIS5Lg/esHnwzHmD6UcnyU+lgLWvwvl7Rgcz5zzHojVoqz0PGV3kN3qcoVxLN/eQXQiwEbpdSfq/264eBCVLKZxq5/1vAbVLKRQ1cexx4HCA6Ojp1xYoV1xl+26iqqsJsNnd2GM3qKXH2evVVjDln+b9bNMSNmsqYwQ/WXTt6oaLu79JuxfnlB6DVob9zEUK0wRi+BC7oEWeNCAQyyokcbGuz6QHOPV8gC/LQpsxEGz+owXuSVr9PTFYm68cLkm9OI6D/o43WV5kvydsuQUD/6QJzn667orSnfD67gqZinDlz5gEpZVpD1/wZZboA9L3i6/ja1xqzAvhLQxeklG8DbwOkpaXJGTNm+PH49peenk5XiaUpPSHOmkOHOJdzlioT5A6VrD5zJ/JM9RV3fPOR7F9TyhwgXx/FJ8cM1x+YhFlWPakO7zM8/e38ttwDx9tusHWcvQ8TyePA6WK2lV07px5gUPSt/DErk1sOST5K3c+vvv0O6Bo/I/Wjsk0UHYfL+7Tc/9/juuzmXj3h89lVtDZGf9ol+4DBQohEIYQBeBBYd+UNQojBV3x5F1B/Tpai1Cr5v78B8NVYQWDVaCTaRu/1DS62RXeLVsLdNd5k7kKyLtAB/Ryt7i9vzOUr+9EbcbpXPPoJaZicYDgO5/a/3WSdvUcK+idHYK92sfFvmXg8qj9daVizCV1K6QKeAb4EsoCPpJTHhRA/F0LMqb3tGSHEcSFEBvAj4JruFkVxnD+PZeNXuDSwf7Rkd/mCJu+PsXlngVwy9rmu5+ol3FttYLhThx3JmiAHJw3u66qzMb7Nw3o7itHIxp8R88RTANx+QPJBxnsNDqL6CCGYvXgEgaEGLp2pIGPj+bYNWukx/Oo5lFJukFIOkVIOlFL+sva1l6SU62r//p9SyiQp5Rgp5Uwp5fH2DFrpnkqXLkNI2DZSEO5MxE7jXQca6aZPbSv3kqn1Cd3ogfuqDCTUzmRZYbZzXt9+S+vtWiNl+lB00k2ko6TR+wInTUIMTqRXNZSecFCSubbJek1BemZ+x9uFs2ddDiUXqto0bqVnUCtFlQ7hrqigdM0qANJT4UDpA03e39tRjF66KNP3wqZtXZ9xgAceqDYS59ZSKTx8aLZTqGv/7opLxhgAYm3XzjP3EUIQ83htK32fZPm+3zZbb0JyJCNuisXjkmxcmqn2fFGuoRK60iHKV69G2J0cSRDclDiIMtn0Mv4Y22UALrayuyXIAw9WGYl2ayjTePgw2EG5H0v428LF2t8omkroACG3346ndxjxJZB5qoSavL3N1j1l4SBCIk0U51Vx8ItzbRKv0nOohK60O+lyUbTMOxj6ZZrgW5P/p9kydf3nppgWPy/IAw9UGYn0aCjSeFhutrdq5WdrXayNOcZ2qem+cb2ePo8+BsDN++Dllc82W7fBpGPWw9794g98cY7KYmsbRKz0FCqhK+3OsnEjsrCEi+Egokyk/W/jM0AAkJIYe20LvYX9575kHlGbzFea7U3uktgeKnShVGsDCPTY6OUsb/LeXvfdT41ez4g8KLcW4a5sakawV9zQMAaPi8bt9LB9lZpQpnxDJXSl3RX+7T0ANqRpKC27tdn7Q12VBLmt1GhMVOhC/X6Or5slwqOhsDaZWzvjEy4EF3396Pamu1205iA+S5gCwISDgvStS/x6xJQFg9AbtZw9XMy5440Pvio3FpXQlXZlPXIE5+FjVJmgeJDgkHVKs2Xqdbf4edZmoAfurzISXpvMP+qsZF7L1+3SXD86wLoBN+EWgoknJGtPbAFn890oQb2MjLsrEYBtK0/hdqoBUkUldKWdFS9dCsDXYwRYxuHPSp5Y34Con/3nptpk7usz7+xkDt/0/fveS1OKA3qxJX4UGgl9jwiO7P69X88YNSuesD6BVBRaObxJ7fWiqISutCNnQSGWL7/ALSBzNOyyNLxF7tVi7P4vKDJ64P5qI709Gkq6SDIHKDZE4BB6b/eRq7rZ+z8ZOBOAmzMky4+saHIw1Uer03DT/d5F2ge+OKdOOVJUQlfaT9mKFQi3ZO9QwT2DJuOg8f1KfExuK+HOcpxCR5Gx6amNegkLq7+ZmrjSbKemi3yipdDULYjyp9vldK94jkb2I9ABHHdy4fgqEp7/jITnP6u3YdnV+o2IIH5YGA6ri4NfqmmMN7ou8vFXehqPw0Hxh+8DsG0s3DPtZb/K+eafFxij8IjG93nRSphfbSDWraFCeFhpdnT4bJbmNNWP7kvWCc9/VvfamoE3A97tAD7c/0e/nzNx3kAAjmzOp6rMfj0hK91cF/svoPQUlZ9tQFRUczYajMHhDPvVYb/Kxfmxf4tGwpxqA/1dWqqE5CNz604Yam++mS4xzcx08dnbZzgyLpqoCjifWUKi9qxf5aITQhiY0hu308O+Df6VUXomldCVNnc0v5wdv3kDgH+lCs6UzW2mxDfibfkA5Adcc4YK4D3/884aPYNcWmqE5COzvcNWgLZUgTEKNxoiHSUY3M23nKXQ8KdI7yyg2fslo8I+8ftZE+YMQGgEWTsuUV5Q0+qYle5NJXSlzYXmn2NAeSGVAVDTz0C2078zw01uK70dJbiEtuEWuoTZVn3dromrg+yUdNFkDuDW6CgwRiFofj66z8a+qVQb9Ay5CNaaiwRT2XwhIKxPEMMn9UF6JHvX51xH1Ep3phK60ubi92wDYONYgaViuv/lrN5VkpeMfXBrrj10YqpNxxiHDieSj80OCjpgo63r5ftNo68136/77Tojn/a/CYAJhwQ3hX7s97PS7kpEoxWcPlCoWuk3KJXQlTblvHyZ6BPHcQvIHQ57rLP9LtvX5k3oeQHx11wbb9Mx0a7HjWRdkOO6z//sKL734m9CB1h/xUIjqT2GaGJf9SsFh5sYNrEPUsIBNePlhqQSutKmSpcvRyNh71ABrmQ8LfiIxVsb7j9PtmuZbtMjkXwe6CSnHfczb2uXjdE4hI4IZxlBLv/2MC8JCGVrfDIaCQOOCQzVX/v9vJTb+yMEnNp9WW3cdQNSCV1pMx67neIP/w7AnjGS3RX3+l022FlJL1cldo2BQkPvutcHOzTcatUD8HWAk6x2OmmovXiElgsmX7dL8xtv+XwyoHah0WHJKfs2v8uF9g5k8PhoPB7JoX+pk41uNCqhK22mcsPnaCxWzkaDNigGC/6frO7rbsk3xSGF92PZz6nh7hoDGgQ7TE4OGbtXMvdpTbdLdlhfsiLiCLSD7pSLgpxNfpdNvS0BBGTuvEh1uZqXfiNRCV1pE1JKLv/trwBsTBEcbea80Ktd3d0S7RLMrzagQ3DA4GKn0dW2AXeguoRuy/drSb/P6oHe8Yfb9ktW7HrV73LhsUEMHNsbj0ty6CvVSr+RqISutAnroQzkqVwqA8A4IIA8d4L/haUk3jcgaoon3C1YWG3EgCBT72JTgNOfPb26rFJ9GFXaIILcNYQ7S/0utzsmiUKzmT7lkH3sPNYy/wc6U29PACBz+0Xs1u77w1BpGZXQlTZRsOxdwLur4gCT/zNbAMKdpQS5rVRpA3Fqe3FflYFAKcjRufk8sHsncwCEIK/2N49+Leh28QgNHyfOAmDmfsn6bT/zu2zvfsHEDe2F0+4mc9vFlsWrdFsqoSvXzVlQSM1Xm3ELKBulxxYwqUXlfYOFl0zx3FdtIkRquKB1888gB57unsxr5Zla3o8O8K9+43EYtIzIg41HdjHkef/npY+Z3Q+AI5vz1IHSNwiV0JXrVrL8H2g83l0V546Z6/ehFD4JNd6uhBiRULen+cdBDlw9JJnDN/3ocbaLaPycVw5g1Zu4OHYiAGmHBBOD1/tdtn9SBL2iA6kqs3PmYDPH/ik9gkroynXx7qronap4eKxkyuSftKi83uMgznYRiSBCO5AK4WG12Y6th30ya3RBlOjD0EtX3Y6S/soffxMeAZOyJAGGfX4PrAqNYMzsvgBkfJWHbMGArNI99bD/NkpHq/xsA9pK71RFl6k/iT9Nb1H5fjV5aPGg0cZQozXxkdlBVQ/9VJ4L9HaB+H4j8ZetVxi7Yoej80DCcQ+njq/yu+zQCX0wmfUUnbdw6XTTB1Yr3V8P/a+jdAQpJRfe+zMA6SmC/eX3tbACmGzxHp0mDYmsCeq6Oye2hbOBCQAMqMlt0fRF+GYK4+wMyfI9/u+VrjNoGTndOyCbsVEdU9fTqYSutJr1UAaa03lUBoAtNpQC2fyRcVeabNPQy54LwNchfbvFZlvX45KxD1aNiV6uCsKcLWstnwjvz6mIPphtYD1UQvGlg36XTZ4ej0YryD1SrLYD6OFUQlda7eL//QWATWMEZyr9Oy/UZ6xdy6TqEpBWarTBZAb0ao8QuxQpNOQG9gcgsSa3xeU/GnAr4F1otHLbL/wuFxhiYFBqFFLC8W3+bz+gdD8qoSut4rx8GdvX23ALKByi47hztN9lhzu0zLYacDu9+3ZnByW0eGZMd/VNt0vLTxbaFTuSInMQfcrh1MET2KqK/C6bPMM7yyZz+yVcju65hYLSPJXQlVYpfH8pWgm7hwlKnNP8Lpfo1HBHjXezLYvrDABnA/q3S4xd0fmAvriElj72AgLcLduz3CM0rE709qXP2NeyhUbRiSH07heMrdpJ9n41hbGnUgldaTGP1UrpyuUAnEiW7Ki51a9ycS4Nc6sNaBEc1JUQ6CrBIfRcCIhtz3C7FKdGT74pDkHLZ7sA/Kv/eNyBBoZdgC0H0vG4nX6VE0LUtdKPpuerKYw9lF8JXQhxuxDipBDitBDi+Qau/0gIkSmEOCKE+FoIceM0uW5AZevWoat2kB0DFtNI3GibLRPlEiyoMqBHcNjgotDt7W45H9AXj2i+fE+Sc+Vslxay6YxEPPQtAFL2e9i253d+lx2cFoUpyDuFsSDXv6PtlO6l2YQuhNACfwLuAEYADwkhrj4k8hCQJqUcBawG/N8aTulWpJRceMc7bW5XCuysXNhsmbDazbaMCE7q3XwV4GRgTW13S+CN97M/tzah97Xmo/P418K+0l35fXFrYMJJydo9K/wupzNoGXFTDABHN7dsCwKle/CnhT4eOC2lzJFSOoAVQL1j3KWUm6WUvg7B3cC1Z4gpPULNrl3o80soNUN177hm9zwP9gjurzIQJAVndW4+C3QQ4K4m3nYRNxpyAhM7KPKuo1oXRIEhCr10tXhvF4DSgFC2xI9CI6H/PjvHj3/kd9mkqXEg4PTBQqxVjhY/W+naRHN9aUKIhcDtUsrv1X79MDBBSvlMI/f/L3BZSnnNvCohxOPA4wDR0dGpK1b437poT1VVVZjN/h/G0Fm6QpymN39NaNY5Pp4q6D3lGez6uGvuiQ6AAivgEIgjgQirBhniRo6sAS24c47hPrYL0ac/+vH+9b+3h7o4O4E7OwN31j40cQPRpc5q8t6G4gwqLGDSX9/AroMPHzdz56jX/H72uS0eqi5B9BhB5LC2m13UFT6f/ugOcTYV48yZMw9IKdMaunbt0erXQQjxHSANaPCodynl28DbAGlpaXLGjBlt+fhWS09Pp6vE0pTOjtOec5acrHM4dBA6LppXTjTcXfJfyS7+97COB6uMRHk0FGo8rMCBPdP7cVtw8SyxwOfuwWQfbdOPYIv8V7KL33bS84OdQ1nMPuwXz/FnncSp0Td6b8NxxvGrPv0Zc/kcwUeqGbIgiNi4cX49+2xYERv+chTbRRPTn5iIaKMpo539+fRXd4iztTH60+VyAeh7xdfxta/VI4SYDbwAzJFSqnOveqC8t/8AwLaRgoUzm9iEyw0Lq73JvETjYZXZjr32kxbstBBrv4xT6Or6km9EFn0wF4190EsXia2Ykw7w4cA7ALj1gOTDdP+nMPYfGUFQLyMVhVYunCxr1bOVrsmfhL4PGCyESBRCGIAHgXVX3iCEGAv8FW8yV5NceyBXWRnWz74EoCo1gD6Db2/wPp0EcTyAWLeGCuFhldlBzRWfskHVpwHIDezfZKv0RnDKPBiAoVXZrSp/NHIgDIonxArFe3KoKPfvuDmNVsOIKd7B0ePq8IsepdmELqV0Ac8AXwJZwEdSyuNCiJ8LIebU3vYaYAZWCSEyhBDrGqlO6aYu//1v6JySgwMFR2umkfD8Z9fco5Ewp9qAqNBRJSQfmR1YNPXHaIbUJvRTQYM6JO6uLDtoIB4Efa35mNyt6MwXglfCZgBw+17J8s0v+F10xE2xCAE5GUXUVKrB0Z7Cr3noUsoNUsohUsqBUspf1r72kpRyXe3fZ0spo6WUY2r/zGm6RqU78TgclHywDIATo2Cn9dpBPCHhnhoDA11apM7DR+Zrd04MdZYT5SjGIfScC+jXIbF3ZTZtAOcD+qLFw6DqnFbVsSN2FMXBAUSXQ/bOA1htFX6VM4eZ6J8cicctObHrUquerXQ9aqWo0qzS9WsxVDrIjYLLgWnIqz42QsKdNXqGOLXYkMhkKyUNbIM7pMrbOs8JSsSt6bzB0K7E95vKkFZ2u3iEhn8MvBOA2Xska7e+5HfZpKneFbrHt11AetTK0Z5AJXSlSVJK8v7yewAOpgi2Vs+76ga4zapnhFOHA8lqsx3MDZxfKSXDq04CcDJocHuH3W3kBCXiElri7JcwuyytquPrvuOwBOhJKIS9W7/G5fKvC6VfUgTmcCOVxTbyT6nB0Z5AJXSlSZZt2zDll1FqhrEzp2HH+M1FCbdY9SQ7vMl8jdnBpUb2NI+3XSDUVUml1lx3vqYCTo2hbgfGYZZTratDq2PVAO+mXVN3u/nXntf9KqfRCIZP9rbSs7arwdGeQCV0pUln3vSuD9uRArfe/PNvLki42apnjEOHE8knQQ7ydY2fLJ9kyQIgK3gYUqiP3ZWOm4cDkGTJRMjGv4dN+TRhCu4AHcPzYeOmlUiPf/UMnxwDAs5kFKmVoz2A+p+lNKrm6FFMx/OoMUDCjFHozFHeCxJmWvWkOHS4kKwNcnBe33gCMbmtDKzOwYMgM3h4B0XffeQFxFOhCyHEXUU/a+uOibPqTUR++9sApO5ysuXgX/0qFxxuot+ICDwuycndLTu8Wul6VEJXGpX9e2+LfPsYmHPHr70vSphp05NWm8z/GeQgt4lkDjCs6hRaPJwP6EuVrmsvue4UQnAs2Lvf3UhLZqurifzuE7gNGlJyJJ9ufMfvLXKTbvJ2u2Ruv6i21e3mVEJXGuQ4fx7dzmO4NBA2LRFTWCJSSmbYdKTZdbhrk3lOM8kcKeu6W46r1nmjsoKH4kZDQs05zK6qVtUx6Dc72dDPu/x/1A4be4596Fe5/qMiCAgxUHa5hss5alvd7kwldKVBp/6wBI2EXUkw/+5fI6Vk+6psxtn1/idzIMZ+mXBnGdXagLrzNJVrWbWB5AQlokEyovYHYGssH3QbLi2My5Z88uWbfpXRajUMn+Q94DtzuzpztDtTCV25hqu4GPnFdgA0U6IxRyezbcUpjmzKr+tmOeNHMgcYWentQsgyD7vhDrJoqaPBSYB3ALm1g6NlphA2JYwFYOj2KjJOrfer3PAp3m6X0wcKsVtdrXq20vlUQleukf3HV9C54MBgmDf3Z2xZfoqjWy6g0QnWtiCZB7mqGFx9Gg+C48FXn4miXO2CKZYyfShmdzWJrTjNyOf9QXfj0cKEE5KVG35FwvOf1f1pTK+oQOKG9MLl8JC9r6DVz1Y6l0roSj3u8nIcn3wBwJnkQF58w87xrRfQ6jTc+dQozvqZzAFGVx5Fi4fTQQOp1Ie0V8g9hxB1rfSxFYdbXU1JQChBd81GAwzYWk6fgAy/yvla6Vk71Jz07koldKWe7L+8isEhOZKgwV71PMkOHTqDhrueGUX/pAi/69F7HHXdLYdCR7dXuD1OZvAIbBojsfbLxNhav8dK3A/+G48GJmdKkjUf+1Vm4NjeGAN1FJ6zUJTXulWrSudSCV2p466qxvrRP/EIHRcHPUacIwI7kvcNVqYu3dXkr+xXS7JkYZQO8k2xFBqj2jHqnsWp0XMkZCQAKRWHWl2PPjYW8z23oAEmHbDSJ6D5Fr/OoGXIeO/gaNYOtWFXd6QSulLnpUe/j96uY9e4JzG4RmETko/Mdi40sQK0IdLjYUzFEUC1zlvjSMhIXELLgJpzhDtKW11P7I9ewK2FSScko1njVxnfIdKn9l7G5XC3+tlK51AJXQHAY7Vy19nDZIx+BnvgcKqFZIXZzuVG9mZpsq6LOQS7qyjV9yI3QE1VbCmrNpBM8zAAUir86/9uiD46muC53oNIpuy3Eh2Q0ewAaWR8MFH9g7HXuDhzqKjVz1Y6h0roCgDH/vwm2UP+g4rQgVg1Npab7RQ1sAVuc4T04Mn2JqGMkNHQRudV3mgOhY7Bg2BIVTbS2rqFRgBxP/x/OHXeeekpHv/60tXgaPelErpCeV4pe48mUhXcF48oZJkZylqRzMF7IpG0lFGpNZMVPLSNI71xVOpDOB00EC0e3Nmtn/Gi692b9AFjAJi210pM0L5mywweF43OoOHCqXLKC2pa/Wyl46mEfoMrzq9i1a/3YDf1xmA7z8Ze+dccG+cvjXQzocybMPaGjVMLia7Tvl6peBB4zmUR4vTvJCKfK7tW3h04H7teMOasJNW2Fmj639cYoGNQqncgO1O10rsVldBvYBdOlfHJ6wdwuI2ElZ2kLOxtDsvW77cy3HKCUFclmEM5YR7ShpHemEoN4d7vo5RMLNvb6noqjUFsGDwZgNt22Oln3tJsmRE3xQFwYtcl3K7WrVpVOp5K6Deo0wcKWf27gzhsbnoXHcJc/Ge+DLiv1fVpPS7Glx/w/n1oqtrzvI3sCRsHGi1Dq08TaW/9IOWyAXdSHahh0GUYX/4F0HSS7jMghLCYIKwWJ7lHilv9XKVjqf91N6DDm/L48t1j6BBEX05n5PH3yBoTwBlP61vVyZbjmN3VFBki0MQOaMNob2xVumA0Cd5tEyaX7Wl1PXadkZVDbgXgzh0uBoVsaPJ+IUS9bXWV7kEl9BuIxyPZ/lE22z/KBgnO6h2MOLGK7HjJp8bFra7X5LYyrnw/ALvDJiDUzJY2pR08Brsw0N+aR5y19bshruk3k7JQPTFlMOnCVqzOpgc8h07og0YnOJ9VSmWxtdXPVTqOSug3CKfDzZdvH+Pwpjw0WsG0e2OZcehDBHBsbAR5ntbPF59cuhuTx8G5gL7kBvRru6AVAITRxMFetTNVSrajka1b8OPRaHlv6HwA7trl4cN/vdDk/SaznoFjo0BC1k61crQ7UAn9BlBdYeefbxwiJ6MIY6COOf8xhoqPn8PogiODYLX2yVbX3cd2maSqE7jRsDXiJjXvvJ0cChlNuS6ESGcpo2tX4bbG1zHjuBgVRGgNVKz8kuKqpo+dG1Hb7ZK18xIetxoc7epUQu/hivMtrP71fgrOVhIcYeLeH6diFhfptSUbj4AjSQMoI6xVdQvpYXrJNsC7xL9c36stQ1eu4Nbo2BIxFYAJ5fsxu1q5eZYQvDbi35DALfslS1c+3eTtcUN6ERoVQHW5ndyjJa17ptJhVELvwc4eKWbNawepKrPTZ0AIC3+SRnhMEIdeegqthEMjYLX4bqvrT7JkEuUoxqI1s69XahtGrjTkfGA/soMGopcuppXsaHU9J3olcDQxDp0Hoj/J4lRB49sLCCEYOc07hfH4NnWaUVenEnoPJKXkwBe5bPjLEVx2N5l6F8+VFDDila+4sP1zojOKcGhh7+Dx2DG26hnBTgtTzbPtAgAAIABJREFUSncDsC1iMi6Nvi3fgtKIbeGTcQg9A2vOklh9ttX1/Hroozj1kHaa/9/enYdHVd2PH3+fmclMZkky2VfIzp6EJWERUcQNXEDr0kX7a/uttf1Wn652ta2t3bTab6vV1m52UStaAUVABQREZF9C2CFk35dJMjOZzH5+f0xEkBCSkJAQzut55mEm99y5n5swn7n3rLzytwd7XRx6wuxktDoNVYdtdDSrxtGRTCX0UcbnDbDu+cNsf70MJMxanMlqk4+ACFWRlP70BwAcKtLxJncO7CBScl3LBvTSx0lTJidNqpvixdKps7A9OrQQ9DWt7xEeGFiCbQuPIvoztwIw661W1u9/8Zxlwy1hoZGjUnVhHOlUQh9FHDY3K57cy4ldjYQZtCz6Sh6FN2VCdzvlbU3LSajx0G6Gq77+U+QA//wF9gOkuetwaYxsiLtaNYReZCWRedSGJ2MOdHFtyybo5eq6NwtsV2CP1DCmBfY+9xtcvXRjnNxd7XJka50aOTqCqYQ+SlQftfHqr3bRXOUgMi6cO747g6yp8ae2G/xd3H0gVEXScF0cadPuGNBxor1tXNEWep8NcVfj1hovPHilX6TQsC7uWjxCT5argknOowN6H582jOemhEYH3/CBnxdWfOucZZOyIolNtdDl8FFWrKbVHalUQr/ESSnZu7aSN58qxu30MXZSDHf9oIjYVMsZ5b5a8yesTqhKhIXfe2FAx9IG/dzQvB6dDHDYMp5yc+ZgnIIyAI6wCDbFhXq9zGvdQlQ/J+/60MaEIk6OtRLuA9O/N1NuO9ZjuVDjaKgL48H3VOPoSNWnhC6EWCiEOCaEKBVCfL+H7VcJIfYKIfxCiAFWzCr95XH5ePvPB9m2/CRSQuFNGdz8YAHh5jMbKMe4y5h/MFT3afzULIwxGf0/mJRc3fo+Cd4WOnQRvB87dxDOQLkQx825HDfnoJd+FjWtRRf0Deh9fj7xq/j0UFgqWfrMfedsIB03M4kwg5a6E+201g58jnZl6Jw3oQshtMCzwCJgEvBpIcSkjxWrAj4P/GewA1R61lzt4NVf76asuBm9Uceir+Qxa3EWGs2Z9dlSSr515G/o/XBonGDel/4yoONNdhxhsvMofqFlTcJCvJqB9Y5RBpEQbIy9inZdFPHeFha0vDeg+vRGYwwxnw01kF65qoXV2//UYzm9UceE2aE1Rw9sqhl43MqQ6csV+kygVEpZJqX0AkuBJacXkFJWSClLON8UbsoFk1JycHMtyx7fg725i7gxFu7+YeEZ9eWn2/X3nzCh0kunAZaPvxWh0/f7mAmeplMDiDbGXk2LIe6CzkEZPF6tgdWJN+IVOsZ3nmCqfWCjSFO/+SvcKQbi7FDz9LO0uHqeYTHvmjQAjm1vwN05sDsCZeiI3vqfAnRXoSyUUt7X/fqzwCwp5YM9lP0nsEpK+do53ut+4H6AxMTEGUuXLr2w6AeJ0+nEYrGcv+Aws7c56Thkwt59cRSdBUkzBBptz71MvJ02Ih55GKsTiudH0DKv97k7eiK7nPjeXwnuTjQZk9Dln7+qJdEIjZdAd+XRFGewrhz/7vWAQDdnEZr41H4dIy81CkP5ESKeeAptUPDS3XEkjn+IvNSos8pWbArS2QCJUwVxEz76v3epfI4uhTh7i/Gaa67ZI6Us7Gmbbkij+hgp5V+AvwAUFhbK+fPnX8zDn9OmTZsYKbGcS0NZByvf3IOvE8LCtVxzzwRyixLPWT7j+6v50cnHmeuE6iT4ddQ3sR/o35/bEPBwR/3bxPo6qTUk8zpXEjxw/lWIvp3n57f9PNZwGF1x5jI7ykZRx15c29exLHkJLYae79p6UnHPfJg/n7LSnXiWbef6d1r4ntjF9nt+cXbZ2BZWP1uCq8rAVffPOVXNdyl8juDSiHOgMfalyqUWGHPa67TunykXQTAQZOeqcpY/uRdfJySkR/DJh4t6TeYAc1wbmHPQTlDA21NnYReR/TquNujn5qa3iPW10RoWzerERWpJuRFue/TM7kZSH4sbV/dr2boPl6u73ncbbbEaEjrg3uMraHe3n1U2fXIskfFGHDa3WvxihOlLQt8F5AohMoUQeuBTwMqhDUsB6Gh2seK3+9i1qhwpJXET4RPfmUFUvKnX/Todrdy/ew0aCcX5epaH928lIo0McEPzu6S663FqzaxMugWPVjWCjnhCsC5+AdXhqZgDXdzWsAqTv3+LPAc0Op4quJeARnLtviDPP/2Zs3q9CI0gf36oLr1kY/Wgha9cuPMmdCmlH3gQeAc4ArwqpTwkhHhUCLEYQAhRJISoAe4C/iyEODSUQY92HzZ8Lv3FLhrKOjBbDSz5xjQSCzRodef/Dn73odtJskFTNPw+/ev9OrZGBrixaT05rjI8Gj0rk27GqRvZ9Y3KR4JCy+rEhTTq44ny27mtYWW/k/qOyHx2TQlN5zBnaTlrPji718uEK5LRGbTUHmunuWqAMz8qg65P/dCllGuklOOklNlSyl92/+wnUsqV3c93SSnTpJRmKWWslHLyUAY9mjnb3Kx6Zj/v/ecYfk+A3MIEPvXjmaSN79sUt7tWPEn25maCAt4onE2zpveqmdNpZICFTetOJfM3km6hVR870FNRholPo+fNpJtoDYsm1tfGJxpex+zvX7/xn2d+heYkLVYXOH79DDUdVWdsNxh1TJ4bGmi0b11VT2+hDAM1UnSEkFJyeEsdL/9sB1WHbBjMOm64bzI33DflrIFC59LeWkPnE39HI2Ffvonl5r6P8dIFfSxqWku2qxy3Rs/rSbfSaOj7l4EysnRpTSxPXkKzPpZoXwd31L9BhM/e5/2DQsvPC76K2wAFJyXLf/ZJ/EH/GWUKrhuDRiMo3d2olqgbIVRCHwHsLV28+XQxG188itcdICM/jk//eBa5hX1PqFJK1n9tCYk2aI6FJ8aee16OjwsPdHFbw5tkuSpwawy8nrSYJkPCQE5FGUHcWiMrkhafqn65s34F8Z6+z8NywphO0gOh9pf577Tzwgtn9lSOiAkntygRKaF4vapLHwlUQh9GwUCQfeuqePnRHVQfacNg1nH9/0zipv/Nw2ztXyPk6ifvZfIeFz4t/HPGzXRo+7Z6UJSvnbvqlpPsacSutfBa8m0096O7mzKyebThvJ58KzXhKVgCLu6of50MV0Wf90++/1G8s+IJC0DOs++xed+rZ2yfdkNoDdkjH9Th9wxs1kdl8KiEPkyaKu289vgeti4rxe8NklOYwGcemc24mUmIfk5HW7LlRZJe3AvA5sJUNpiu6dN+Y11V3FW3HKvfTpM+jv+mfII2fUy/z0UZ2bwaA28k3cIRyzjCpJ9bGt9iWkdxn6cJyP/TKhzJGuLs0PyDn1LTXnlqW2yqhfQpsfh9QWzHVUIfbiqhX2Qel4/NLx/jv4/tprnKgSXawM0P5HPjfVMwRfZ/WH5bWxW1P/4VZg+UZup4MqkPvVqkpKhtN4sbV2MMeig3prM8+TZcOvMAzki5FASFlvVxC9huLUIAV9q2sajpHfRBz3n3FaZICp79Gy6TZFKFZM1Dd+D2u09t//Aq3XYCvG7/ud5GuQhG/jC5UUIGJcd2NLB1eSldDh9CIyi4No2iWzLRhw/sz+ALeHnrgcVMq5d0RMAvJ34LRO/f0caAi+uaN5LRVYUEtluLQuuBqkUqRj8h2BVdSKs+huuaN5LjKieu1sZbCdefc1RpxvdXn3q+86HP0fTzfzNvSyf/+uUd3P+TVQghSMm1kpQVSUOZnQObapixMOMinZDyceoK/SJoLLfz2m/28O6/jtDl8JGcE8UnHy5i7p25A07mAK/8aCHT9nrwaSHtFz+kQd97Q2ZWZzn31LxCRlcVbo2BlYk3syu6UCXzy0yZOYulqXfSrI/D6u/g7rrlFLbvQcje59abWZLPgRmh2RaveKWMl/8ZuhsUQjDzllC/9X1rq/B0qav04aIS+hBytrlZ/8/DvPb4bpoq7Jii9Fz3+Ync/u3pZy1A0V9v/u3LFLxRH3pelMeVG89d920IuLm2eQM3N72NMeimOjyVl1Pvpso09oJiUC5d9rAo/pt8OyURU9ASZE7bTu6qW0G0t63X/R5O+xaVEw3ogpD71DrWv/scAGkTozHFg8flp2SD6vEyXFSVyxDwuv3sW1tF8boq/L4gGq1g6nVjmLEo44KuyD+09d2niPvTZnRB2Dsxhr8mfa7nglIywXmcK21bMQbd+IWWrdGz2R+Zp67KFQIaHe/FzaPMnMm1zRtJ9Dbx6dpX2Rs1ld3W6fg1Z49/CKLhO+N+yNOdj5BUBZ0PP8Xu+LEU5t9EQp6gYoOkeH01efPT+jx+Qhk8KqEPooA/yKH3a9m9poIuR2iu6OzpCcy5PZuo+MFZe3P/rpfp+vFzpHRCa2Y4P879bo/l4jwtzLN9QJo7tFJRTXgKm2Kvok3ftxGnyuWj2pjGf9Lu5srWbUx2HqGoYy/jO0/wfsxcykwZZ335O4SZn+V/g1+6f09iE9R+9SEO/SMKc4IgbYKVmqNtFK+vYvaS7OE5ocuYSuiDIBiUnNjZwM5V5dhbQq3/iZmRzL0jh+ScvvUH7wubrRjHo38mxwbt8Vpmv7SO4G92nFHG7Hcyp20nE5zHEECXJpwtMXM4ahmvrsqVc/JqDGyIn8/hiAnMb91MvLeVm5veptaQzAcxc2gMP3OQW4UujaLnnmP3fV8mtQUqv/Ql7N/8Llctvp2ao3so2VBD/jVjBtRzSxk4ldAvgAxKSvc2sWtVOW0NoQmQopNMzL4tm8yCuH73J+9N0cPP8ND+PzOxDhyRgmkvvYEu5qOVg0x+F9M79pHnOIROBgigoSRyCrusM/BowwctDmV0awhP4pWUO8mzH2Jm+25SPfXcXb+ck6ZMdloLz1itSj/paqY9/TjFD3yP9AYo/cMTeP49i4z8OCpKWtj++kkW/L+Jw3g2lx+V0AcgGJSU7mlkz1uV2Oo6AYiMC6fwpkzGz0pEox3ctubK6u187eAfyS8FlwF+UvRljv7xKHAUi9/B1I6SU4kc4IQpi20xs+kIO3u1GUU5Hyk0lETlcTRiHDPa9zHVXkK2q5xsVzllpgx2WWecmhrCWLiEyY+3cfg7j5FTE+TIPXfy+IxvcCdZHN5ax5SrU0lI799c/MrAqYTeDwF/kOM7G9j7ThXtjaErcku0gcKbMpgwJ7lPU9v2V3nlFj74+v0UHpN49PDYnHs5GpFDvKeZaR37ye0sRUNohF5PV1GKMlBejYFtMbMpicxjWkcxeY5DZLkqyHJVUBuezIldMWTPmEnk/M+zbO4ebt+2jvT6ID/e/juWTX+EPG88779ygk98Z/qg3q0q56YSeh943X4Ob6mjeH01ne2hkXWRceFMvzF9yBI5wLETa9n10DeYcUzi1sOBuz+Noz6cu+qWkeRpAiCI4Jg5h71R01QiV4ZEp87Mlti57I2axlT7fqbYD5Pqrmflk78kKiGRvGsXsirsKq66W0tg2duktcBdux9jX8GvaSjr4PjORsbPShru07gsqITeC4fNTcnGGg5vqcPbPVgiJsXMtBvGkluUiHaQq1ZOt23bc1Q/+hTTy6Ep0sCb44tIPrqf632hLxSPRs9hywSKo/Jx6iKGLA5F+ZBLZ2JrzBx2WWcwyXGUAnsJNDWy5eV/8QU0nPClUzPtOm49sJ6UJjee0lcoz/4s25aXkpkfh96o0s1QU7/hj5FSUl/aTsnGWsqKm5HBUHVGck4U029IJ31KLEIztLePb77xbfxPrSM8EM17Ey249HqSvaFBRI36eA5GTua4OafHfsKKMtR8Gj37o/IpiZzC2K5qpjgOk+GqRNaXkwrsSJ1AUkwLOdX7scRdiZNMtrx2ggWfVQ2kQ00l9G5et5/jOxs5+F4trbWh1V00GkFOUSJTrxsz5A07UkrqSg+z7K/fQ3fCQ1f8R6M4TVFWPpBjKZqWw6tVatEJZWSQQkOlKZ1KUzpmv5MvWY7SVFoaWljcYKU1x4reu5xgZz4HN+USn6Uhb+744Q57VLusE7qUkqZKB3U7g/xjxQf4PaFeIsaIMCbPS2XyvFQs0UO3OLLH1UnVgf2U79/DyT3bcbWHVmn36Q1og0HGz72aifOvY2zeVB5/+G1mRak5MpSRqVNnQZs7lf90zSDe20JuZynjOkuJwAneA+A9wNqn36R4TToFCxaRUTCdyDg17/5guywTemeHh+M7Gjm6vf5Ut0MIkJJrZfK8FLKnJaANG/z6cZ/HTd3xo1QfOkDVof00lB5HBj+aEMng85PY0UmHychvx91PV4MRljbA0rcHPRZFGRJC0GyIp9kQz9bo2SR7G/hMx3ICnVYC2GkqLWVd6R8AiElJY8yUAsZOziNtUh6mSNXN9kJdNgnd6/ZTXtzM8Z2NVB+xnZrb3xgRhinFx42fnkV00uDOB+60tVJfeoy640epPXKIxvJSgoHAqe1BBD6jjzGNdnIbXJi8Xl7MX8CrYxepUZ3KpU8I6g3J/DbhAW73bye7fTKBQD2mtg9w6l3Y6mqw1dWwf21oit6Y1DGkjp9IyvhJJOeOJyY5FaFR8wf2x6hO6D5vgMoDrZTuaaTyQCt+X+hqWKMVZEyJZcKcZNLzYnn//c0XnMxd9g6ayk/SWFZKY1kpDSdP4Gg9c/1GITQkZGQzZko+/y7ZysTW7dy6PYguCLZIHd+b+b8ciVbzXyijzwrdbK6KdDLLVYA3cQpF+5/GH6ihpiiHsIQsGkpPYKutxlZbzYENawEwmM0kZY8jMSsn9MjMITI+QfVp78WoS+gel4+KA62UFTdTdagVv/ejKo3k7CjGzUoiZ3oC4ZaB9RDxe73Y6mpora6kpbqS5qoKmivKcLbZziqrN5oolTE0hCdSb0hi3WOfo9lWwkv/+Bqf2uZgTEuo3Hu54/jd+M/h0Q1dfb2iDLfNeguagJcij54D+V9i5s4nmLHhIDbrYTIe/CJpMxfx4O+Wk+xuINHTBJ2dVJbso7Jk36n3MJjMxKdnEp+eSdyYdGLHpBM3ZiwGk1ptC0ZJQm9vclFR0kLFgRbqT3QQDH60tmFCRiS5hQlkT08gIqZvc5rIYBBnu432+jra6utoa6jrvnqooaOpEdnDQgBhhnDi0zNJzA5dSSRl5xKTkkbmD98CIFrbwPMv3kX4mnIWHw3F1xah4//y7mV3wpRB+C0oysj3XniAmECAbL+F4isfZMyB3zCm0QW/+CvH015Al309axJuBCE48J1ZNJQep7E8dNfbWH6SLnsHNUcOUnPk4Bnva46OISYlrfuRijU5hejkVCLjEtDqRkWa65NL8kx9ngC1x9qoOtRK5WEb9uauU9uEJrQkVvb0eDIL4ntM4lJK3E4H9pZm7C1NNO7fw4aKY3Q0NdLR2EBHYwN+n7fHYwuNhuik1FNXB/Fj04nPyMKakNRjfZ9V08i88BeYdKiBK1eALgh+HawYP4cXshbj06q+5MrlQwpYZfbyGYeBeH88+yc/gnvir0nY2U5SjZtHa97kZNI7vJy7AHPUjeTOuoLcWVeElsKLmYkpysXqe7NpriwP3SXXVGGrqaazzUZnm43qQyVnHE9oNETGxROVmIw1IYnI+ARsLTbqUhKJjEvAbI0eVfX0l2RCbzjZweo/fvSHM5h1jJ0US0Z+LGnjrQT8TjptNhrL9nNydytOW+jhsLXgaG3B0dqM33Pm4rg1HzuGMTIKa2ISMSlpRCenEp2cQkzqGKxJKejCek/CGd9fTYb+IIUs5ysn7FxxGMICEBSwIyOdZ8fdS7NJzUuuXJ68Al6zeLjbaSA2aGG/5lE8168hv3EN6fs1ZDd4+VHD22ybtw7uXMSML3w/tKMQuHRmMqfOIHPqjFPvJ4NB7C3NobvouprQXXV9LW31dThsLaELtaZGqk6LoXz9KgA0Wh0RsbFYYuKIiI3DEhOLJToWS0ws5uhoLNYYzNHRhBkujRlLL8mEHhHrx2guwWjxozd4CQQ6qT/STum2NrqcDk51YemF3mgkMi6ByPgEHB4fE6dNJyohkaiEJKyJyRhMpn7H5emysfH9J/iCdxUT9/nJqwz9PAjsTU/lTzn3UBPR+7qfinI5cGpgqcXDXU4DCUEt7Y6b+X38fK5ZuIq8pvdJOSiIbwvAX1dx/PlV/CzDysrU69hnLTrrvYRG0/3ZTSRzWuEZ2/xeLx3N3XfeTQ10NDVy8vAhDALsLU102TtOJfze6I0mzNZoTFFWzFFWjB/+GxmFMSISU2Tkqefhlohhq+a5JBO6x+WgrWY9Pa1+KIQGk9WKufub1RIdE/rWjYkl4sNv4dg4DCbzqdbyTZs2UTR//oBi8Xa1s33Pn1m76r+kVHRSdBTudndv08GWzAm8lL6EOosaRKEop3Np4BWLhzs7DSQHNHzSYWGj8Q6Wxt3K9ddu5Qr7GqzHvWRXCWaebGfmyddwGJfx7v1/ZuztnyNrwRK0ht47Euj0emJTxxCbOuajH27axPzuz7vP68HZ2oKjtRVHa3Pobr4tdEff2daGs91GZ1sb3i4X3i4XbfW1fTo3vdGEMSKCcEvoYTBbMFosGMwWpi9ajNk6NHfol2RCj4yLp2jxHZgiozBFWUP/WqMxW6MxRkai0WiH7uBSUl+zne27/k3N7t0YTjgpKIV7PqrGpz42nLdSr2RN2tV06gdn6TlFGY3c3Un9mq4wCrw6ru/Sk+7X8q5xHm9b5jF+RiXXT19Fat1Jkk5oSGqTRGwuw7/5EQ6EPcKJZDM7EiayO2oWG//w1X7Xh4fpDd1VqqnnLCOlxN3pxNXeTmd7Gy57O66ODlwd7XTZO3DZO+hydNBlt9PldOB2OE59AfR05Z+34MZ+/5766pJM6MaISK665wsX5Vg+Vxul5es5UvI2TQcOIqscpNVIxjXAhNPKtUbq2JUygTeSb6QiKvmixKYoo4FPwFqTj0pdkBtdYYzzacnyhbPP4GeHIZ1nNA+gS/EzO3U/hf6NJDTUEVehYUwzTKnqZErVbr7IbvZO/yMdWVGETZ5EwswFpM+6lvCEC5+2VwiB0RKB0RJBbNqY85aXwSAelwu300GX047b6cTd6cTtdOBxOjFHDd6ylB93SSb0odDlaKC2fjfVpdtpOnEAR009sqGTyOYgY5tgogtOnysuoIHyBDO74ybzbsI8KiOS1OhORbkAx/QB6rVBrnLrmOjTUeQJo8Cj44g+wGG9hi3aGWzRzkCTGqQg7TjT+IC0thNE1ntJqtMQ65CYDrfD4a0E/7uVcn6B0yxwJhqRY5MwZucSPbGIQCdIrxehH5r1ToVGQ7jFQrjFgpWLe3HXp4QuhFgIPAVogb9JKR/72HYD8G9gBtAKfFJKWTG4ofZf0O/Baa+jvaMSR1MF7Q3lOJpqcLU2425rw9/uRNi96O1BNjkgoQOSPNDTd3qXAWrjLORcNZeUa24norCIWx7deNHPSVFGM7tWssrsY6ffzzx3GFl+LQVeHQVeHR0iSGVYkBptkHLdRPZpJoAVjFY3eVNOMDGwg5SOSiLauohogdQmsHRKLGUuKCuDTWVI3iEFOPzIL3BaBC5rGIGocIiJQBcbiyE+EWNCKpbkDCyJWUTGpxAeHYfmPHX1I8V5E7oQQgs8C1xPqHffLiHESinl4dOKfRFok1LmCCE+BTwOfHIoAgao2b+WHX/8CXj94Asg/UGEL4DGJ9H4JFqvRO8FgxdMntBDIyGG0KM37jCwWcNoibBQbU6i2FTA8cgsmkzRoSvwLmCNE9aoZK4oQ6VJJ1lm8RITEEz2apnk1RIlNeR7NeR3l/EjaddI2jV6OjXTOSmmcdAg8SWDIcVFgraWhEAl0Z5GTC4HBpcfY2cQi1MS5QKNlJg6JHRAqE9jO8g2PBzFQ+jK9EN+bWj8iFcvCOgEgTBBMExDUKeBUw9t6BGmRei0CO2H/+pAo0HodGi0WmZ96QGi03KH5PfWlyv0mUCplLIMQAixFFgCnJ7QlwA/7X7+GvCMEEJI2Yf+gwPww+ff4gfvdfRrH3cYuMMFrnANXeE6nAYD7eERNBviyEpP4h+2cTSa4nCEmVTViaKMEDat5H2jn/fD/SQFBGl+LakBDSl+DRYpiAsK4s4euA3oASswGQCPIfSwR0PvHRQHib/74Tl707+eXMbLv//+kBxWnC/nCiHuBBZKKe/rfv1ZYJaU8sHTyhzsLlPT/fpkd5mWj73X/cD93S/HA8cG60QuUBzQct5Sw0/FObhUnINLxTl4eosxXUrZYz/oi9ooKqX8C/CXi3nMvhBC7JZSFp6/5PBScQ4uFefgUnEOnoHG2JdOm7XA6X110rp/1mMZIYQOiOLMKihFURRliPUloe8CcoUQmUIIPfApYOXHyqwEPtf9/E5gw1DVnyuKoig9O2+Vi5TSL4R4EHiHULfF56WUh4QQjwK7pZQrgb8DLwghSgEboaR/KRlx1UDnoOIcXCrOwaXiHDwDivG8jaKKoijKpWH0TASsKIpymVMJXVEUZZRQCb2bEOLnQogSIUSxEGKtECJluGPqiRDiCSHE0e5YVwghhm6mnwsghLhLCHFICBEUQoyoLmJCiIVCiGNCiFIhxNCM8BgEQojnhRBN3eM8RiQhxBghxEYhxOHuv/fXhzumngghwoUQO4UQ+7vj/Nlwx9QbIYRWCLFPCLGqP/uphP6RJ6SU+VLKqcAq4CfDHdA5rAOmSCnzgePAD4Y5nnM5CHwC2DzcgZzutKksFgGTgE8LISYNb1Tn9E9g4XAHcR5+4NtSyknAbOCBEfr79AALpJQFwFRgoRBi9jDH1JuvA0f6u5NK6N2klPbTXpqBEdlaLKVcK6X0d7/cTmhcwIgjpTwipRwpI4FPd2oqCymlF/hwKosRR0q5mVCvsRFLSlkvpdzb/dxBKAmde3LxYSJDnN0vw7ofI/IzLoRIA24G/tbffVVCP40Q4pdCiGrgHkal/2bVAAAB5ElEQVTuFfrp/gd4a7iDuMSkAtWnva5hBCagS5EQIgOYBuwY3kh61l2NUQw0AeuklCMyTuD3wHcJrV7ZL5dVQhdCrBdCHOzhsQRASvmwlHIM8BLwYO/vNnxxdpd5mNDt7ksjOU7l8iCEsADLgG987G53xJBSBrqrVNOAmUKIKcMd08cJIW4BmqSUeway/2W1wIWU8ro+Fn0JWAM8MoThnNP54hRCfB64Bbh2OEfk9uP3OZL0ZSoLpR+EEGGEkvlLUsrlwx3P+Ugp24UQGwm1T4y0Bue5wGIhxE1AOBAphHhRSnlvX3a+rK7QeyOEOH2C4iXA0eGKpTfdi418F1gspXQNdzyXoL5MZaH0kQittP534IiU8v+GO55zEULEf9gjTAhhJLS+w4j7jEspfyClTJNSZhD6v7mhr8kcVEI/3WPd1QUlwA2EWplHomeACGBddxfL54Y7oJ4IIW4XQtQAc4DVQoh3hjsmCE1lQag67R1CDXivSikPDW9UPRNCvAxsA8YLIWqEEF8c7ph6MBf4LLCg+/9jcffV5UiTDGzs/nzvIlSH3q8ugZcCNfRfURRllFBX6IqiKKOESuiKoiijhEroiqIoo4RK6IqiKKOESuiKoiijhEroiqIoo4RK6IqiKKPE/wfszehUeXN0SwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gAXu9CrBYb1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}